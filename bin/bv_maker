#! /usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import, division
from __future__ import print_function, unicode_literals

import binascii
import codecs
import io
import locale
import sys
import os
import re
import pprint
import subprocess
import glob
import shutil
import json
from optparse import OptionParser
from fnmatch import fnmatchcase
import tempfile
import datetime
import distutils.spawn
import platform
import shlex
import time
import traceback
from smtplib import SMTP
import gzip
import multiprocessing  # for cpu_count()

default_subprocess_timeout = 3600 * 6 # default subprocess timeout is 6 hours
try:
    # backport of subprocess of python 3
    import subprocess32
    
except ImportError:
    subprocess32 = None

try:
    from subprocess import DEVNULL
except ImportError:
    DEVNULL = open(os.devnull, 'wb')

import six
from six.moves import reload_module, shlex_quote, zip
from six.moves.urllib.request import urlopen

# the following imports are just to make functions available in tests
# using eval() in filters/conditions
from socket import gethostname

# Ugly hack to backport subprocess.check_ouput method on python < 2.7
# TODO: remove this once BrainVISA is only compatible with python >= 2.7
if "check_output" not in dir(subprocess):  # duck punch it in!
    def f(*popenargs, **kwargs):
        kwargs=dict(kwargs)
        kwargs.pop('timeout', None)
        if 'stdout' in kwargs:
            raise ValueError(
                'stdout argument not allowed, it will be overridden.')
        process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs,
                                   **kwargs)
        output, unused_err = process.communicate()
        retcode = process.poll()
        if retcode:
            cmd = kwargs.get("args")
            if cmd is None:
                cmd = popenargs[0]
            raise subprocess.CalledProcessError(retcode, cmd)
        return output
    subprocess.check_output = f


def decode_output(output_bytes):
    """Decode the output of subprocess.check_output to Unicode."""
    return output_bytes.decode(locale.getpreferredencoding())


if os.path.exists(sys.argv[0]):
    this_script = sys.argv[0]
else:
    this_script = None
    for p in os.environ.get('PATH', '').split(os.pathsep) + [os.curdir]:
        s = os.path.join(p, sys.argv[0])
        if os.path.exists(s):
            this_script = s
            break
if this_script:
    this_script = os.path.normpath(os.path.abspath(this_script))
    python_modules = os.path.join(
        os.path.dirname(os.path.dirname(this_script)), 'python')
    if os.path.isdir(python_modules):
        sys.path.insert(0, python_modules)

import brainvisa.maker.components_definition
import brainvisa.maker.brainvisa_projects as brainvisa_projects

from brainvisa.maker.path import DefaultPathConverterRegistry, \
                                 Path, SystemPathConverter, \
                                 get_host_path_system
from brainvisa.maker.version import version as brainvisa_cmake_version

from brainvisa.maker.version_number import VersionNumber
from brainvisa.maker.version_number import version_format_short


IGNORED_STEP = 'ignored'

if this_script:
    cmake_root = os.path.join(os.path.dirname(this_script),
                              '..', 'share', 'brainvisa-cmake-%s' %
                              str(VersionNumber(
                                    brainvisa_cmake_version,
                                    version_format_short)),
                              'cmake')


def check_ld_library_path_error(fatal):
    # This code is a safeguard: libraries that are dynamically mounted by
    # Singularity should never be used by the linker, see
    # https://github.com/brainvisa/casa-distro/issues/113
    if '/.singularity.d/libs' in (os.environ.get('LD_LIBRARY_PATH', '')
                                  .split(os.pathsep)):
        try:
            libs_list = os.listdir('/.singularity.d/libs')
        except OSError:
            libs_list = []
        if libs_list:
            # if we have set the env variable
            # BV_MAKER_BYPASS_SINGULARITY_LIB_PATH, then bypass the safeguard
            # by removing the singularity paths during configure/build
            if (os.environ.get('BV_MAKER_BYPASS_SINGULARITY_LIB_PATH', '')
                    in ('1', 'TRUE', 'True', 'true')):
                lpath = os.environ.get('LD_LIBRARY_PATH', '').split(os.pathsep)
                lpath.remove('/.singularity.d/libs')
                lpath = os.pathsep.join(lpath)
                os.environ['LD_LIBRARY_PATH'] = lpath
            else:
                sys.stderr.write('''\
    ERROR: The LD_LIBRARY_PATH environment variable contains
    '/.singularity.d/libs', which probably means that you are running
    bv_maker/cmake from within Singularity with binding of the NVidia
    drivers. This has been found to result in broken builds, see
    <https://github.com/brainvisa/casa-distro/issues/113>.

    Please remember to always run configuration and compilation work
    (bv_maker, cmake, or make) without the NVidia driver binding, by
    starting your container:

      - either with 'bv bv_maker',
      - or, by passing the 'opengl=container' option to 'casa_distro run'.
    ''')
                if fatal:
                    sys.exit(1)


class BrainVISAJenkins:
    '''
    Wrapper to access Jenkins server of BrainVISA and push bv_maker results
    '''
    
    job_xml = '''<?xml version='1.1' encoding='UTF-8'?>
    <hudson.model.ExternalJob plugin="external-monitor-job@1.7">
    <description>{description}</description>
    <keepDependencies>false</keepDependencies>
    <properties>
        <hudson.plugins.jira.JiraProjectProperty plugin="jira@3.1.1"/>
        <jenkins.model.BuildDiscarderProperty>
        <strategy class="hudson.tasks.LogRotator">
            <daysToKeep>-1</daysToKeep>
            <numToKeep>20</numToKeep>
            <artifactDaysToKeep>-1</artifactDaysToKeep>
            <artifactNumToKeep>-1</artifactNumToKeep>
        </strategy>
        </jenkins.model.BuildDiscarderProperty>
    </properties>
    </hudson.model.ExternalJob>
    '''

    build_xml = ('<run>'
        '<log encoding="hexBinary">{hex_log}</log>'
        '<result>{result}</result>'
        '<duration>{duration}</duration>'
        '<displayName>{build}</displayName>'
        '<description>{description}</description>'
        '</run>')

    def __init__(self, server, login, password):
        '''
        server = URL of the Jenkins server
        login = username to use for Jenkins authentication
        password = password or token for authentication
        '''
        self.server = server
        self.login = login
        self.password = password
    
    def get(self, route, **kwargs):
        return requests.get('{0}/{1}'.format(self.server, route),
                            auth=(self.login, self.password),
                            **kwargs)

    def post(self, route, **kwargs):
        return requests.post('{0}/{1}'.format(self.server, route),
                             auth=(self.login, self.password),
                             **kwargs)

    def delete(self, route, **kwargs):
        return requests.delete('{0}/{1}'.format(self.server, route),
                               auth=(self.login, self.password),
                               **kwargs)
    
    def job_exists(self, environment):
        r = self.get('/job/{0}/api/json'.format(environment))
        if r.status_code == 404:
            return False
        r.raise_for_status()
        return True
    
    def create_job(self, environment, distro, system, branch):
        '''
        Create a jenkins job representing a task performed in a casa_distro 
        environment.The type of the job created is "external task" therefore 
        the corresponding plugin must be installed on the server. The job is
        configured to keep only the 20 last build logs (others are destroyed).
        
        environment : name of the casa_distro environment.
        distro      : distro of casa_distro used for this job
        system      : system of casa_distro used for this job
        branch      : branch of casa_distro used for this job
        '''
        description = '''environment = {0}
        distro = {1}
        system = {2}
        branch = {3}'''.format(environment, distro, system, branch)
        r = self.post('createItem',
            params={'name': environment},
            headers={'Content-Type': 'application/xml'},
            data=self.job_xml.format(description=description))
        r.raise_for_status()
        
    def delete_job(self, job):
        r = self.delete('job/{0}/'.format(job))
        r.raise_for_status()

    def jobs(self):
        r = self.get('api/json')
        r.raise_for_status()
        return [i['name'] for i in r.json()['jobs']]
    
    def create_build(self, environment, task, result,
                     log, duration=None, description=None):
        '''
        Add a build report related

        environment : name of the casa_distro environment.
        task        : name of the task that is performed by this build 
                      (e.g. src, configure, build, etc.)
        result      : integer value representing the result of the build
                      any no zero value means failure
        log         : console output of the build
        duration    : (optional) duration of the build in milliseconds
        description : (optional) description text attached to the build
        '''
        # Python 2 need binascii module to convert str
        # to hex string. In Python 3, bytes have an hex() method.
        hex_log = binascii.hexlify(log.encode())
        r = self.post('job/{0}/postBuildResult'.format(environment),
            headers={'Content-Type': 'application/xml'},
            data=self.build_xml.format(build=task,
                                       hex_log=hex_log,
                                       result=result,
                                       duration=duration or '0',
                                       description=description or ''))
        r.raise_for_status()


ASCII_SUBSTITUTIONS = {
    ord('┌'): '/',
    ord('─'): '-',
    ord('│'): '|',
    ord('✓'): 'v',
    ord('✗'): 'X',
}


def substitute_ascii_error_handler(error):
    """Unicode error handler that replaces a few characters with ASCII.

    Characters not in ASCII_SUBSTITUTIONS are handled by the 'replace' error
    handler (i.e. replaced by '?').
    """
    if isinstance(error, UnicodeEncodeError):
        unencodable = error.object[error.start:error.end]
        substitute = unencodable.translate(ASCII_SUBSTITUTIONS)
        replaced_substitute = substitute.encode(error.encoding, 'replace')
        if six.PY2:
            return (replaced_substitute.decode(error.encoding), error.end)
        return (replaced_substitute, error.end)
    else:
        raise error


codecs.register_error('substitute_ascii', substitute_ascii_error_handler)


def reconfigure_stdout():
    """Reconfigure stdout so it does not crash on foreign Unicode characters.

    Also enable line-buffering, so that the output from print() and
    subprocesses will be interspersed correctly.
    """
    # Python 3.7 and later
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(errors='substitute_ascii', line_buffering=True)
        return

    try:
        fileno = sys.stdout.fileno()
    except (AttributeError, IOError):
        fileno = None

    # Under Python 2 many libraries (e.g. optparse) will try to write
    # strings of type 'str' to stdout, so we need to replace it with an
    # object that handles both unicode and str.
    if six.PY2:
        linebuf_stdout = sys.stdout
        if fileno is not None:
            linebuf_stdout = os.fdopen(fileno, 'w', 1)
        encoding = getattr(sys.stdout, 'encoding', None)
        if encoding is None:
            encoding = locale.getpreferredencoding()
        new_stdout = codecs.getwriter(encoding)(
            linebuf_stdout, errors='substitute_ascii')
    else:
        # Python 3.0 to 3.6
        new_stdout = io.open(fileno, mode='wt', buffering=1,
                             encoding=sys.stdout.encoding,
                             errors='substitute_ascii',
                             closefd=False)
    sys.stdout.flush()
    sys.stdout = new_stdout


reconfigure_stdout()


# This function is copied from the 'six' library, where it was introduced in
# version 1.12.0, because we do not want to depend on such a recent version.
#
# This function is Copyright (c) 2010-2018 Benjamin Peterson, released under
# the Expat licence.
def ensure_str(s, encoding='utf-8', errors='strict'):
    """Coerce *s* to `str`.

    For Python 2:
      - `unicode` -> encoded to `str`
      - `str` -> `str`

    For Python 3:
      - `str` -> `str`
      - `bytes` -> decoded to `str`
    """
    if not isinstance(s, (six.text_type, six.binary_type)):
        raise TypeError("not expecting type '%s'" % type(s))
    if six.PY2 and isinstance(s, six.text_type):
        s = s.encode(encoding, errors)
    elif six.PY3 and isinstance(s, six.binary_type):
        s = s.decode(encoding, errors)
    return s

# This function is copied from the 'six' library, where it was introduced in
# version 1.12.0, because we do not want to depend on such a recent version.
#
# This function is Copyright (c) 2010-2018 Benjamin Peterson, released under
# the Expat licence.
def ensure_text(s, encoding='utf-8', errors='strict'):
    """Coerce *s* to six.text_type.

    For Python 2:
      - `unicode` -> `unicode`
      - `str` -> `unicode`

    For Python 3:
      - `str` -> `str`
      - `bytes` -> decoded to `str`
    """
    if isinstance(s, six.binary_type):
        return s.decode(encoding, errors)
    elif isinstance(s, six.text_type):
        return s
    else:
        raise TypeError("not expecting type '%s'" % type(s))


def get_target_path_system(platform):
    if platform.startswith('win'):
        # We prefer alternative windows path i.e. pathes separated 
        # with slaches instead of back slaches
        return 'windows'
    
    else:
        return 'linux'

def system(*args, **kwargs):
    print('$ ' + ' '.join(shlex_quote(arg) for arg in args))
    error = None
    try:
        try:
            kwargs = dict(kwargs)
            timeout = kwargs.pop('timeout', None)
            if subprocess32 is not None:
                popen = subprocess32.Popen(args, **kwargs)
                popen.communicate(timeout=timeout)
            else:
                # timeout not supported in python2.subprocess
                popen = subprocess.Popen(args, **kwargs)
                popen.communicate()
            if popen.returncode != 0:
                raise OSError()
        except Exception as e:
            error = (type(e), e, sys.exc_info()[2])
    finally:
        if error:
            txt = 'Command failed: %s' % ' '.join((repr(i) for i in args))
            if 'cwd' in kwargs:
                txt = '%s\nFrom directory: %s' % (txt, kwargs['cwd'])
            if error[1].args:
                txt += '\n%s' % error[1].args[0]
            error = (error[0], error[0](txt, *error[1].args[1:]), error[2])
            six.reraise(*error)

def system_output_on_error(*args, **kwargs):
    # system_output_on_error is a bit strange currently:
    # on error an exception is raised and the output value is not passed
    # to the caller. Only stdout is used in this case, when the output
    # strings is actally useful in this situation.
    # However it should be in the exception e.output
    echo = kwargs.pop('echo', True)
    if echo:
        print(' '.join([str(x) for x in args]))
    try:
        if subprocess32 is not None:
            # !!! Redirecting STDERR to STDOUT is a burden on Windows OS and 
            # lead to enormous processing times using "wine" (x80) ... I do not
            # know why.
            # The issue can be reproduced using commands:
            # time python -c 'import subprocess;print subprocess.check_output(["winepath", "-u", "c:\\"]).strip()'
            # time python -c 'import subprocess;print subprocess.check_output(["winepath", "-u", "c:\\"], stderr=subprocess.STDOUT).strip()'
            output = subprocess32.check_output(*args, stderr=subprocess.STDOUT,
                                               **kwargs)
        else:
            if 'timeout' in kwargs:
                # timeout not supported in python2.subprocess
                kwargs = dict(kwargs)
                del kwargs['timeout']
            output = subprocess.check_output(*args, stderr=subprocess.STDOUT,
                                             **kwargs)
    except subprocess.CalledProcessError as e:
        print('-- failed command: --')
        print('-- command:', args)
        print('-- popen kwargs:', kwargs)
        print('-- return code: %d, output: --' % e.returncode)
        print(e.output)
        print('-- end of command outpput --')
        raise

    if sys.version_info[0] >= 3:
        output = output.decode()

    return output

def cmake_path(path):
    if sys.platform == 'win32':
        return Path(path, 'windows').to_system('windows_alt')
    else:
        return path

def copy_brainvisa_cmake(installDir):
    global this_script
    sourceDir = os.path.dirname(os.path.dirname(this_script))
    samefile = getattr(os.path, 'samefile', None)
    if samefile:
        samefile = samefile(sourceDir, installDir)
    else:
        samefile = sourceDir == installDir
    if samefile:
        return
    import brainvisa.maker
    with open(os.path.join(os.path.dirname(brainvisa.maker.__file__),
                           'installed_files.txt')) as installed_f:
        for f in installed_f:
            p, f = os.path.split(f.strip())
            d = os.path.join(installDir, p)
            if not os.path.exists(d):
                os.makedirs(d)
            shutil.copy(os.path.join(sourceDir, p, f), d)


def normalize_path(path):
    file_scheme = 'file://'
    has_file_scheme = path.startswith(file_scheme)
    if has_file_scheme:
        # Remove file scheme
        path = path[len(file_scheme):]
        
    # Try to detect windows pathes starting with drive letters
    # for cross compilation.
    # TODO: check only for cross compiling mode
    if not (len(path) > 1 and path[1] == ':'):
        path = os.path.normpath(os.path.realpath(os.path.abspath(path)))
    
    if has_file_scheme:
        # Add file scheme
        path = file_scheme + path
    
    return path

def get_matching_dirs(directories, pattern):
    dirs = []
    for d in directories:
        if normalize_path(
            d.replace_vars(pattern)) == d.directory:
            dirs.append(d)
            
    return dirs
    
env_vars_regex = re.compile(r'\$([A-Za-z0-9_]*)')
python_vars_regex = re.compile(r'\%\(([A-Za-z0-9_]*)\)s')

def variablesSubstitution(parser, value, vars={}):
    result = value
    offset = 0
    for m in parser.finditer(value):
        content = vars.get(m.group(1))
        if content is not None:
            start, end = m.span()
            start += offset
            end += offset
            offset += len(content) - end + start
            result = result[:start] + content + result[end:]
    return result


def pythonVariablesSubstitution(value, python_vars={}):
    return variablesSubstitution(python_vars_regex, value, vars=python_vars)

def environmentVariablesSubstitution(value, env=None):
    if env is None:
        env = os.environ

    return variablesSubstitution(env_vars_regex, value, vars=env)

def environmentPathVariablesSubstitution(path, env=None):
    return normalize_path(environmentVariablesSubstitution(path, env))

def run_and_log_tests(cwd=None, env=None, options=None, projects=None, timeout=None):
    # get test labels to assign them to projects
    test_labels = system_output_on_error(
        ['ctest', '--print-labels'] + options, echo=False, cwd=cwd)
    lines = test_labels.strip().split('\n')
    if 'All Labels:' in lines:
        labels_index = lines.index('All Labels:')
        labels = [line.strip() for line in lines[labels_index+1:]]
    elif 'No Labels Exist' in lines:
        labels = [] # no tests
    else:
        raise RuntimeError(
            'ctest --print-labels produced an unexpected output:\n'
            + '\n'.join(lines))
    logs = {}

    if timeout is None:
        timeout = configuration.general_section.subprocess_timeout
        
    for label in labels:
        if projects is not None and label not in projects:
            # skip this test, it's not part of the packaging/build config
            continue
        logfile = tempfile.mkstemp(prefix='bv_test_%s' % label, suffix='.log')
        os.close(logfile[0])
        start_time = time.localtime()
        try:
            system(cwd=cwd, 
                   env=env,
                   timeout = timeout,
                  *(['ctest', '-L', '^%s$' % label, '--output-on-failure',
                     '-O', logfile[1]] + options))
        except Exception as e:
            logitem = {}
            logitem['log_file'] = logfile[1]
            logitem['exception'] = e
            logitem['start_time'] = start_time
            logitem['stop_time'] = time.localtime()
            logs[label] = logitem
        else:
            logitem = {}
            logitem['log_file'] = logfile[1]
            logitem['exception'] = None
            logitem['start_time'] = start_time
            logitem['stop_time'] = time.localtime()
            logs[label] = logitem
            #os.unlink(logfile[1])
        # FIXME DEBUG
        with open(logfile[1], 'a') as f:
            print('-------------------------------------', file=f)
            print('projects to test: %s' % repr(projects), file=f)
            print('labels to test: %s' % repr(labels), file=f)
            print('current label: %s' % label, file=f)
    return logs


def run_and_log_testref(cwd=None, env=None, options=None, timeout = None):
    logs = {}

    if timeout is None:
        timeout = configuration.general_section.subprocess_timeout
        
    if ((configuration.general_section.email_notification_by_default. \
            upper() != 'ON' and not configuration.options.email) \
            or (configuration.general_section.failure_email == ''
                and configuration.general_section.success_email == ''
                and configuration.general_section.failure_email_by_project
                    == {})) \
            and (not configuration.general_section.jenkins_server_url
                  or configuration.options.disable_jenkins):
        print_output = True
    else:
        print_output = False
    logfile = tempfile.mkstemp(prefix='bv_testref', suffix='.log')
    os.close(logfile[0])
    start_time = time.localtime()
    try:
        output = system_output_on_error(['make'] + options + ['testref'],
                                        cwd=cwd, env=env, 
                                        timeout = timeout)
    except Exception as e:
        if hasattr(e, 'output'):
            with open(logfile[1], 'w') as f:
                f.write(e.output)
            if print_output:
                print(e.output)
        logitem = {}
        logitem['log_file'] = logfile[1]
        logitem['exception'] = e
        logitem['start_time'] = start_time
        logitem['stop_time'] = time.localtime()
        logs['testref'] = logitem
    else:
        with open(logfile[1], 'w') as f:
            f.write(output)
        logitem = {}
        logitem['log_file'] = logfile[1]
        logitem['exception'] = None
        logitem['start_time'] = start_time
        logitem['stop_time'] = time.localtime()
        logs['testref'] = logitem
        #os.unlink(logfile[1])
        if print_output:
            print(output)
    return logs


class GlobalConfiguration(object):

    def __init__(self, argv):
        usage = '''%prog [options] [ command [command options] ]...

This program is for the management of source retrieval, configuration and compilation of BrainVISA projects.

In order to work, the commands svn and svnadmin must be installed on your system. On some Linux systems they are in two separate packages (e.g. subversion and subversion-tools).

Commands:

* info: Just output info about configured components.
* sources: Create or updated selected sources directories from Subversion
  repository.
* status: Display a summary of the status of all source repositories.
* configure: Create and configure selected build directories with CMake.
* build: compile all selected build directories.
* doc: Generate documentation (sphinx, doxygen, docbook, epydoc).
* testref: Execute tests in a special mode to generate machine-specific
  reference files (this is needed by some tests).
* test: Execute tests using ctest.
* pack: Generate binary packages.
* install_pack: Install binary packages.
* testref_pack: Create the machine-specific reference files for tests in
  installed binary package.
* test_pack: Run tests in installed binary packages.
* publish_pack: Publish binary packages.

To get help for a specific command, use -h option of the command. Example: "%prog build -h".

To get help on how to configure and write a bv_maker configuration file, see:

http://brainvisa.info/brainvisa-cmake/compile_existing.html

config file syntax:

http://brainvisa.info/brainvisa-cmake/configuration.html

and more generally:

http://brainvisa.info/brainvisa-cmake/
'''
        defaultConfigurationFile = os.environ.get('BRAINVISA_BVMAKER_CFG')
        if defaultConfigurationFile is None:
            defaultConfigurationFile = os.path.join(
                os.environ['USERPROFILE' if sys.platform.startswith('win') 
                           else 'HOME'], '.brainvisa', 'bv_maker.cfg')
        parser = OptionParser(usage=usage)
        
        parser.add_option('-d', '--directory', dest='directories',
                          help='Restrict actions to a selected directory. May be used several times to process several directories.',
                          metavar='DIR', action='append', default=[])
        parser.add_option('-c', '--config', dest='configuration_file',
                          help='specify configuration file. Default ="' +
                          defaultConfigurationFile + '"',
                          metavar='CONFIG', default=None)
        parser.add_option('-s', '--sources', dest='sources_directories',
                          help='directory containing sources',
                          metavar='DIR', action='append', default=[])
        parser.add_option('-b', '--build', dest='build_directory',
                          help='build directory',
                          metavar='DIR', default=None)
        parser.add_option('--username', dest='username',
                          help='specify user login to use with the svn server',
                          metavar='USERNAME', default='')
        parser.add_option('-e', '--email', action='store_true',
                          help='Use email notification (if configured in the '
                          'general section of the configuration file)')
        parser.add_option('--disable-jenkins', action='store_true',
                          dest='disable_jenkins', default=False,
                          help='disable Jenkins server logging')
        parser.add_option('--def', '--only-if-default', action='store_true',
                          dest='in_config', default=False,
                          help='apply only steps which are defined as default '
                          'steps in the bv_maker.cfg config file. Equivalent '
                          'to passing --only-if-default to every substep '
                          'which supports it.')
        parser.add_option(
            '-v', '--verbose', dest='verbose', action='store_true',
            help='show as much information as possible')
        parser.add_option(
            '--version', dest='version', action='store_true',
            help='show bv_maker (brainvisa-cmake) version number')

        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])

        if options.version:
            print('bv_maker version:', brainvisa_cmake_version)
            sys.exit(0)

        packages = []
        
        self.sourcesDirectories = {}
        self.buildDirectories = {}
        self.packageDirectories = {}
        self.publicationDirectories = {}
        self.general_section = GeneralSection(self)

        self.directories = options.directories

        for i in ('configuration_file', 'username', 'verbose'):
            setattr(self, i, getattr(options, i))

        bd = None  # build directory supplied on the command-line
        if options.build_directory:
            if not options.configuration_file:
                cf = os.path.join(options.build_directory, 'bv_maker.cfg')
                if os.path.exists(cf):
                    options.configuration_file = cf
                else:
                    options.configuration_file = defaultConfigurationFile
            os.environ['BV_MAKER_BUILD'] = options.build_directory
            reload_module(brainvisa.maker.components_definition)
            reload_module(brainvisa_projects)

            bd = BuildDirectory(options.build_directory, self)

            for sd in options.sources_directories:
                if os.path.exists(os.path.join(sd, 'project_info.cmake')) \
                    or glob.glob(os.path.join(sd, 'python', '*', 'info.py')) \
                    or glob.glob(os.path.join(sd, '*', 'info.py')):
                    bd.addConfigurationLine('directory ' + sd)
                else:
                    bd.addConfigurationLine('brainvisa all * ' + sd)
        elif not options.configuration_file:
            options.configuration_file = defaultConfigurationFile

        if options.configuration_file \
                and os.path.exists(options.configuration_file):
            with open(options.configuration_file, 'rb') as f:
                self.parse_config_file(f, options, extra_build_dir=bd)

        if options.verbose:
            print('variables initialized')

        # store options and args
        self.options = options
        self.args = args


    def parse_config_file(self, f, options, extra_build_dir=None):
        """Read configuration from an file object (opened in binary mode)."""
        lineCount = 0
        currentDirectoryObject = None

        source_dirs = []
        build_dirs = [extra_build_dir] if extra_build_dir else []
        package_dirs = []
        publication_dirs = []

        condition_stack = []

        for line in f:
            lineCount += 1
            line = line.strip()
            try:
                line = line.decode()
            except UnicodeError:
                line = line.decode('utf-8')
            # skip comments
            if not line or line[0] == '#' or line.startswith('//'):
                continue
            try:
                if line[0] == '[':
                    if line[-1] != ']':
                        raise SyntaxError()
                    l = line[1:-1].split(None, 1)
                    if len(l) != 2 and l[0] not in ('if', 'endif', 'else', 
                                                    'general'):
                        raise SyntaxError()

                    if l[0] == 'if' \
                            and currentDirectoryObject is not None \
                            and len(l) >= 2:
                        if len(condition_stack) != 0 \
                                and condition_stack[-1] is False:
                            # if an upstream condition is already false,
                            # all the subtree is false (but we still have
                            # to parse it to count if/endif/else
                            # occurrences in it)
                            condition_stack.append(False)
                        else:
                            try:
                                condition_stack.append(
                                    check_filter_condition(l[1:]))
                            except Exception:
                                print('error in condition, line %d:'
                                      % lineCount, file=sys.stderr)
                                print(line, file=sys.stderr)
                                raise
                    elif l[0] == 'endif' and len(l) == 1:
                        if len(condition_stack) > 0:
                            # ends the filtered section
                            condition_stack.pop()
                        else:
                            SyntaxError('[endif] clause is not preceded '
                                        'by [if] clause.')
                    elif l[0] == 'else' and len(l) == 1:
                        if len(condition_stack) > 0:
                            # inverts the filtered section, only if its
                            # parent condition is True
                            if len(condition_stack) == 1 \
                                    or condition_stack[-2]:
                                condition_stack[-1] \
                                    = not condition_stack[-1]
                        else:
                            SyntaxError('[else] clause is not preceded by '
                                        '[if] clause.')
                    elif len(condition_stack) == 0 \
                        or False not in condition_stack:
                        if self.verbose:
                            print('  processing line %s:' % str(lineCount),
                                  repr(line))
                            sys.stdout.flush()

                        if l[0] == 'source':
                            currentDirectoryObject = SourceDirectory(
                                l[1].strip(),
                                self)
                            source_dirs.append(currentDirectoryObject)
                        elif l[0] == 'build':
                            currentDirectoryObject = BuildDirectory(
                                l[1].strip(),
                                self)
                            build_dirs.append(currentDirectoryObject)
                        elif l[0] == 'virtualenv':
                            currentDirectoryObject = VirtualenvDirectory(
                                l[1].strip(),
                                self)
                            build_dirs.append(currentDirectoryObject)
                        elif l[0] == 'package':
                            currentDirectoryObject = PackageDirectory(
                                l[1].strip(),
                                self)
                            package_dirs.append(currentDirectoryObject)
                        elif l[0] == 'package_publication':
                            currentDirectoryObject = PublicationDirectory(
                                l[1].strip(),
                                self)
                            publication_dirs.append(currentDirectoryObject)
                        elif l[0] == 'general' and len(l) == 1:
                            currentDirectoryObject = self.general_section
                        else:
                            raise SyntaxError()

                elif len(condition_stack) == 0 \
                    or False not in condition_stack:
                    if currentDirectoryObject is None:
                        raise SyntaxError()
                    if self.verbose:
                        print('  processing line %s:' % str(lineCount),
                              repr(line))
                        sys.stdout.flush()

                    currentDirectoryObject.addConfigurationLine(line)
            except SyntaxError as e:
                # FIXME: SyntaxError should be reserved for Python syntax
                # errors, use a custom exception instead
                msg = e.message
                if msg == '':
                    msg = 'Syntax error'
                raise SyntaxError('%s in ' % msg + repr(
                    options.configuration_file) + ' on line '
                    + str(lineCount))

        if len(condition_stack) > 0:
            RuntimeError('some [if] clause remain unclosed by [endif].')

        if options.verbose:
            print('configuration file %s parsed'
                % repr(options.configuration_file))

        for r, sections in ((None, [self.general_section]), \
                            ('sourcesDirectories', source_dirs), \
                            ('buildDirectories', build_dirs), \
                            ('packageDirectories', package_dirs), \
                            ('publicationDirectories', publication_dirs)):
            for s in sections:
                # Variable initialization is done after parsing of sections
                # because it may depend on the complete parsing of other
                # sections
                if not hasattr(s, '_initialized') or not s._initialized:
                    s.init_vars()

                    registry = getattr(self, r, None) if r else None
                    if registry is not None:
                        # Register section
                        registry[s.directory] = s

                    if isinstance(s, SourceDirectory):
                        # Parses source configuration
                        s.parseSourceConfiguration()

                if options.verbose:
                    print(getattr(s, 'directory', 'general'), 'options:')
                    for o in s._validOptions:
                        print(' ', o, '=', getattr(s, o, None))


def check_filter_condition(filters):
    # for now, use python eval()
    expression = ' '.join(filters)
    # replace %(var)s vars
    vars = global_installer_variables()
    expression = expression % vars
    try:
        res = bool(eval(expression))
    except Exception:
        traceback.print_exc()
        raise
    return res


_installer_datetime = None
_installer_variables = None

def get_standard_arch(arch = platform.architecture()[0]):
    return 64 if arch in ['64', '64bit', 'x86_64'] else 32
    
def get_host_system_name():
    systems = {'darwin' : 'osx', 
               'windows': 'win'}
    system = platform.system()
    osname = system.lower()
    osname = systems.get(osname, osname)
    
    if osname in ('linux', 'win'):
        # Append architecture
        arch = platform.architecture()[0]
        osname += str(get_standard_arch(arch))

    return osname

def get_host_libc_version():
    # determine libc version - using ctypes and calling C
    # gnu_get_libc_version() function
    # Note: plaform.libc_ver() is completely bogus.
    import ctypes
    libc = ctypes.cdll.LoadLibrary("libc.so.6")
    gnu_get_libc_version = libc.gnu_get_libc_version
    gnu_get_libc_version.restype = ctypes.c_char_p
    
    ver = gnu_get_libc_version()
    if sys.version_info[0] >= 3:
        # in python3, ver is a bytes, not a str
        ver = ver.decode()
    return ver.split('.')

def get_pack_host_system_name():
    '''
        Get system name to use for packaging.
        Because linux compatibility for packs depends on libc version, the
        libc version is integrated to the system name.
        On Mac, the version of OSX is also appended.
    '''
    pack_system = get_host_system_name()
    if pack_system.startswith('linux'):
        libc_version = get_host_libc_version()
        pack_system += '-glibc-'+ '.'.join(libc_version[:2])  
    elif pack_system.startswith('osx'):
        pack_system += '-' + '.'.join(platform.mac_ver()[0].split('.')[:2])

    return pack_system


def installer_parse_date(value):
    return datetime.datetime.strptime(value, '%Y_%m_%d').timetuple()[:3]

def installer_parse_time(value):
    return datetime.datetime.strptime(value, '%H:%M:%S').timetuple()[3:6]

def installer_format_date(date):
    return '%04d_%02d_%02d' % date
    
def installer_format_time(time):
    return '%02d:%02d:%02d' % time

def global_installer_datetime():
    global _installer_datetime
    if _installer_datetime is not None:
        return _installer_datetime
      
    plt = time.localtime()
    p_date = installer_format_date(plt[:3])
    p_time = installer_format_time(plt[3:6])

    _installer_datetime = {'date': p_date, 'time': p_time}
                            
    return _installer_datetime
    
def global_installer_variables():
    global _installer_variables
    if _installer_variables is not None:
        return _installer_variables

    pack_host_system = get_pack_host_system_name()
 
    _installer_variables = {'os': pack_host_system,
                            'hostname': gethostname().split('.')[0]}
    return _installer_variables



class StepCommand(object):
    
    def __init__(self, argv, configuration):
        # Initialize python variables that can override directories
        # python variables
        super(StepCommand, self).__init__()
        self.python_vars = {}

    def process(self, step, directories_list, method, *meth_args,
                **meth_kwargs):
        for o in directories_list:
            # Update directory python variables by those coming from the command
            # line (package date and version)
            o.update_python_vars(self.python_vars)
            # Python variables update need to reprocess environment variables
            o.reset_environ()
            
            # Get the new directory value
            d = o.directory
            normalize_path_needed = 'directory' in \
                getattr(o, '_path_variables', set())
            
            # Resolve directories pattern using configuration directory 
            # variables
            conf_dirs = [normalize_path(o.replace_vars(c)) \
                         if normalize_path_needed else o.replace_vars(c) \
                         for c in configuration.directories] \
                        if configuration.directories else []
                        
            if (not conf_dirs or d in conf_dirs) and o.conditional_build():
                if (not self.options.in_config
                    and not configuration.options.in_config) \
                        or step in o.default_steps:
                    if o.has_satisfied_dependencies(step):
                        self.redirect_stdout(d, o, step)
                        logs = None
                        try:
                            logs = getattr(o, method)(*meth_args,
                                                      **meth_kwargs)
                            if not logs:
                                o.status[step] = 'succeeded' # mark as done
                        except KeyboardInterrupt:
                            # record failure
                            o.status[step] = 'interrupted'
                            o.stop_time[step] = time.localtime()
                            # user interruptions should stop all.
                            raise
                        except Exception:
                            traceback.print_exc()
                            # record failure
                            o.status[step] = 'failed'
                        if logs:
                            if logs == IGNORED_STEP:
                                # step did nothing and should be ignored
                                o.status[step] = 'not run'
                                self.release_stdout(o)
                                continue
                            o.stop_time[step] = time.localtime()
                            o.status[step] = 'succeeded'
                            for label, item in six.iteritems(logs):
                                log = item['log_file']
                                exc = item['exception']
                                full_step = '%s:%s' % (step, label)
                                o.start_time[full_step] = item['start_time']
                                o.stop_time[full_step] = item['stop_time']
                                if exc is None:
                                    o.status[full_step] = 'succeeded'
                                elif isinstance(exc, KeyboardInterrupt):
                                    o.status[full_step] = 'interrupted'
                                    if o.status[step] != 'failed':
                                        o.status[step] = 'interrupted'
                                else:
                                    o.status[full_step] = 'failed'
                                    o.status[step] = 'failed'
                                self.release_notify_log(d, o, step, label, log,
                                                        exc)
                        else:
                            self.release_notify_stdout(d, o, step)
                    else:
                        print('Skipping', step, 'of', d,
                              'because it depends on a step that failed.')
            elif configuration.verbose:
                print('Skipping', step, 'of', d,
                      'because it is not in the selected directories.')


    def redirect_stdout(self, d, o, step):
        o.start_time[step] = time.localtime()
        if configuration.general_section is None:
            return
        if ((configuration.general_section.email_notification_by_default. \
                upper() != 'ON' and not configuration.options.email) \
                or (configuration.general_section.failure_email == ''
                    and configuration.general_section.success_email == ''
                    and configuration.general_section.failure_email_by_project
                        == {})) \
                and (not configuration.general_section.jenkins_server_url
                     or configuration.options.disable_jenkins):
            return
        if o.stdout_file or o.stderr_file:
            # Line buffering is used (buffering=1) because the output from
            # bv_maker needs to be interspersed correctly with the output of
            # external commands called through subprocess.
            if o.stdout_file:
                self.tmp_stdout = open(o.stdout_file, 'w', buffering=1)
                if o.stderr_file:
                    self.tmp_stderr = open(o.stderr_file, 'w', buffering=1)
                else:
                    self.tmp_stderr = self.tmp_stdout
            else:
                self.tmp_stdout = open(o.stderr_file, 'w', buffering=1)
                self.tmp_stderr = self.tmp_stdout
        else:
            tmp_stdout = tempfile.mkstemp(prefix='buildout_')
            os.close(tmp_stdout[0])
            print('redirecting outputs to temporary file:', tmp_stdout[1])
            sys.stdout.flush()
            sys.stderr.flush()
            self.tmp_stdout = open(tmp_stdout[1], 'w', buffering=1)
            self.tmp_stderr = self.tmp_stdout
        self.orig_stdout = os.dup(sys.stdout.fileno())
        self.orig_stderr = os.dup(sys.stderr.fileno())
        os.dup2(self.tmp_stdout.fileno(), 1)
        os.dup2(self.tmp_stderr.fileno(), 2)

    def release_notify_stdout(self, d, o, step):
        o.stop_time[step] = time.localtime()
        fix_stdout = False
        if hasattr(self, 'orig_stdout'):
            fix_stdout = True
            os.dup2(self.orig_stdout, 1)
            os.dup2(self.orig_stderr, 2)
            self.tmp_stdout.close()
            if self.tmp_stderr is not self.tmp_stdout:
                self.tmp_stderr.close()
        self.notify_log(d, o, step)
        if fix_stdout:
            del self.orig_stderr
            del self.orig_stdout
            if not o.stdout_file:
                os.unlink(self.tmp_stdout.name)
            # tmp_stderr is never removed: either it is specified as a
            # persistant file or it is tmp_stdout.
            del self.tmp_stdout
            del self.tmp_stderr

    def release_stdout(self, o):
        if not hasattr(self, 'orig_stdout'):
            return
        os.dup2(self.orig_stdout, 1)
        os.dup2(self.orig_stderr, 2)
        self.tmp_stdout.close()
        if self.tmp_stderr is not self.tmp_stdout:
            self.tmp_stderr.close()
        del self.orig_stderr
        del self.orig_stdout
        if not o.stdout_file:
            os.unlink(self.tmp_stdout.name)
        # tmp_stderr is never removed: either it is specified as a persistant
        # file or it is tmp_stdout.
        del self.tmp_stdout
        del self.tmp_stderr

    def release_notify_log(self, d, o, step, label, log, exc):
        self.release_stdout(o)
        self.tmp_stdout = open(log)
        self.tmp_stdout.close()
        self.tmp_stderr = self.tmp_stdout
        full_step = '%s:%s' % (step, label)
        if exc is None:
            o.status[full_step] = 'succeeded'
        elif isinstance(exc, KeyboardInterrupt):
            o.status[full_step] = 'interrupted'
        else:
            o.status[full_step] = 'failed'
        self.notify_log(d, o, full_step)
        del self.tmp_stdout
        os.unlink(log)

    def notify_log(self, d, o, step):
        status =  o.status.get(step, 'not run')
        # global log file notification
        self.log_in_global_log_file(d, o, step, status)
        # email notification
        email = ''
        if configuration.general_section.email_notification_by_default.upper() \
                == 'ON' or configuration.options.email:
            if status in ('failed', 'interrupted'):
                email = configuration.general_section.failure_email
                if configuration.general_section.failure_email_by_project:
                    project = step.split(':')[-1]
                    if project in  configuration.general_section. \
                            failure_email_by_project:
                        email = configuration.general_section. \
                            failure_email_by_project[project]
            elif status == 'succeeded':
                email = configuration.general_section.success_email
        if email:
            try:
                self.send_log_email(email, d, o, step, status)
            except Exception as e:
                print('WARNING: notification email could not be sent:',
                      e.message)
                traceback.print_exc()
        # Jenkins notification
        self.jenkins_notification(d, o, step, status)
        # console notification
        if email and status in ('failed', 'interrupted'):
            # original stdout has been changed, we need to print again
            print(self.message_header(d, o, step, status))
            print(self.log_message_content())

    def message_header(self, d, o, step, status):
        real_dir = o.replace_vars(d)
        dlen = max((len(step), len(status), len(real_dir)))
        if hasattr(o, 'get_environ'):
            env = o.get_environ()
        else:
            env = os.environ
        start_time = '%04d/%02d/%02d %02d:%02d' % o.start_time[step][:5]
        stop_time = '%04d/%02d/%02d %02d:%02d' % o.stop_time[step][:5]
        message = '''\
=========================================
== directory: %s%s ==
== step:      %s%s ==
== status:    %s%s ==
== started:   %s%s ==
== stopped:   %s%s ==
=========================================

--- environment: ---
''' % (real_dir, ' ' * (dlen - len(real_dir)),
            step, ' ' * (dlen - len(step)),
            status, ' ' * (dlen - len(status)),
            start_time, ' ' * (dlen - len(start_time)),
            stop_time, ' ' * (dlen - len(stop_time)))
        message += '\n'.join(['%s=%s' % (var, env[var])
                              for var in sorted(env.keys())])
        message += '\n------------------------------------------\n\n'

        return message

    def send_log_email(self, email, d, o, step, status):
        if configuration.general_section.from_email == '':
            from_address = '%s-%s@intra.cea.fr' \
                % (os.getenv('USER'), gethostname())
        else:
            from_address = configuration.general_section.from_email
        if configuration.general_section.reply_to_email == '':
            reply_to_address = 'appli@saxifrage.saclay.cea.fr'
        else:
            reply_to_address = configuration.general_section.reply_to_email
        to_address = email

        # header
        machine = gethostname()
        osname = global_installer_variables()['os']
        Status = status[0].upper() + status[1:]
        message = '''MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset="utf-8"
Reply-To: %s
Subject: %s - %s %s on %s (%s)

%s - build started %s, stopped %s on %s (%s)

''' % (reply_to_address, Status, step,
            '%04d/%02d/%02d' % o.start_time[step][:3],
            machine, osname, Status,
            '%04d/%02d/%02d %02d:%02d' % o.start_time[step][:5],
            '%04d/%02d/%02d %02d:%02d' % o.stop_time[step][:5], machine,
            osname)

        message += self.message_header(d, o, step, status)
        message += self.log_message_content()

        # Normalize all end-of-lines to use CRLF as required in Internet
        # messages (taken from smtplib).
        message = re.sub(r'(?:\r\n|\n|\r(?!\n))', '\r\n', message)

        if configuration.general_section.smtp_server != '':
            smtp_server = configuration.general_section.smtp_server
        else:
            smtp_server = 'mx.intra.cea.fr'
        server = SMTP(smtp_server)
        server.sendmail(from_address, to_address, message.encode('utf-8'))
        server.quit()

    def log_message_content(self):
        if self.tmp_stderr is not self.tmp_stdout:
            message = '====== standard output ======\n\n'
        else:
            message = '====== output ======\n\n'
        # Read message from file
        with io.open(self.tmp_stdout.name, mode='rt', errors='replace',
                     newline='') as file:
            message += file.read()
        if self.tmp_stderr is not self.tmp_stdout:
            message += '====== standard error ======\n\n'
            with io.open(self.tmp_stderr.name, mode='rt', errors='replace',
                         newline='') as file:
                message += file.read()
        return message

    def log_in_global_log_file(self, d, o, step, status):
        # print('log_in_global_log_file', step, status)
        if status == 'not run':
            return # don't log non-running steps
        log_file = None
        if configuration.general_section \
                and configuration.general_section.global_status_file:
            log_file = configuration.general_section.global_status_file
        if not log_file:
            return

        status = status.upper()
        if status == 'SUCCEEDED':
            status = 'OK' # we used OK, so let's go on
        machine = gethostname()
        osname = global_installer_variables()['os']

        message = '%s step %s: %s' % (status, step, d)
        start = o.start_time.get(step)
        if start:
            message += ', started: %04d/%02d/%02d %02d:%02d' \
                % start[:5]
        stop = o.stop_time.get(step)
        if stop:
            message += ', stopped: %04d/%02d/%02d %02d:%02d' \
                % stop[:5]
        with open(log_file, 'a') as f:
            f.write('%s on %s (%s)\n' % (message, machine, osname))

    def jenkins_notification(self, d, o, step, status):
        ''' Notify job execution (build, test etc) to a Jenkins server
        '''
        global jenkins_server, casa_environment
        
        if not configuration.general_section.jenkins_server_url \
                or configuration.options.disable_jenkins:
            return # don't notify
        
        if o.status[step] not in ('interrupted', 'failed'):
            result = 0
        else:
            result = 1
        
        log = (self.message_header(d, o, step, status) +
               self.log_message_content())
        jenkins_server.create_build(environment=casa_environment,
            task=step,
            result=result,
            log=log)


class InfoCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] info [options]

    Display information about configuration, sources directories and build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(InfoCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        print('Configuration file:', configuration.configuration_file)
        dirs = dict(configuration.sourcesDirectories)
        dirs.update(configuration.buildDirectories)
        dirs.update(configuration.packageDirectories)
        dirs.update(configuration.publicationDirectories)
        self.process('info', list(dirs.values()), 'info')


class SourcesCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] sources [options]

    Create or updated selected sources directories from Subversion repository.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--no-cleanup', dest='cleanup', action='store_false',
                          default=True,
                          help='don\'t cleanup svn sources')
        parser.add_option('--no-svn', dest='svn', action='store_false',
                          default=True,
                          help='don\'t update svn sources')
        parser.add_option('--no-git', dest='git', action='store_false',
                          default=True,
                          help='don\'t update git sources')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        parser.add_option('--ignore-git-failure', dest='ignore_git_failure',
                          action='store_true', default=False,
                          help='ignore git update failures, useful when '
                          'working on a feature branch')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(SourcesCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('sources', list(configuration.sourcesDirectories.values()),
                     'process', self.options, self.args)


class SourceStatusCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] status [options]

    Display a summary of the status of all source repositories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--no-svn', dest='svn', action='store_false',
                          default=True,
                          help="don't display the status of svn sources")
        parser.add_option('--no-git', dest='git', action='store_false',
                          default=True,
                          help="don't display the status of git sources")
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])

        super(SourceStatusCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('status',
                     list(configuration.sourcesDirectories.values()),
                     'source_status', self.options, self.args)


class ConfigureCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] configure [options]

    Create or updated selected build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('-c', '--clean', dest='clean', action='store_true',
                          default=False,
                          help='clean build tree (using bv_clean_build_tree '
                          '-d) before configuring')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(ConfigureCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('configure', list(configuration.buildDirectories.values()),
                     'configure', self.options, self.args)

class BuildCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] configure [options]

    Compile selected build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('-c', '--clean', dest='clean', action='store_true',
                          default=False,
                          help='clean build tree (using '
                          'bv_clean_build_tree -b) before building')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(BuildCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('build', list(configuration.buildDirectories.values()),
                     'build', self.options, self.args)


class DocCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] doc [options]

    Generate documentation (docbook, epydoc, doxygen).'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(DocCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('doc', list(configuration.buildDirectories.values()), 'doc')


class TestCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] test

    Executes ctest.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        parser.add_option('-t', '--ctest_options',
                          default=None,
                          help='options passed to ctest (ex: "-VV -R carto*"). '
                          'Same as the configuration option ctest_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('test', list(configuration.buildDirectories.values()), 'test',
                     self.options, self.args)


class TestrefCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] testref

    Executes tests in the testref mode (used to generate reference files).'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestrefCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('testref', list(configuration.buildDirectories.values()), 'testref',
                     self.options, self.args)


class PackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] pack [options]

    Make installer package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(PackCommand, self).__init__(argv, configuration)
        self.python_vars = dict(global_installer_datetime())
        self.options = options
        self.args = args

    def __call__(self):
        # First, we need to order packages to manage dependencies between 
        # them (especially for offline installer that refer to data package, 
        # because in this case, it is necessary to update data package  
        # repository before software package has been packaged)
        def __getPackageDirectoriesByDepth():
            def __getDepth(package_dir):
                data_dir = package_dir.get_data_dir()
                if not data_dir:
                    return 0
                else:
                    return __getDepth(data_dir) + 1
                
            dirs=[]
            for o in configuration.packageDirectories.values():
                dirs.append((__getDepth(o), o))
            
            #print([(o, d.directory) for o, d in sorted(dirs)])
            return [d for o, d in sorted(dirs, key=lambda x: x[0])]
        
        self.process('pack', __getPackageDirectoriesByDepth(),
                     'package', self.options, self.args)


class InstallPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] install_pack [options]

    Install a binary package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--prefix', dest='prefix',
                          default=None,
                          help='sets the prefix directory to install the pack.')
        parser.add_option('--local', dest='local',
                          action='store_true',
                          default=False,
                          help='True if the installation must be done ' \
                               'locally. Default is False.')
        parser.add_option('--offline', dest='offline',
                          action='store_true',
                          default=False,
                          help='True if the installation must be done using ' \
                               'offline installer. Default is False.')
        parser.add_option('--debug', dest='debug',
                          action='store_true',
                          default=False,
                          help='True if the installation must be done in debug ' \
                               'mode (i.e. generated files must not be deleted). ' \
                               'Default is False.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(InstallPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('install_pack', list(configuration.packageDirectories.values()),
                     'install_package', self.options, self.args)


class TestPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] test_pack [options]

    Test in installed package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-t', '--ctest_options',
                          default=None,
                          help='options passed to ctest (ex: "-VV -R carto*"). '
                          'Same as the configuration option ctest_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('test_pack', list(configuration.packageDirectories.values()),
                     'test_package', self.options, self.args)


class TestrefPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] testref_pack [options]

    Create test reference files in installed package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestrefPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('testref_pack', list(configuration.packageDirectories.values()),
                     'testref_package', self.options, self.args)


class PublishPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] publish [options]

    Run command to publish package for the selected publication directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(PublishPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('publish_pack', list(configuration.publicationDirectories.values()),
                     'publish_package', self.options, self.args)

class VarReplacementType:
    NO = 0
    PYTHON = 1
    ENV = 2
    ALL = PYTHON | ENV
        
def replace_vars(value, 
                 replacement_type=VarReplacementType.ALL,
                 python_vars=None,
                 env_vars=None):
    result = value

    if python_vars and (replacement_type & VarReplacementType.PYTHON):
        # Uses python variable substitutions to allow partial replacements
        #print('replace_vars, replace_python_vars call', value, replacement_type)
        #result = result % python_vars
        result = pythonVariablesSubstitution(result, python_vars=python_vars)

    if env_vars and (replacement_type & VarReplacementType.ENV):
        #print('replace_vars, replace_env_vars call', value, replacement_type)
        # Replaces only environment variables
        result = environmentVariablesSubstitution(result, env = env_vars)

    return result
    
class ConfigVariableParser(object):

    _validOptions = set()
    _validAdditiveOptions = set()
    _path_variables = set()
    _variables_with_replacements = set()
    _variables_with_env_only_replacements = set()
    _variables_with_python_only_replacements = set()

    def __new__(cls, *args):
        # Initialize the class properties
        for prop in cls._validOptions.union(cls._validAdditiveOptions):
            cls.property_init(prop)
            
        return super(ConfigVariableParser, cls).__new__(cls)
        
    def __init__(self, *args):
        super(ConfigVariableParser, self).__init__(*args)
        
        self._property_info = {}
        self._property_recursivity = {}
        for prop in self._validOptions.union(self._validAdditiveOptions):
            self._property_info[prop] = \
                (self.get_replacement_type(prop), 
                 self.is_path(prop))
                
    @classmethod
    def property_init(cls, name, doc = None):
        from functools import partial
        
        # Declare option as a property
        setattr(cls, name, 
                property(partial(getattr(cls, '_property_get'), name),
                         partial(getattr(cls, '_property_set'), name),
                         partial(getattr(cls, '_property_del'), name),
                         doc if doc else 'property ' + name))
    
    @staticmethod
    def _property_has(name, config_parser):
        return name in config_parser._property_info
        
    @staticmethod            
    def _property_set(name, config_parser, value):
        setattr(config_parser, '_' + name, value)
        #print('val_type is', type(v), 'for value:', value)

    @staticmethod
    def _property_get_origin(name, config_parser):
        getattr(config_parser, '_' + name)
        
    @staticmethod
    def _property_get(name, config_parser):
        info = config_parser._property_info.get(name, None)
        if info is None:
            raise RuntimeError('Property %s is not declared' % name)
        
        repl_type, is_path = info
        
        def from_config_object(value):
            # Recursively replaces configuration patterns 
            # using ConfigValue object
            if isinstance(value, (list, tuple, set)):
                value = type(value)([from_config_object(v) for v in value])
                
            elif isinstance(value, dict):
                value = dict([(k, from_config_object(v)) \
                              for k, v in six.iteritems(value)])
                
            elif isinstance(value, six.string_types):
                env_vars = config_parser.get_environ()
                python_vars = config_parser.get_python_vars()
                value = replace_vars(value, repl_type, python_vars, env_vars)
                if is_path and value:
                    value = normalize_path(value)
                   
            return value

        value = getattr(config_parser, '_' + name)
        config_parser._property_recursivity[name] = True
        value = from_config_object(value)
        del config_parser._property_recursivity[name]
        
        #print('_property_get', name, value, type(value), repl_type, is_path);sys.stdout.flush()
        return value
    
    @staticmethod
    def _property_del(name, config_parser):   
        delattr(config_parser, '_' + name)
    
    def property_append(self, name, value):
        old_value = getattr(self, '_' + name)
        prop_type = type(old_value)
        
        if prop_type in (dict, set):
            old_value.update(value)
        else:
            old_value += value
        
        setattr(self, name, old_value)
    
    def property_remove(self, name, value):
        old_value = getattr(self, '_' + name)
        prop_type = type(old_value)
        if prop_type is dict:
            for k in value:
                if k in old_value:
                    del old_value[k]
        elif prop_type is set:
            old_value.difference_update(value)
        elif prop_type is list:
            old_value = [x for x in old_value if x not in value]
            setattr(self, name, old_value)
        else:
            try:
                old_value -= value
            except Exception:
                raise SyntaxError()
    
    def get_valid_options(self):
        return self._validOptions
    
    def addConfigurationLine(self, line):
        i = line.find('=')
        if i > 0:
            oper = '' # assign (=) operator by default
            if i > 1 and line[i-1] in ('-', '+'): # operators -=, +=
                oper = line[i-1]
                option = line[:i-1].strip()
                if option not in self._validAdditiveOptions:
                    raise SyntaxError('Option %s does not allow additive '
                                      'assignation (+=, -=)' % option)
            else:
                option = line[:i].strip()
            value = line[i + 1:].strip()
            if option not in self._validOptions:
                raise SyntaxError('Invalid option: %s' % option)
            
            var_type = str
            if hasattr(self, option):
                var_type = type(getattr(self, option))
                if var_type in (list, tuple):
                    value = shlex.split(value)
                elif var_type is dict:
                    if value.startswith('{') and value.endswith('}'):
                        try:
                            value = eval(value)
                        except Exception:
                            raise SyntaxError()
                    else:
                        try:
                            value = eval('{' + value + '}')
                        except Exception:
                            # try simpler syntax without quotes
                            try:
                                value = [x.strip() for x in value.split(',')]
                                value = dict([(x[:x.find(':')],
                                               x[x.find(':') + 1:].strip())
                                    for x in value])
                            except Exception:
                                raise SyntaxError()
            
            if oper == '':
                setattr(self, option, value)
                        
            elif oper == '+':
                self.property_append(option, value)

            elif oper == '-':
                self.property_remove(option, value)
                
            self.validate_option(option)
            return True # parsed
        return False # not parsed

    def validate_option(self, option):
        # by default nothing more is done
        pass

    def is_path(self, var):
        return var in getattr(self, '_path_variables', set())

    def allows_env_replacements(self, var):
        return (self.is_path(var) \
                and var not in getattr(self, 
                                   '_variables_with_python_only_replacements', 
                                   set())) \
            or var in getattr(self, 
                              '_variables_with_env_only_replacements', 
                              set()) \
            or var in getattr(self, 
                              '_variables_with_replacements', 
                              set())

    def allows_python_replacements(self, var):
        return (self.is_path(var) \
                and var not in getattr(self, 
                                   '_variables_with_env_only_replacements', 
                                   set())) \
            or var in getattr(self, 
                              '_variables_with_python_only_replacements', 
                              set()) \
            or var in getattr(self, 
                              '_variables_with_replacements', 
                              set())

    def allows_replacements(self, var):
        return self.allows_python_replacements(var) \
           and self.allows_env_replacements(var)

    def get_replacement_type(self, var):
        if self.allows_replacements(var):
            return VarReplacementType.ALL
        
        elif self.allows_env_replacements(var):
            return VarReplacementType.ENV
        
        elif self.allows_python_replacements(var):
            return VarReplacementType.PYTHON
        
        else:
            return VarReplacementType.NO
        
    def init_vars(self):
        self.__init_python_vars()
        self.__init_environ()
            
    def __init_python_vars(self):
        self._python_vars = dict(global_installer_variables())

    def __init_environ(self):
        self._env_vars = dict(os.environ)

        if not self._property_recursivity.get('env'):
            # Automatically add the env property of the directory 
            # to the environment variables if it exists
            if hasattr(self, 'env'):
                # Add env property content
                self.update_environ(getattr(self, 'env', {}))
        
    def reset_environ(self):
        self.__init_environ()

    def update_python_vars(self, vars):
        '''Update python variable cache for the section'''               
        self._python_vars.update(vars)        

    def update_environ(self, vars):
        '''Update environment variable cache for the section'''
        self._env_vars.update(vars)
        
    def get_python_vars(self):
        return getattr(self, '_python_vars', {})

    def get_environ(self, env = None):
        env_vars = getattr(self, '_env_vars', None)
        if not env_vars:
            return os.environ
            #raise RuntimeError('Environment is not initialized')

        new_env = dict(self._env_vars)
        if env:
            new_env.update(env)
        return new_env

    def replace_vars(self, value, replacement_type=VarReplacementType.ALL):
        return replace_vars(value, replacement_type, 
                            self.get_python_vars(), 
                            self.get_environ())

    def replace_vars_if_allowed(self, var, value, env=None):
        if self.allows_replacements(var):
            return replace_vars(value, VarReplacementType.ALL, 
                                self.get_python_vars(), 
                                self.get_environ())
        
        elif self.allows_env_replacements(var):
            # Replaces only environment variables
           return replace_vars(value, VarReplacementType.ENV,
                               env_vars = self.get_environ())
        elif self.allows_python_replacements(var):
            # Replaces only environment variables
           return replace_vars(value, VarReplacementType.PYTHON,
                               python_vars = self.get_python_vars())
        else:
            return value


class GeneralSection(ConfigVariableParser):
    _variables_with_replacements = \
        set(('directory_id_by_default',
             'jenkins_server_url',
             'subprocess_timeout'))
    _variables_with_env_only_replacements = set(('casa_environment', 'env'))
    _validAdditiveOptions = set(('env', ))
    _path_variables = set(('global_status_file', ))
    _validOptions = set(('failure_email', 'success_email', 'smtp_server',
                         'from_email', 'reply_to_email',
                         'email_notification_by_default',
                         'failure_email_by_project',
                         'casa_environment',
                         'jenkins_username',
                         'jenkins_token'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_variables_with_env_only_replacements)

    def __init__(self, configuration):
        super(GeneralSection, self).__init__()
        
        self.configuration = configuration
        self.configurationLines = []
        self.failure_email = ''
        self.failure_email_by_project = {}
        self.success_email = ''
        self.smtp_server = ''
        self.from_email = ''
        self.reply_to_email = ''
        self.global_status_file = None
        self.email_notification_by_default = 'OFF'
        self.jenkins_server_url = ''
        self.casa_environment = ''
        self.jenkins_global_job_name_step_by_default = ''
        self.jenkins_username = None
        self.jenkins_token = None
        self.subprocess_timeout = default_subprocess_timeout
        self.directory_id_by_default = ''
        self.env = {}

    def addConfigurationLine(self, line):
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            raise SyntaxError()

    def validate_option(self, option):
        if option == 'env':
            # env variables are set immediately
            self.init_vars()

    def init_vars(self):
        super(GeneralSection, self).init_vars()
        # actually add env vars to os.environ
        for var, value in six.iteritems(self._env_vars):
            if var not in os.environ or os.environ[var] != value:
                os.environ[var] = value


class DirectorySection(object):

    def __init__(self):
        super(DirectorySection, self).__init__()
        self.status = {}
        self.start_time = {}
        self.stop_time = {}
        self.depend_on_sections = {}
        self.deps_set = False
        self.build_condition = None
        self.stdout_file = None
        self.stderr_file = None

    def has_failed(self, step):
        return self.status.get(step, 'not run') \
            in ('failed', 'interrupted', 'unmet dependency')

    def has_succeeded(self, step):
        return not self.status.get(step, 'not run') == 'succeeded'

    def get_status(self, step):
        return self.status.get(step, 'not run')

    def has_satisfied_dependencies(self, step):
        if not self.deps_set:
            self.set_dependencies()
            self.deps_set = True

        for dep_sec in self.depend_on_sections.get(step, []):
            dep, dep_step = dep_sec[:2]
            if len(dep_sec) >= 3: # function to test dependency
                if not dep_sec[2](self, dep, dep_step):
                    self.status[step] = 'unmet dependency'
                    return False
            else:
                if dep.has_failed(dep_step):
                    self.status[step] = 'unmet dependency'
                    return False
        return True

    def set_dependencies(self):
        pass

    def conditional_build(self):
        '''Tells if the current directory has actually to be built.
        If a condition option is False, it will not.
        '''
        if not self.build_condition:
            return True
        cond = True
        try:
            cond = eval(self.build_condition)
        except Exception as e:
            print('Directory', self.directory,
                  ': error in parsing build_condition option:',
                  file=sys.stderr)
            print(self.build_condition, file=sys.stderr)
            print('(Condition is evaluated as python expression). Error:',
                  sys.stderr)
            print(e, file=sys.stderr)
            raise
        return cond

    def process_configuration_lines(self):
        pass


class GitUpdateError(Exception):
    """Exception for a non-fatal error updating a Git repository."""
    pass


def cached_property(fget):
    """Create a read-only attribute that caches its value."""
    def cached_getter(self):
        try:
            return self._cache[fget.__name__]
        except KeyError:
            pass
        value = fget(self)
        self._cache[fget.__name__] = value
        return value
    return property(cached_getter, doc=fget.__doc__)


class GitRepository(object):
    """Class for querying and interacting with a Git repository."""
    def __init__(self, source_directory, dest_directory,
                 remote_url=None, remote_ref=None):
        self.source_directory = source_directory
        self.dest_directory = dest_directory
        self.path = os.path.join(source_directory, dest_directory)
        self.remote_url = remote_url
        self.remote_ref = remote_ref
        self._cache = {}

    def invalidate_cache(self, key=None):
        """Invalidate a cached property (all properties if key=None)."""
        if key is None:
            self._cache.clear()
        else:
            try:
                del self._cache[key]
            except KeyError:
                pass

    def call_command(self, args, echo=False, **kwargs):
        """Call a command in the repository, returning its exit code."""
        if echo:
            print('$ ' + ' '.join(shlex_quote(arg) for arg in args))
        return subprocess.call(args, cwd=self.path, **kwargs)

    def call_nonessential_command(self, args, echo=True, **kwargs):
        """Call a command in the repository, ignoring failure."""
        try:
            retcode = self.call_command(args, echo=echo, **kwargs)
        except OSError:
            # "Command not found" scenario
            return
        if echo and retcode != 0:
            print('You can safely ignore errors of the above command')

    @cached_property
    def local_branch(self):
        """Name of the current branch, or None if detached."""
        try:
            head_ref = decode_output(subprocess.check_output(
                ['git', 'symbolic-ref', '--quiet', 'HEAD'],
                cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None
        if head_ref.startswith('refs/heads/'):
            return head_ref[len('refs/heads/'):]

    def sha1_of_rev(self, rev):
        """Obtain the full SHA-1 of the commit identified by rev."""
        try:
            return decode_output(subprocess.check_output(
                ['git', 'rev-parse', '--quiet', '--verify', rev + '^{commit}'],
                cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None

    @cached_property
    def head_short_sha1(self):
        """Shortened SHA-1 identifier of the current HEAD commit."""
        try:
            return decode_output(subprocess.check_output(
                ['git', 'rev-parse', '--quiet', '--verify',
                 '--short', 'HEAD^{commit}'],
                cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None

    @cached_property
    def head_sha1(self):
        """SHA-1 identifier of the current HEAD commit."""
        return self.sha1_of_rev('HEAD')

    @cached_property
    def bv_head_sha1(self):
        """SHA-1 identifier of the commit referenced by refs/bv_head."""
        return self.sha1_of_rev('refs/bv_head')

    @cached_property
    def git_upstream_full_ref(self):
        """Full ref of the current branch's @{upstream}.

        None is returned if there is no @{upstream}.
        """
        try:
            return decode_output(subprocess.check_output(
                ['git', 'rev-parse', '--symbolic-full-name', '@{upstream}'],
                stderr=DEVNULL, cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None

    @cached_property
    def git_upstream_abbrev_ref(self):
        """Abbreviated ref of the current branch's @{upstream}.

        None is returned if there is no @{upstream}.
        """
        try:
            return decode_output(subprocess.check_output(
                ['git', 'rev-parse', '--abbrev-ref', '@{upstream}'],
                stderr=DEVNULL, cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None

    @cached_property
    def full_remote_ref(self):
        """Full ref of the remote-tracking branch representing remote_ref."""
        if self.remote_ref is None:
            return None
        try:
            return decode_output(subprocess.check_output(
                ['git', 'rev-parse', '--symbolic-full-name',
                 'refs/remotes/origin/' + self.remote_ref],
                stderr=DEVNULL, cwd=self.path).rstrip())
        except subprocess.CalledProcessError:
            return None

    def update_origin_and_bv_head(self):
        """Fetch all branches and tags from the 'origin' remote."""
        # Redirect stderr to stdout since git fetch prints progress on stderr,
        # but other BrainVISA tools (e.g. bv_build_nightly) consider every
        # print to stderr to be an error.
        retcode = self.call_command([
            'git', 'fetch', '--tags', '--prune', 'origin',
            '+refs/heads/*:refs/remotes/origin/*',
            # Unfortunately we cannot combine this fetch with fetching
            # remote_ref into refs/bv_head, because this conflicts with --prune
            # (refs/bv_head gets pruned). Confirmed with git version 2.7.4.
            #
            # '+' + self.remote_ref + ':refs/bv_head',
        ], echo=True, stderr=subprocess.STDOUT)
        self.invalidate_cache('full_remote_ref')
        if retcode != 0:
            self.print_command_failure_message('''\
Fetching failed. Please check your Internet connection and access rights
to the origin repository.''')
            raise GitUpdateError('fetch failed')
        self.update_bv_head()

    def update_other_remotes(self):
        """Fetch all remotes except 'origin' (errors are non-fatal)."""
        self.call_nonessential_command(
            ['git', '-c', 'remote.origin.skipDefaultUpdate',
             'remote', 'update'], echo=True)

    @property
    def remote_ref_is_a_branch(self):
        """Test if remote_ref names a branch on the given remote."""
        return self.full_remote_ref is not None

    @staticmethod
    def print_command_failure_message(message):
        """Print a prominent error message referring to the command above."""
        print('^' * 72)
        print(message)
        print('=' * 72)

    @classmethod
    def _setup_git_lfs_global_config(cls):
        """Install git-lfs so that 'git clone' will check out lfs files.

        Errors of 'git lfs install' are ignored, including git lfs not being
        installed.
        """
        if not hasattr(cls, '_git_lfs_is_configured'):
            args = ['git', 'lfs', 'install', '--skip-repo']
            print('$ ' + ' '.join(shlex_quote(arg) for arg in args))
            try:
                subprocess.check_call(args)
            except OSError:
                # "Command not found" scenario
                cls._git_lfs_is_configured = False
            except subprocess.CalledProcessError:
                print('You can safely ignore errors of the above command')
                cls._git_lfs_is_configured = False
            else:
                cls._git_lfs_is_configured = True

    def update_bv_head(self):
        """Change refs/bv_head to point to the given remote ref."""

        if self.remote_ref_is_a_branch:
            # Case 1: if remote_ref points to a branch, use the corresponding
            # remote-tracking branch.
            ref = 'refs/remotes/origin/' + self.remote_ref
        elif self.sha1_of_rev('refs/tags/' + self.remote_ref) is not None:
            # Case 2: if remote_ref points to a tag, use it
            ref = 'refs/tags/' + self.remote_ref
        else:
            # Case 3: neither of the above is true, fall back to using 'git
            # fetch' to fetch the remote ref.
            ref = None

        if ref is not None:
            retcode = self.call_command(['git', 'update-ref', '--no-deref',
                                         'refs/bv_head', ref], echo=True)
            if retcode != 0:
                self.print_command_failure_message(
                    'Failed to update refs/bv_head.')
                raise GitUpdateError('bv_head update failed')
        else:
            # Redirect stderr to stdout since git fetch prints progress on stderr,
            # but other BrainVISA tools (e.g. bv_build_nightly) consider every
            # print to stderr to be an error.
            retcode = self.call_command([
                'git', 'fetch', 'origin',
                "+" + self.remote_ref + ":refs/bv_head"
            ], echo=True, stderr=subprocess.STDOUT)
            self.invalidate_cache('bv_head_sha1')
            if retcode != 0:
                self.print_command_failure_message('''\
Fetching failed. Please check your Internet connection and access rights
to the remote repository.''')
                raise GitUpdateError('fetch failed')

    def checkout_or_create_branch(self, branch, remote='origin'):
        """Check out a branch, or create it from the remote branch."""
        retcode = self.call_command(['git', 'checkout', branch, '--'],
                                    echo=True)
        self.invalidate_cache()
        if retcode != 0:
            retcode = self.call_command(
                ['git', 'checkout', '-b', branch, '--track',
                 'refs/remotes/origin/' + branch])
            if retcode != 0:
                self.print_command_failure_message("""\
The git repository could not be updated, probably because you have
uncommitted local changes (see above).""")
                raise GitUpdateError('checkout failed')

    def try_ff_pull_from_upstream(self):
        """Try to fast-forward from the git-configured @{upstream}.

        This fast-forward is attempted only if @{upstream} is set and is
        different from the remote_ref that bv_maker uses to update the
        repository.

        This is useful e.g. if you are working on a feature branch: it will try
        to pull from the corresponding remote branch if there is one, before
        trying to incorporate changes from the master branch. Failure is
        ignored because this is provided for convenience only.
        """
        # NOTE: if this fails (e.g. because of uncommitted changes or
        # network error), but the remote branch has advanced, the merge
        # from origin (below) may make the local branch diverge from the
        # remote feature branch, which effectively forces the user to merge the
        # commits from master into their branch.
        if (self.git_upstream_full_ref is not None
                and self.git_upstream_full_ref != self.full_remote_ref):
            # Redirect stderr to stdout since git fetch prints progress on
            # stderr, but other BrainVISA tools (e.g. bv_build_nightly)
            # consider every print to stderr to be an error.
            self.call_nonessential_command(['git', 'pull', '--ff-only'],
                                           stderr=subprocess.STDOUT)
            self.invalidate_cache('head_sha1')

    def ff_merge_bv_head(self):
        """Fast-forward merge refs/bv_head into the current branch."""
        retcode = self.call_command(
            ['git', 'merge', '--ff-only', 'refs/bv_head'], echo=True)
        self.invalidate_cache('head_sha1')
        if retcode != 0:
            # TODO(ylep): fall back to resetting the current branch if
            # this is sufficiently safe (useful if a branch is
            # rewritten or rebased).
            self.print_command_failure_message("""\
The upstream branch could not be merged, please refer to the error message
above.""")
            raise GitUpdateError('merge failed')

    def detach_at_bv_head(self):
        """Put the repository in detached state, pointing at refs/bv_head."""
        retcode = self.call_command(
            ['git', 'checkout', '--detach', 'refs/bv_head', '--'], echo=True)
        self.invalidate_cache()
        if retcode != 0:
            self.print_command_failure_message("""\
The Git repository could not be updated, probably because you have
uncommitted local changes (see above).""")
            raise GitUpdateError('checkout failed')

    def print_short_status(self):
        print("\nStatus of {0}:".format(self.path))
        if not os.path.exists(os.path.join(self.path, '.git')):
            print('not a Git repository.')
            return
        self.call_command(['git', 'status', '--short', '--branch'])

    def get_status_dict(self):
        if not os.path.exists(os.path.join(self.path, '.git')):
            return {
                'source_directory': self.source_directory,
                'dest_directory': self.dest_directory,
                'describe_head': 'ERROR: not a Git repository',
            }
        # Collect information that can be used to build a short status string.
        # This is inspired by git/contrib/completion/git-prompt.sh from the Git
        # official source repository.
        #
        # Get the name of the current branch or description of commit
        describe_head = None
        if self.local_branch is None:
            try:
                describe_head = decode_output(subprocess.check_output(
                    ['git', 'describe', '--always'], cwd=self.path).rstrip())
            except subprocess.CalledProcessError:
                pass

        # Get the dirty state of the repository
        retcode = self.call_command(['git', 'diff', '--no-ext-diff',
                                     '--quiet'])
        tree_dirty = (retcode != 0)
        retcode = self.call_command(['git', 'diff', '--no-ext-diff',
                                     '--cached', '--quiet'])
        index_dirty = (retcode != 0)

        # Show the stash state of the repository
        retcode = self.call_command(['git', 'rev-parse', '--verify', '--quiet',
                                     'refs/stash'],
                                    stdout=DEVNULL)

        stash = (retcode == 0)

        # Show a marker if there are untracked files
        retcode = self.call_command(['git', 'ls-files', '--others',
                                     '--exclude-standard', '--directory',
                                     '--no-empty-directory', '--error-unmatch',
                                     '--', ':/*'],
                                    stdout=DEVNULL,
                                    stderr=DEVNULL)
        untracked = (retcode == 0)

        # Show upstream info for bv_maker-configured and git-configured
        # upstream
        bv_maker_upstream_ref = self.full_remote_ref
        git_upstream_ref = self.git_upstream_full_ref
        if bv_maker_upstream_ref:
            bv_upstream_info = 'U' + self.behind_ahead_upstream_suffix(
                bv_maker_upstream_ref)
        else:
            bv_upstream_info = ''

        if git_upstream_ref and git_upstream_ref != bv_maker_upstream_ref:
            git_upstream_info = 'u' + self.behind_ahead_upstream_suffix(
                '@{upstream}')
            git_upstream_name = self.git_upstream_abbrev_ref
        else:
            git_upstream_info = ''
            git_upstream_name = ''

        return {
            'source_directory': self.source_directory,
            'dest_directory': self.dest_directory,
            'describe_head': describe_head,
            'current_branch': self.local_branch,
            'head_short_sha1': self.head_short_sha1,
            'tree_dirty': tree_dirty,
            'index_dirty': index_dirty,
            'stash': stash,
            'untracked': untracked,
            'bv_upstream_info': bv_upstream_info,
            'git_upstream_info': git_upstream_info,
            'git_upstream_name': git_upstream_name,
        }

    def behind_ahead_upstream(self, upstream='@{upstream}'):
        """Get the number of local commits behind and ahead of the upstream.

        (None, None) is returned if the information is unavailable (e.g. the
        specified upstream does not exist).
        """
        try:
            output = subprocess.check_output(
                ['git', 'rev-list', '--count', '--left-right',
                 upstream + '...HEAD'],
                stderr=DEVNULL, cwd=self.path)
            behind, ahead = (int(n) for n in output.split())
        except subprocess.CalledProcessError:
            return None, None
        return behind, ahead

    def behind_ahead_upstream_suffix(self, upstream='@{upstream}'):
        """Get a suffix string representing the number of diverging commits.

        '=' is returned if the current branch is even with upstream. Otherwise,
        '+A-B' is returned, where A and B are the number of commits ahead and
        behind of the branch, respectively. Any '+0' or '-0' part is omitted.

        An empty string is returned if the information is unavailable (e.g. the
        specified upstream does not exist).
        """
        behind, ahead = self.behind_ahead_upstream(upstream)
        if behind is None:
            return ''
        if behind == ahead == 0:
            return '='
        upstream_info = ''
        if ahead != 0:
            upstream_info += '+{0}'.format(ahead)
        if behind != 0:
            upstream_info += '-{0}'.format(behind)
        return upstream_info

    @classmethod
    def have_pre_commit(cls):
        """Test if pre-commit is available."""
        if not hasattr(cls, '_have_pre_commit'):
            cls._have_pre_commit = bool(
                distutils.spawn.find_executable('pre-commit')
            )
        return cls._have_pre_commit

    def update_or_clone(self, source_dir):
        """Update or clone the repository."""
        print("\n")
        print("Updating git repository {0}".format(self.path))

        # Clone repository if it does not exist yet locally
        if not os.path.exists(os.path.join(self.path, '.git')):
            if os.path.isdir(self.path) and os.listdir(self.path):
                print('''
ERROR: directory "%s" is not empty, Git will not be able to clone into it.
This error may be due to a repository change for a component (typically
going from Subversion to Git). You must check yourself that you have nothing
to keep in this directory and delete it to make "bv_maker sources" work.'''
                       % self.path)
            self._setup_git_lfs_global_config()
            system('git', 'clone', '--branch', self.remote_ref,
                   self.remote_url, self.path)
        else:
            # Make sure that the origin remote is configured and points to the
            # URL configured in bv_maker
            retcode = self.call_command(
                ['git', 'remote', 'set-url', 'origin', self.remote_url],
                stderr=DEVNULL,
            )
            if retcode != 0:
                retcode = self.call_command(
                    ['git', 'remote', 'add', '--tags',
                     'origin', self.remote_url], echo=True)
                if retcode == 0:
                    raise GitUpdateError('remote set-up failed')

        # Fetch the remote ref specified in bv_maker.cfg into refs/bv_head
        #
        # FIXME(ylep): what happens if the update below ends with an error?
        # bv_head is already updated, does that pose a problem?
        # Get the SHA-1 identifiers of HEAD and refs/bv_head commits
        old_bv_head = self.bv_head_sha1
        self.update_origin_and_bv_head()

        # Update other remotes only if the user has explicitly configured
        # update_git_remotes = 'ON'.
        if source_dir.update_git_remotes.upper() == 'ON':
            self.update_other_remotes()

        if self.remote_ref_is_a_branch:
            if ((not self.local_branch and self.head_sha1 == old_bv_head)
                    or self.head_sha1 is None):
                # NOTE: this code path will upgrade repositories that follow a
                # branch in detached mode, which were used until May 2019.
                self.checkout_or_create_branch(self.remote_ref)
                # In case of success, we proceed to do the normal fast-forward
                # update
            elif not self.local_branch:
                print('=' * 72)
                print("""\
The Git repository was not updated, because it is in detached HEAD
state. You can update it manually with:

  git -C '{path}' checkout {remote_ref}
  git pull origin {remote_ref}

If that fails, you can force the re-creation of the local branch (beware
that this could lose local commits on the old '{remote_ref}' branch):

  git -C '{path}' checkout -B {remote_ref} origin/{remote_ref}\
""".format(path=self.path, remote_ref=self.remote_ref))
                print('=' * 72)
                raise GitUpdateError('detached')

            self.try_ff_pull_from_upstream()

            # We are following a branch. Advance the branch if it has not
            # diverged from upstream. If local commits exist, that would
            # require creating a merge commit, and we do not want to do that
            # behind the back of the developer. The merge aborts safely if
            # there are local uncommitted changes, and prints an appropriate
            # message.
            self.ff_merge_bv_head()
        else:  # not self.remote_ref_is_a_branch
            # If self.head_sha1 == old_bv_head, it means that the user has not
            # moved the repository since the last bv_maker run. In this case,
            # we allow ourselves to reconfigure the repository (e.g. check out
            # a different commit).
            if (self.head_sha1 == old_bv_head
                    or not self.head_sha1
                    or not old_bv_head):
                # If remote_ref is not a branch (i.e. it is a tag or a sha-1),
                # we want to detach the repository at this precise commit.
                self.detach_at_bv_head()
            elif self.head_sha1 == self.bv_head_sha1:
                pass  # success (nothing to do!)
            else:
                print('=' * 72)
                print("""\
The Git repository was not updated, because a different commit was
checked out since the last run of bv_maker sources. You can update your
repository manually using the following command:

  git -C '{path}' checkout refs/bv_head\
""".format(path=self.path, remote_ref=self.remote_ref))
                print('=' * 72)
                raise GitUpdateError('detached')

        if (os.path.exists(os.path.join(self.path, '.pre-commit-config.yaml'))
                and self.have_pre_commit()):
            self.call_nonessential_command(['pre-commit', 'install'])


def print_git_status_summary(source_directory, status_list):
    if not status_list:
        return

    header = 'Summary of Git repositories in ' + source_directory
    print('\n' + header)
    print('=' * len(header))

    def format_head(status_dict):
        if status_dict.get('current_branch') is not None:
            return '{current_branch} ({head_short_sha1})'.format(**status_dict)
        else:
            return status_dict['describe_head']

    # Calculate optimal field widths
    head_width = max(max(len(format_head(d)) for d in status_list), 1)
    bv_upstream_width = max(len(d.get('bv_upstream_info', ''))
                            for d in status_list)
    if bv_upstream_width != 0:
        bv_upstream_format = '{{bv_upstream:{0}s}}'.format(bv_upstream_width)
    else:
        bv_upstream_format = ''
    git_upstream_width = max(len(d.get('git_upstream_info', ''))
                             for d in status_list)
    if git_upstream_width != 0:
        git_upstream_format = '{{git_upstream:{0}s}}'.format(
            git_upstream_width)
    else:
        git_upstream_format = ''
    update_message_width = max(len(d.get('update_message', u''))
                               for d in status_list)
    if update_message_width != 0:
        update_message_format = '{{update_message:{0}s}} '.format(
            update_message_width)
        update_message_width += 1
    else:
        update_message_format = ''

    print('┌───── * uncommitted working tree changes')
    print('│┌──── + uncommitted index changes')
    print('││┌─── $ stash present')
    print('│││┌── % untracked files')
    print('││││ ┌ HEAD')
    prefix = '││││ │' + ' ' * head_width
    if update_message_width != 0:
        print(prefix + '┌ update status')
        prefix += '│' + ' ' * (update_message_width - 1)
    print(prefix + '┌ bv_maker upstream state')
    print(prefix + '│' + ' ' * bv_upstream_width + '┌ Git upstream state')
    print(prefix + '│' + ' ' * bv_upstream_width + '│'
          + ' ' * git_upstream_width + '┌ Directory')

    for status_dict in status_list:
        print(u'{{tree_dirty}}{{index_dirty}}{{stash}}{{untracked}} '
              '{{head:{head_width}s}} '
              '{update_message_format}'
              '{bv_upstream_format} {git_upstream_format} '
              '{{dest_directory}}'
              .format(
                  head_width=head_width,
                  bv_upstream_format=bv_upstream_format,
                  git_upstream_format=git_upstream_format,
                  update_message_format=update_message_format,
              )
              .format(
                  dest_directory=status_dict['dest_directory'],
                  head=format_head(status_dict),
                  tree_dirty='*' if status_dict.get('tree_dirty') else ' ',
                  index_dirty='+' if status_dict.get('index_dirty') else ' ',
                  stash='$' if status_dict.get('stash') else ' ',
                  untracked='%' if status_dict.get('untracked') else ' ',
                  bv_upstream=status_dict.get('bv_upstream_info', ''),
                  git_upstream=status_dict.get('git_upstream_info', ''),
                  update_message=status_dict.get('update_message', ''),
              ))


class SourceDirectory(DirectorySection, ConfigVariableParser):

    _variables_with_replacements = set(('directory_id',  'cross_compiling_dirs'))
    _path_variables = set(('directory',))
    _validAdditiveOptions = set(('default_steps', 'cross_compiling_dirs'))
    _validOptions = set(('revision_control',
                         'build_condition',
                         'stdout_file', 
                         'stderr_file',
                         'update_git_remotes',
                         'default_source_dir',
                         'ignore_git_failure'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)
        
    def __init__(self, directory, configuration):
        super(SourceDirectory, self).__init__()
        self.configuration = configuration
        self.directory = directory
        self.configurationLines = []
        self.sourceConfigurationLines = []
        self.svnComponents = []
        self.gitComponents = []
        self.default_steps = ['sources']
        self.revision_control = 'ON'
        self.update_git_remotes = 'ON'
        self.directory_id = ''
        # cross_compiling_dirs contains toolchain substitutions for source
        # directories. This is used when execution needs different path to
        # access sources (i.e.: in windows cross compilation, for pure python
        # components, it is necessary to access source directory through
        # network share, instead of NFS mount point.
        self.cross_compiling_dirs = {}
        self.ignore_git_failure = False
        if self.configuration.verbose:
            print('Processing source directory %s' % self.directory)
        self._git_only_failed = False

    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ source ... ]:
        #    default_steps [info] [sources]
        #    git <url> <git_tag> [<dest_directory> [<bv_version>]]
        #    svn <url> [<dest_directory> [<bv_version>]]
        #    brainvisa <component_pattern> <version_pattern>
        #    brainvisa_exclude <component_pattern> [<version_pattern>]
        #    + soma/soma-base/trunk [<dest_directory>] [<bv_version>]]
        #    + https://svn.url [<dest_directory>] [<bv_version>]]
        #    + <component_pattern> <version_pattern>
        #    - <component_pattern> [<version_pattern>]
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            self.sourceConfigurationLines.append(line)
            
    def parseSourceConfiguration(self):
        for l in self.sourceConfigurationLines:
            self.parseSourceConfigurationLine(l)
        
    def parseSourceConfigurationLine(self, line, virtual=False, 
                                     component_version = None):
        line = os.path.expandvars(line)
        l = line.split()
        sign = l[0]
        if sign == 'git':
            if len(l) < 3 or len(l) > 5:
                raise SyntaxError()
            sign, url, git_tag, dest_directory, bv_version = (
                l + [None, None])[:5]
            git_tag_type, git_tag = (['branch'] \
                + git_tag.split(':',1))[-2:]
            # git_tag is the git branch (master, integration...)
            # bv_version is the bv branch name (bug_fix, trunk)
            if self.configuration.verbose:
                print('    adding repository: git', url, git_tag)
                print('                   in:', \
                    os.path.join(self.directory, dest_directory))
                if component_version:
                    print('                  for: %s version %s' \
                        % component_version)
            self.gitComponents.append(
                (component_version, url, git_tag, dest_directory,
                    bv_version))
        else:
            if len(l) < 2 or len(l) > 4:
                raise SyntaxError()
            sign, componentPattern, versionPattern, bv_version = (
                l + [None, None])[:4]
            if sign == 'svn' or (sign == '+' and '/' in componentPattern):
                if '*' in componentPattern:
                    raise SyntaxError()
                if componentPattern.startswith('http') \
                        or componentPattern.startswith('file'):
                    url = componentPattern
                    dest_directory = versionPattern
                else:
                    url = brainvisa_projects.SVN_URL + '/' \
                        + componentPattern
                    dest_directory = versionPattern
                    if dest_directory is None:
                        dest_directory = componentPattern
                if dest_directory is None:
                    raise SyntaxError()
                if self.configuration.verbose:
                    print('    adding repository: svn', url,
                            component_version)
                    print('                   in:', \
                        os.path.join(self.directory, dest_directory))
                    if component_version:
                        print('                  for: %s version %s' \
                            % component_version)

                self.svnComponents.append(
                    (component_version, url, dest_directory, bv_version))
            elif sign in ('brainvisa', '+'):
                if versionPattern is None:
                    raise SyntaxError()
                for component in brainvisa_projects.find_components(
                    componentPattern):
                    project = brainvisa_projects.project_per_component[
                        component]
                    for version, repo_dir in six.iteritems(
                        brainvisa_projects.url_per_component[component]):
                        repo, dir = repo_dir
                        if fnmatchcase(version, versionPattern):
                            default_source_dir = getattr(self, 'default_source_dir', None)
                            if default_source_dir:
                                dir = default_source_dir.format(project=project,
                                                                component=component,
                                                                branch=version)
                            self.parseSourceConfigurationLine(
                                '%s %s %s' % (repo, dir, version), 
                                virtual=True, 
                                component_version=(component, version))
            elif sign in ('-', 'brainvisa_exclude'):
                if '/' in componentPattern:
                    raise SyntaxError()
                else:
                    if versionPattern is None:
                        versionPattern = '*'
                    for component in brainvisa_projects.find_components(
                        componentPattern):
                        for version, repo_dir in six.iteritems(
                            brainvisa_projects.url_per_component[
                                component]):
                            if fnmatchcase(version, versionPattern):
                                # Remove unwanted svn components
                                count = 0
                                for component_version \
                                    in [i[0] for i in self.svnComponents]:
                                    if component_version:
                                        c, v = component_version
                                        if c == component and v == version:
                                            if self.configuration.verbose:
                                                component_version, url, \
                                                dest_directory, bv_version = \
                                                self.svnComponents[count]
                                                print('    removing repository:',
                                                      'svn', url)
                                                print('                     in:',
                                                      os.path.join(
                                                          self.directory, 
                                                          dest_directory))
                                                print('                    for: %s version %s' % component_version)
                                            del self.svnComponents[count]
                                            count -= 1
                                    count += 1
                                # Remove unwanted git components
                                count = 0
                                for component_version in [i[0] for i in self.gitComponents]:
                                    if component_version:
                                        c, v = component_version
                                        if c == component and v == version:
                                            if self.configuration.verbose:
                                                component_version, url, git_tag, dest_directory, bv_version = self.gitComponents[
                                                    count]
                                                print('    removing repository: git', url, git_tag)
                                                print('                     in:', os.path.join(self.directory, dest_directory))
                                                print('                    for: %s version %s' % component_version)
                                            del self.gitComponents[count]
                                            count -= 1
                                    count += 1
            else:
                raise SyntaxError('Line cannot begin with "%s"' % sign)
            
        if not virtual:
            self.configurationLines.append(line)

    def process(self, options, args):
        self._git_only_failed = False
        if options.ignore_git_failure:
            self.ignore_git_failure = True
        if not os.path.exists(self.directory):
            os.makedirs(self.directory)
        with open(os.path.join(self.directory, 'bv_maker.cfg'),
                  'w') as clientFile:
            print('\n'.join(self.configurationLines), file=clientFile)

        repositoryDirectory = os.path.join(self.directory, '.repository')
        checkout = False
        use_rcs = self.revision_control.upper() in ('', 'ON')
        if use_rcs and options.svn and not os.path.exists(repositoryDirectory):
            os.makedirs(repositoryDirectory)
            # Because of a bug in svnadmin on MacOS, I cannot use an absolute name for the directory to create.
            # When I try "svnadmin create /neurospin/brainvisa/cmake_mac/", I have the following error:
            # svnadmin: '/neurospin/brainvisa/cmake_mac' is a subdirectory of an existing repository rooted at '/neurospin'
            # But it works if I do "cd /neurospin/brainvisa && vnadmin create
            # cmake_mac"
            cwd, dir = os.path.split(repositoryDirectory)
            system('svnadmin', 'create', dir, cwd=cwd)

            if len(os.path.splitdrive(repositoryDirectory)[0]) > 0:
                # This is for windows absolute pathes
                repositoryDirectory = '/' + \
                    repositoryDirectory.replace(os.path.sep, "/")

            self.svncommand(
                'checkout',  'file://' + repositoryDirectory, self.directory)
            checkout = True

        source_directories = []

        # Update SVN repositories

        # Go to the sources directory
        externalsFileName = os.path.join(self.directory, 'bv_maker.externals')
        with open(externalsFileName, 'w') as externalsFile:
            for component_version, url, dest_directory, bv_version in set(self.svnComponents):
                print(dest_directory, url, file=externalsFile)
                source_directories.append((dest_directory, bv_version))

        if use_rcs and options.svn:
            if options.cleanup:
                self.svncommand('cleanup', self.directory, cwd=self.directory)
            self.svncommand('propset', 'svn:externals',
                            '--file', externalsFileName, self.directory,
                            cwd=self.directory)
            self.svncommand('commit', '-m', '', self.directory,
                            cwd=self.directory)
            self.svncommand('update', self.directory, cwd=self.directory)

        # update Git Repositories

        git_status_list = []
        git_update_failure = False
        for component_version, url, git_tag, dest_directory, bv_version \
                in self.gitComponents:
            if dest_directory is None:
                dest_directory = url.rsplit('/', 1)[-1]
                if dest_directory.endswith('.git'):
                    dest_directory = dest_directory[:-4]
            if use_rcs and options.git:
                gr = GitRepository(self.directory, dest_directory,
                                   remote_url=url, remote_ref=git_tag)
                try:
                    gr.update_or_clone(source_dir=self)
                except GitUpdateError as exc:
                    update_message = u'✗ ' + ensure_text(str(exc))
                    git_update_failure = True
                else:
                    update_message = u'✓'
                status_dict = gr.get_status_dict()
                status_dict['update_message'] = update_message
                git_status_list.append(status_dict)
                source_directories.append((dest_directory, bv_version))

        print_git_status_summary(self.directory, git_status_list)

        components_sources = {}
        for dest_path, bv_version in source_directories:
            pinfo = brainvisa_projects.read_project_info(
                os.path.join(self.directory, dest_path),
                version_format=version_format_short
            )
            if pinfo:
                project, component, version, build_model = pinfo
                version = str(version)
                components_sources.setdefault(component, {})[
                    bv_version or version] = (dest_path, build_model)
            else:
                print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found or used' % os.path.join(self.directory, dest_path))
        with open(os.path.join(self.directory, 'components_sources.json'),
                  'w') as f:
            json.dump(components_sources, f, indent=2)
        if git_update_failure:
            self._git_only_failed = True
            raise RuntimeError('Error updating one or more Git repositories')

    def source_status(self, options, args):
        repositoryDirectory = os.path.join(self.directory, '.repository')
        use_rcs = self.revision_control.upper() in ('', 'ON')

        # Display status of SVN repositories

        # Go to the sources directory
        if use_rcs and options.svn:
            self.svncommand('status', self.directory, cwd=self.directory)

        # Display status of Git Repositories

        git_status_list = []
        for _, url, git_tag, dest_directory, _ in self.gitComponents:
            if dest_directory is None:
                dest_directory = url.rsplit('/', 1)[-1]
                if dest_directory.endswith('.git'):
                    dest_directory = dest_directory[:-4]
            dest_path = os.path.join(self.directory, dest_directory)
            if use_rcs and options.git:
                gr = GitRepository(self.directory, dest_directory,
                                   remote_url=url, remote_ref=git_tag)
                gr.print_short_status()
                status_dict = gr.get_status_dict()
                git_status_list.append(status_dict)

        print_git_status_summary(self.directory, git_status_list)

    def svncommand(self, *svnargs, **subprocess_kwargs):
        cmd = ['svn', svnargs[0]]
        if self.configuration.username:
            cmd += ['--username', self.configuration.username]
            if self.configuration.username == 'brainvisa':
                cmd += ['--password', 'Soma2009']
        cmd.extend(svnargs[1:])
        system(*cmd, **subprocess_kwargs)

    def info(self):
        print('Source directory: "' + self.directory + '"')
        for component_version, url, dest_directory, bv_version in self.svnComponents:
            print('  %s <- svn %s' % (dest_directory, url))
            if component_version:
                component, version = component_version
                print('    component %s (%s)' % (component, version))
        for component_version, url, git_tag, dest_directory, bv_version in self.gitComponents:
            print('  %s <- git %s' % (dest_directory, url))
            if component_version:
                component, version = component_version
                print('    component %s (%s)' % (component, version))

    @staticmethod
    def dep_condition(dest_section, src_section, step):
        # this function is used for step condition testing. It is overloaded
        # just in case the option ignore_git_failure is set: then next
        # steps are still enabled, while this source step has failed.
        if not src_section.has_failed(step):
            return True
        if src_section.status.get(step, 'not run') == 'failed' \
                and src_section.ignore_git_failure \
                and src_section._git_only_failed:
            return True
        return False


class ComponentsConfigParser(DirectorySection):

    def __init__(self, directory, configuration):
        super(ComponentsConfigParser, self).__init__()
        self.configuration = configuration
        self.directory = directory
        self.configurationLines = []
        self.projects = set()
        self.components = {}
        self._configuration_lines_processed = False

    def process_configuration_lines(self):
        if not self._configuration_lines_processed:
            if self.configuration.verbose:
                print('Processing build directory %s' % self.directory)
            for line in self.configurationLines:
                if '=' in line:
                    continue
                first, rest = line.split(None, 1)
                if first in ('directory', '+'):
                    directory = environmentPathVariablesSubstitution(
                            rest.strip(), env=self.get_environ())
                    pinfo = brainvisa_projects.read_project_info(
                        directory,
                        version_format=version_format_short
                    )
                    if pinfo:
                        project, component, version, build_model = pinfo
                        version = str(version)
                        if self.configuration.verbose:
                            print('    adding component %s version %s from %s'
                                  % (component, version, directory))
                        self.components[component] = (
                            directory, version, version, build_model)
                    else:
                        print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found' % directory)
                elif first in ('brainvisa_exclude', '-'):
                    component_def = rest.split(None, 1)
                    componentPattern, versionPattern = (
                        component_def + ['*'])[:2]
                    components \
                        = brainvisa_projects.find_components(componentPattern)
                    if len(components) == 0 \
                            and component_def[0] in self.components:
                        components = [component_def[0]]
                    for component in components:
                        dir_version = self.components.get(component)
                        if dir_version:
                            dir, selected_version, component_version, \
                               build_model = dir_version
                            if fnmatchcase(selected_version, versionPattern):
                                if self.configuration.verbose:
                                    print('    removing component %s from %s'
                                          % (component, dir))
                                del self.components[component]
                elif first == 'brainvisa' \
                        or (first
                            in brainvisa_projects.project_per_component) \
                        or (first in brainvisa_projects.components_per_group) \
                        or (first
                            in brainvisa_projects.components_per_project) \
                        or '*' in first:
                    if first == 'brainvisa':
                        l = rest.split(None, 2)
                        componentPattern, versionPattern, sourceDirectory = l
                    else:
                        l = rest.split(None, 1)
                        componentPattern = first
                        versionPattern, sourceDirectory = l
                    sourceDirectory = environmentPathVariablesSubstitution(
                            sourceDirectory, env=self.get_environ())
                    with open(os.path.join(sourceDirectory,
                                           'components_sources.json')) as f:
                        components_sources = json.load(f)
                    projects_set = brainvisa_projects.ProjectsSet()
                    projects_set.add_sources_list(components_sources)
                    possible_components = set(
                        projects_set.find_components(componentPattern))
                    for component in possible_components:
                        for version, directory_model \
                                in six.iteritems(
                                    components_sources.get(component, {})):
                            if isinstance(directory_model, list):
                                directory, build_model = directory_model
                            else:
                                directory = directory_model
                                build_model = None
                            directory = os.path.join(
                                sourceDirectory, directory)
                            if fnmatchcase(version, versionPattern):
                                pinfo = brainvisa_projects.read_project_info(
                                    directory,
                                    version_format=version_format_short
                                )
                                if pinfo:
                                    project, component, component_version, \
                                        build_model = pinfo
                                    component_version = str(component_version)
                                    if self.configuration.verbose:
                                        print('    adding component %s version %s from %s' \
                                            % (component, version, directory))
                                    self.components[component] = (
                                        directory, version, component_version, build_model)
                                else:
                                    print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found'
                                          % directory)
                elif first == 'pip':
                    if '=' in rest:
                        module, version = rest.split(None, 1)
                    else:
                        module = rest
                        version = None
                    installed_json = os.path.join(
                        self.directory, 'bv_maker_install.json')
                    if os.path.exists(installed_json):
                        with open(installed_json) as f:
                            installed = json.load(f)
                    else:
                        installed = {}
                    pip_installed = installed.setdefault('pip', {})
                    if module not in pip_installed:
                        command = [os.path.join(
                            self.directory, 'bin', 'pip'), 'install',
                            ('%s==%s' % (module, version) if version
                             else module)]
                        print('Running:', ' '.join(command))
                        subprocess.check_call(command)
                        pip_installed[module] = version
                        with open(installed_json, 'w') as f:
                            json.dump(installed, f)
                else:
                    SyntaxError()
            projects = set(brainvisa_projects.project_per_component.get(i, i)
                           for i in self.components)
            self.projects = [i for i in brainvisa_projects.ordered_projects
                             if i in projects]
            self.projects.extend(projects - set(self.projects))
            self._configuration_lines_processed = True
            if self.configuration.verbose:
                print('Build directory %s parsing done.' % self.directory)


class BuildDirectory(ComponentsConfigParser, ConfigVariableParser):

    _path_variables = set(('directory',
                           'stdout_file', 'stderr_file',
                           'test_ref_data_dir', 'test_run_data_dir'))
    _variables_with_replacements = set(('make_options', 'cmake_options',
                                        'ctest_options', 'directory_id', ))
    _variables_with_env_only_replacements = set(('cross_compiling_prefix',
                                          'cross_compiling_target_system',
                                          'cross_compiling_to_target_path_cmd',
                                          'env', 
                                          'test_ref_data_dir', 
                                          'test_run_data_dir'))
    _validAdditiveOptions = set(('make_options', 'cmake_options', 'env',
                                 'default_steps', 'ctest_options'))
    _validOptions = set(('build_type',
                         'packaging_thirdparty',
                         'build_condition', 'clean_config',
                         'clean_build'))
    _validOptions.update(_validAdditiveOptions)
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)

    sitecustomize_content = '''import os, sys

for i in os.listdir(os.path.dirname(__file__)):
    if i.endswith('.py') and i != '__init__.py':
        module = i[:-3]
        __import__('sitecustomize.%s' % module)

# seek for other sitecustomize modules in path
try:
    i = sys.path.index(os.path.dirname(os.path.dirname(__file__)))
except ValueError:
    i = -1
if 'old_file' not in globals():
  old_file = []
old_file.append(__file__)
for p in sys.path[i+1:]:
    if os.path.isdir(p):
        filename = os.path.join(p, 'sitecustomize.py')
        if not os.path.exists(filename):
            filename = os.path.join(p, 'sitecustomize', '__init__.py')
        if os.path.exists(filename):
            __file__ = filename
            with open(filename) as f:
                file_contents = f.read()
            exec(compile(file_contents, filename, 'exec'))
__file__ = old_file.pop()
for v in ('filename', 'p', 'i'):
    if v in globals():
        del globals()[v]
del v
if len(old_file) == 0:
    del old_file
'''

    def __init__(self, directory, configuration):
        super(BuildDirectory, self).__init__(directory, configuration)
        # self.configurationDirectories = []
        self.build_type = ''
        self.make_options = []
        self.cmake_options = []
        self.packaging_thirdparty = ''
        self.cross_compiling_prefix = ''
        self.cross_compiling_target_system = ''
        self.cross_compiling_to_target_path_cmd = ''
        self.clean_commands = True
        self.default_steps = ['configure', 'build']
        self.clean_config = 'OFF'
        self.clean_build = 'OFF'
        self.ctest_options = []
        self.directory_id = ''
        self.env = {}
        self.test_ref_data_dir = ''
        self.test_run_data_dir = tempfile.gettempdir()

    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ build ... ]:
        #    default_steps [info] [configure] [build] [doc] [test]
        #    directory <directory>
        #    brainvisa <component_pattern> <version_pattern> <source_directory>
        #    brainvisa_exclude <component_pattern> [<version_pattern>]
        #    + <directory>
        #    - <component_pattern> [<version_pattern>]
        #    <component_pattern> <version_pattern> <source_directory>
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            line = os.path.expandvars(line)
            if line[0] == '+':
                if '*' in line:
                    raise SyntaxError()
        self.configurationLines.append(line)

    def set_dependencies(self):
        self.depend_on_sections = {
            'configure': [(d, 'sources', SourceDirectory.dep_condition)
                          for d in
                          self.configuration.sourcesDirectories.values()],
            'build': [(self, 'configure')],
            'doc': [(self, 'build')],
            'test': [(self, 'build')],
            'testref': [(self, 'build')],
        }
    
    def target_system(self):
        if self.cross_compiling_target_system:
            return self.cross_compiling_target_system
        elif self.cross_compiling_prefix:
            if 'mingw' in self.cross_compiling_prefix:
                # Try to split target prefix
                cross_compiling_info = self.cross_compiling_prefix.split('-')
                
                if len(cross_compiling_info) == 3 \
                   and cross_compiling_info[0] == 'x86_64':
                       return 'win64'
                
                return 'win32'
            else:
                raise RuntimeError('Unable to determine target cross '
                                   'compilation system. Please set '
                                   'cross_compiling_target_system option in '
                                   ' build section of your configuration file.')
        else:
            # Target system is the host system
            return sys.platform
        
    def to_target_path(self, path):
        '''
            Get target system path from path
        '''
        host_path_system = get_host_path_system()
        if not isinstance(path, Path):
            path = Path(path, host_path_system)
            
        target_path_system = get_target_path_system(self.target_system())
        if host_path_system != target_path_system:
            if not DefaultPathConverterRegistry().get((host_path_system, 
                                                       target_path_system)):
                if self.cross_compiling_to_target_path_cmd:
                    # Register host to target conversion command
                    cmd = shlex.split(self.cross_compiling_to_target_path_cmd)
                elif host_path_system == 'linux' \
                    and target_path_system == 'windows':
                    # Default cross compilation try to use winepath command
                    # to convert pathes
                    cmd = ['winepath', '-w']
                else:
                    raise RuntimeError('No known conversion between %s and %s '
                                       'path systems. Please set ' 
                                       '\'cross_compiling_to_target_path_cmd\' '
                                       'using an available command to do the '
                                       'conversion'
                                       % (host_path_system, target_path_system))
                
                SystemPathConverter(host_path_system, 
                                    target_path_system, 
                                    cmd)
            
            if target_path_system == 'windows':
                # If target path system is windows, 
                # we prefer to use the windows alternative with slashes
                target_path_system = 'windows_alt'
                
            return path.to_system(target_path_system)
        
        else:
            return path

    def configure(self, options, args):       
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        # Order of projects and components is important for dependencies
        sortedProjects = [p for p in brainvisa_projects.ordered_projects
                          if p in self.projects]
        sortedComponents = []
        components = set(self.components)
        for project in sortedProjects:
            for component \
                    in brainvisa_projects.components_per_project[project]:
                if component in components:
                    sortedComponents.append(component)
                    components.remove(component)
        sortedComponents.extend(components)

        if not os.path.exists(self.directory):
            os.makedirs(self.directory)

        if options.clean or self.clean_config.upper == 'ON':
            my_path = os.path.dirname(__file__)
            bv_clean = os.path.join(my_path, 'bv_clean_build_tree')
            print('cleaning build tree', self.directory)
            # clean and remove empty dirs. Don't use -b option here
            # because configuration has to be done first.
            subprocess.call([sys.executable, bv_clean, '-d', self.directory],
                            env=self.get_environ())

        # Create a sitecustomize Python package that imports all modules it
        # contains during Python startup. This is mainly used to modify
        # sys.path to include pure Python components source (see module
        # brainvisa.maker.build_models.pure_python). This package is used only
        # in build directory, it is not installed in packages (to date there is
        # one exception to this in axon component, see Axon's CMakeLists.txt).
        sitecustomize_dir = os.path.join(
            self.directory, 'python', 'sitecustomize')
        if not os.path.exists(sitecustomize_dir):
            os.makedirs(sitecustomize_dir)
        with open(os.path.join(sitecustomize_dir, '__init__.py'), 'w') as f:
            f.write(self.sitecustomize_content)
        # Remove existing sitecustomize.py (was generated by older Axon)
        for i in glob.glob(sitecustomize_dir + '.py*'):
            os.remove(i)

        if not os.path.exists(self.directory):
            os.makedirs(self.directory)

        cross_compiling_directories = {}
        for k, s in six.iteritems(self.configuration.sourcesDirectories):
            if s.cross_compiling_dirs is not None:
                if len(self.cross_compiling_prefix) > 0:
                    cross_compiling_dir = \
                        s.cross_compiling_dirs.get(
                            self.cross_compiling_prefix)

                    if cross_compiling_dir is not None:
                        cross_compiling_directories[s.directory] = cross_compiling_dir

        #print('==== Toolchain:', self.cross_compiling_prefix,
        #      'directories:', cross_compiling_directories)
        self.buildModelPerComponent = {}
        for component in sortedComponents:
            # find build model
            build_model = self.components[component][3]
            if build_model is None:
                build_model = brainvisa_projects.info_per_component.get(
                    component, {}).get('build_model')
            if build_model is not None:
                build_model_class = getattr(__import__(
                    'brainvisa.maker.build_models',
                    fromlist=[ensure_str('pure_python')], level=0),
                    build_model)
                build_model = build_model_class(
                    component, self.components[component][0], self,
                    cross_compiling_directories, options=options, args=args)
                self.buildModelPerComponent[component] = build_model

        cmakeFile = os.path.join(self.directory, 'bv_maker.cmake')
        with open(cmakeFile, 'w') as out:
            print('set( BRAINVISA_PROJECTS', ' '.join(
                sortedProjects), 'CACHE STRING "BrainVISA Projects list" FORCE )',
                file=out)
            print('set( _BRAINVISA_PROJECTS', ' '.join(
                sortedProjects), 'CACHE STRING "BrainVISA Projects list" FORCE )',
                file=out)
            print('set( BRAINVISA_COMPONENTS',
                  ' '.join(sortedComponents),
                  'CACHE STRING "BrainVISA components list" FORCE )',
                  file=out)
            print('set( _BRAINVISA_COMPONENTS',
                  ' '.join(sortedComponents),
                  'CACHE STRING "BrainVISA components list" FORCE )',
                  file=out)
            print(file=out)
            for component, directory_version_model in six.iteritems(self.components):
                directory, selected_version, version, build_model = directory_version_model
                if component in self.buildModelPerComponent:
                    print('set( BRAINVISA_SOURCES_' + component + ' "' \
                        + cmake_path(self.directory ) + '/build_files/' \
                        + component + '_src' \
                        + '" CACHE STRING "Sources directory for component ' \
                        + component + '" FORCE )',
                        file=out)
                else:
                    print('set( BRAINVISA_SOURCES_' + component + ' "' \
                        + cmake_path(directory) \
                        + '" CACHE STRING "Sources directory for component ' \
                        + component + '" FORCE )',
                        file=out)
                print('set( ' + component + '_DIR "' \
                    + cmake_path(self.directory ) + '/share/' + component + \
                    '-' + version + \
                    '/cmake" CACHE STRING "Directory used for find_package( ' + \
                    component + \
                    ' )" FORCE )',
                    file=out)
                print('set( ' + component + '_VERSION "' + version + '" )',
                      file=out)

        cmakeLists = os.path.join(self.directory, 'CMakeLists.txt')

        with open(cmakeLists, 'w') as out:
            print('''
cmake_minimum_required( VERSION 2.6 )
set( CMAKE_PREFIX_PATH "${CMAKE_BINARY_DIR}" ${CMAKE_PREFIX_PATH} )
find_package( brainvisa-cmake NO_POLICY_SCOPE )
include( "${brainvisa-cmake_DIR}/brainvisa-compilation.cmake" )
''', file=out)

        exe_suffix = ''
        if sys.platform == 'win32':
            command_base = ['cmake', '-G', 'MSYS Makefiles']
            exe_suffix = '.exe'
        else:
            command_base = ['cmake']

        command_options = list(self.cmake_options)
        command_options += ['-DCMAKE_BUILD_TYPE:STRING=' + self.build_type]
        if self.packaging_thirdparty.upper() == 'ON':
            command_options += ['-DBRAINVISA_PACKAGING_THIRDPARTY:BOOL=ON']
        elif self.packaging_thirdparty.upper() == 'OFF':
            command_options += ['-DBRAINVISA_PACKAGING_THIRDPARTY:BOOL=OFF']

        config_dir = cmake_path(self.directory)

        for component, build_model \
                in six.iteritems(self.buildModelPerComponent):
            build_model.configure()

        # set bv_maker path, so that cmake finds its modules
        os.environ['PATH'] = os.path.dirname(this_script) + os.pathsep \
            + os.getenv('PATH')

        # cross compilation options
        cross_compiling_prefix = self.cross_compiling_prefix.strip()
        if len(cross_compiling_prefix) > 0:
            cross_compiling_prefix_path = os.path.join( cmake_root,
                                                        'toolchains',
                                                        cross_compiling_prefix )
            cross_compiling_options = ['-DBRAINVISA_CMAKE_OPTIONS:STRING=' \
                                       'CMAKE_CROSSCOMPILING;COMPILER_PREFIX;' \
                                       'CMAKE_TOOLCHAIN_FILE', \
                                       '-DCOMPILER_PREFIX:STRING=%s' % \
                                       self.cross_compiling_prefix.strip(), \
                                       '-DCMAKE_CROSSCOMPILING:BOOL=ON']
            cross_compiling_toolchain_path = os.path.join(
                                                cross_compiling_prefix_path,
                                                'toolchain.cmake' )

            cross_compiling_init_cache_path = os.path.join(
                                                cross_compiling_prefix_path,
                                                'init-cache.cmake' )
            #print("=== cross_compiling_prefix:", cross_compiling_prefix, "===")
            #print("=== cross_compiling_prefix_path:", cross_compiling_prefix_path, "===")
            #print("=== cross_compiling_toolchain_path:", cross_compiling_toolchain_path, "===")
            #print("=== cross_compiling_init_cache_path:", cross_compiling_init_cache_path, "===")
            if os.path.exists( cross_compiling_toolchain_path ):
                cross_compiling_options += ['-DCMAKE_TOOLCHAIN_FILE:PATH=%s' % \
                                            cmake_path(
                                              cross_compiling_toolchain_path),]

            if os.path.exists( cross_compiling_init_cache_path ):
                cross_compiling_options += ['-C',
                                            cmake_path(
                                              cross_compiling_init_cache_path),]
            #print('cross compiling using toolchain:', cross_compiling_prefix)
            #print('  with options:', *cross_compiling_options)
        else:
            cross_compiling_options = []

        # special case: if bv-cmake is part of the build directory, run cmake
        # in 2 passes: once to reinstall bv-cmake from sources, and a second
        # time to actually configure all projects using the newly installed
        # bv-cmake.
        if 'brainvisa-cmake' in self.components:
            print('=== bootstraping brainvisa-cmake project ===')
            bvcmake_dir = os.path.join(self.directory, 'brainvisa-cmake')
            if not os.path.exists(bvcmake_dir):
                os.makedirs(bvcmake_dir)
            # pass it Qt version if we have any info
            bvcmake_options = []
            qt_opt = [x for x in self.cmake_options
                      if x.startswith('DESIRED_QT_VERSION')]
            if qt_opt:
                qt_opt = qt_opt[0].split('=')[1].strip()
                bvcmake_options.append('-DDESIRED_QT_VERSION=%s' %qt_opt)
            elif os.path.exists(os.path.join(self.directory, 'CMakeCache.txt')):
                with open(os.path.join(self.directory, 'CMakeCache.txt')) as f:
                    for l in f.readlines():
                        if l.startswith('DESIRED_QT_VERSION:'):
                            qt_opt = l.split('=')[1].strip()
                            bvcmake_options.append(
                                '-DDESIRED_QT_VERSION=%s' %qt_opt)
            system(cwd=bvcmake_dir,
                   *(command_base
                     + [self.components['brainvisa-cmake'][0],
                        '-DBRAINVISA_CMAKE_BUILD_TYPE=brainvisa-cmake-only',
                        '-DCMAKE_INSTALL_PREFIX=%s' % self.directory]
                     + bvcmake_options),
                     env=self.get_environ(),
                     timeout=timeout)
            system(cwd=bvcmake_dir, *['make', 'install'],
                   env=self.get_environ(),
                   timeout=timeout)
            print('=== now configuring all other projects ===')
            # run with this local bv-cmake environment
            system(cwd=self.directory,
                   *( [os.path.join(self.directory, 'bin',
                                    'bv_env_host%s' % exe_suffix)]
                     + command_base
                     + command_options
                     + cross_compiling_options
                     + ["-DBRAINVISA_CMAKE_BUILD_TYPE=no-brainvisa-cmake"]
                     + [config_dir]),
                   env=self.get_environ(),
                   timeout=timeout)
        else:
            # run cmake in a regular way
            system(cwd=self.directory, *( command_base
                                        + command_options
                                        + cross_compiling_options
                                        + [config_dir]),
                   env=self.get_environ(),
                   timeout=timeout)
            
        
        # After a first configuration, the global version file of the build 
        # directory has been generated, and package directories variables, 
        # must be updated
        for p in list(self.configuration.packageDirectories.values()) \
               + list(self.configuration.publicationDirectories.values()):
            if p.get_build_dir() is self:
                version = self.get_version()
                if version:
                    p.update_python_vars({'version': version})

    def build(self, options, args):
        self.process_configuration_lines()

        # It is crucial that we do not run 'make' with spurious
        # libraries in LD_LIBRARY_PATH, because 'make' has no safeguard
        # against it.
        check_ld_library_path_error(fatal=True)

        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
            
        if options.clean or self.clean_build.upper() == 'ON':
            if self.clean_commands:
                clean_opts = ['-b']
            else:
                clean_opts = []
            my_path = os.path.dirname(__file__)
            bv_clean = os.path.join(my_path, 'bv_clean_build_tree')
            print('cleaning build tree', self.directory)
            # don't remove empty dirs here since configure may have created
            # directories which will be used during build
            subprocess.call(
                [sys.executable, bv_clean] + clean_opts + [self.directory],
                env=self.get_environ())

        print('Building directory:', self.directory)
        system(cwd=self.directory, *(['make'] + self.make_options),
               env=self.get_environ(),
               timeout=timeout)

        # make / update run scripts/symlinks from a container
        if os.environ.get('CASA_SYSTEM'):
            try:
                casa_distro = 'casa_distro'
                casa_distro = distutils.spawn.find_executable(casa_distro)
                if not casa_distro:
                    casa_distro = distutils.spawn.find_executable(
                        'casa_container')
                if casa_distro:
                    casa_distro = os.path.dirname(os.path.dirname(
                        os.path.realpath(casa_distro)))
                    script = os.path.join(
                        casa_distro, 'share', 'scripts',
                        'casa_build_host_links')
                    if os.path.exists(script):
                        print('updating run scripts for casa-distro')
                        env = dict(os.environ)
                        if 'PYTHONPATH' in env:
                            pypath = ':'.join(
                                [os.path.join(casa_distro, 'python'),
                                 env['PYTHONPATH']])
                            env['PYTHONPATH'] = pypath
                        else:
                            env['PYTHONPATH'] = os.path.join(casa_distro,
                                                             'python')
                        subprocess.call([sys.executable, script], env=env)
            except Exception as e:
                print(e)
                pass

    def doc(self):
        self.process_configuration_lines()
        print('Building docs in directory:', self.directory)
        timeout = configuration.general_section.subprocess_timeout
        system(cwd=self.directory, *
               (['make'] + self.make_options + ['doc']),
               env=self.get_environ(),
               timeout=timeout)

    def init_vars(self):
        super(BuildDirectory, self).init_vars()
        
        self.__init_python_vars()
        self.__init_environ()
     
    def __init_python_vars(self):
        if not self._property_recursivity.get('directory'):             
            if self.target_system() == sys.platform:
                build_system = get_pack_host_system_name()
            else:
                build_system = self.target_system() 

            self.update_python_vars({'os': build_system})
            
    def __init_environ(self):
        env = {}
        
        # During environment initialization, we need skip property
        # mechanims
        if (not self._property_recursivity.get('test_run_data_dir')) \
           and self.test_run_data_dir:
            # Add directories to env
            env["BRAINVISA_TEST_RUN_DATA_DIR"] = self.to_target_path(
                self.test_run_data_dir)
        if (not self._property_recursivity.get('test_ref_data_dir')) \
           and self.test_ref_data_dir:
            # Add directories to env
            env["BRAINVISA_TEST_REF_DATA_DIR"] = self.to_target_path(
                self.test_ref_data_dir)
            
        self.update_environ(env)
    
    def reset_environ(self):
        super(BuildDirectory, self).reset_environ()
        self.__init_environ()

    def test(self, options, args):
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        if options.ctest_options is not None:
            ctoptions = shlex.split(options.ctest_options)
        else:
            ctoptions = self.ctest_options
        print('Testing directory:', self.directory)
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir is not defined; tests may fail.")
        env = self.get_environ()
        # Create test_run_data_dir and test_ref_data_dir
        if self.test_run_data_dir:
            if not os.path.exists(self.test_run_data_dir):
                os.makedirs(self.test_run_data_dir)
        if self.test_ref_data_dir:
            if not os.path.exists(self.test_ref_data_dir):
                os.makedirs(self.test_ref_data_dir)
        return run_and_log_tests(cwd=self.directory, options=ctoptions,
                                 env=env,
                                 timeout=timeout)

    def testref(self, options, args):
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        if options.make_options is not None:
            ctoptions = shlex.split(options.make_options)
        else:
            ctoptions = self.make_options
        print('Creating test reference data for directory:', self.directory)
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir should be defined to create "
                  "reference files.")
        env = self.get_environ()
        # Create test_ref_data_dir
        if self.test_ref_data_dir:
            if not os.path.exists(self.test_ref_data_dir):
                os.makedirs(self.test_ref_data_dir)
        return run_and_log_testref(cwd=self.directory, options=ctoptions,
                                   env=env,
                                   timeout=timeout)

    def info(self):
        self.process_configuration_lines()
        print('Build directory: "' + self.directory + '"')
        for component, directory_version_model \
                in six.iteritems(self.components):
            directory, selected_version, version, build_model \
                = directory_version_model
            print('  %s (%s) <- %s' % (component, version, directory))
            
    def get_version(self):
        bvconf = os.path.join(self.directory, 
                              'python', 'brainvisa', 'config.py')
        fullVersion = None
        
        if os.path.exists(bvconf):
            ver = {}
            try:
                with open(bvconf) as f:
                    code = compile(f.read(), bvconf, 'exec')
                    exec(code, ver, ver)
                fullVersion = ver.get('fullVersion', fullVersion)
            except ImportError:
                pass
            
        return fullVersion

class VirtualenvDirectory(BuildDirectory):

    '''
    It does the samething with the BuildDirectory
    with additional virtualenv init.
    '''

    def __init__(self, directory, configuration):
        super(VirtualenvDirectory, self).__init__(directory, configuration)
        self.clean_commands = False

    def configure(self, options, args):
        self.virtualenv_command(self.directory)
        super(VirtualenvDirectory, self).configure(options, args)

    def which(self, program):
        def is_exe(fpath):
            return os.path.exists(fpath) and os.access(fpath, os.X_OK)

        def ext_candidates(fpath):
            yield fpath
            for ext in os.environ.get("PATHEXT", "").split(os.pathsep):
                yield fpath + ext
        fpath, fname = os.path.split(program)
        if fpath:
            if is_exe(program):
                return program
        else:
            for path in os.environ["PATH"].split(os.pathsep):
                exe_file = os.path.join(path, program)
                for candidate in ext_candidates(exe_file):
                    if is_exe(candidate):
                        return candidate
        return None

    def virtualenv_command(self, env_path):
        
        timeout = configuration.general_section.subprocess_timeout
        
        if not self.which("virtualenv"):
            raise ValueError("Cannot find virtual. Please install virtualenv.")
        active_path = os.path.join(env_path, "bin", "activate")
        if not os.path.isfile(active_path):
            cmd = ["virtualenv",  "--system-site-packages"]
            cmd.append(env_path)
            system(*cmd, 
                   env=self.get_environ(), 
                   timeout=timeout)
        else:
            print("No need to virtualenv init '%s' since it is already initialized." \
                % env_path)
        pass


class PackageDirectory(ComponentsConfigParser, ConfigVariableParser):

    _path_variables = set(('directory', 
                           'build_directory',
                           'installer_filename',
                           'offline_installer_filename',
                           'data_repos_dir', 'test_install_dir',
                           'stdout_file', 'stderr_file', 'test_ref_data_dir',
                           'test_run_data_dir', 'remote_installer_filename',
                           'remote_offline_installer_filename',
                           'remote_repos_dir', 'remote_data_repos_dir',
                           'remote_test_install_dir',
                           'remote_test_ref_data_dir',
                           'remote_test_run_data_dir'))
    _variables_with_replacements = set(('package_repository_subdir', 
                                        'pack_version', 'directory_id',
                                        'packaging_options',
                                        'make_options', 'ctest_options',
                                        'installer_options'))
    _variables_with_env_only_replacements = set(('env',
                                                 'test_ref_data_dir',
                                                 'test_run_data_dir',
                                                 'remote_test_ref_data_dir',
                                                 'remote_test_run_data_dir'))
    _validAdditiveOptions = set(('packaging_options', 'default_steps',
                                 'make_options', 'ctest_options', 'env',
                                 'installer_options'))
    _validOptions = set(('build_condition',
                         'remote_test_host_cmd',
                         'init_components_from_build_dir',
                         'keep_n_older_repos'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)

    def __init__(self, directory, configuration):
        super(PackageDirectory, self).__init__(directory, configuration)
        self.build_directory = ''
        self.package_repository_subdir = 'packages'
        self.packaging_options = []
        #self.packaging_thirdparty = ''
        self.installer_filename = None
        self.installer_options = ''
        self.offline_installer_filename = None
        self.data_repos_dir = ''
        self.test_install_dir = ''
        self.init_components_from_build_dir = 'ON'
        self.pack_version = None
        self.pathvars = None
        self.default_steps = []
        self.keep_n_older_repos = 1
        self.ctest_options = []
        self.make_options = []
        self.directory_id = ''
        self.env = {}
        self.test_ref_data_dir = ''
        self.test_run_data_dir = tempfile.gettempdir()
        self.remote_installer_filename = None
        self.remote_offline_installer_filename = None
        self.remote_repos_dir = None
        self.remote_data_repos_dir = None
        self.remote_test_install_dir = None
        self.remote_test_host_cmd = None
        self.remote_test_ref_data_dir = None
        self.remote_test_run_data_dir = None

    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ pack ... ]:
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            line = os.path.expandvars(line)
            if line[0] == '+':
                if '*' in line:
                    raise SyntaxError()
        self.configurationLines.append(line)

    #def validate_option(self, option):
        #if option in ('init_components_from_build_dir', 'build_directory'):
            #if self.build_directory not in ('', None):
                #if self.init_components_from_build_dir.upper() == 'ON':
                    #build_dir = self.get_build_dir()
                    #build_dir.process_configuration_lines()
                    #self.components = dict(build_dir.components)
                #else:
                    #self.components = {}
    
    #def get_matching_build_dirs(self):
        #build_dirs = []
        #for o in self.configuration.buildDirectories.values():
            #if normalize_path(
                #o.replace_vars(self._build_directory)) == o.directory:
                #build_dirs.append(o)
                
        #return build_dirs
        
    def get_build_dir(self):
        if not hasattr(self, 'build_dir'):
            #build_dirs = self.get_matching_build_dirs()
            build_dirs = get_matching_dirs(self.configuration.buildDirectories.values(),
                              self._build_directory)
            if len(build_dirs) == 0:
                raise RuntimeError(
                    'Package directory: referenced build directory "%s" does '
                    'not exist' % self.build_directory)
            elif len(build_dirs) > 1:
                raise RuntimeError(
                    'Package directory: referenced build directory "%s" '
                    'must match a unique build directory. Matches %d '
                    'directories %s' % (self.build_directory, len(build_dirs),
                                        str(build_dirs)))
            else:
                self.build_dir = build_dirs[0]
            
        return self.build_dir
        
    def get_data_dir(self):
        if not hasattr(self, 'data_dir'):
            data_dirs = get_matching_dirs(self.configuration.packageDirectories.values(),
                              self._data_repos_dir)
            if len(data_dirs) == 0:
                self.data_dir = None
                
            elif len(data_dirs) > 1:
                raise RuntimeError(
                    'Package directory: referenced data directory "%s" '
                    'must match a unique package directory. Matches %d '
                    'directories %s' % (self.data_repos_dir, len(data_dirs),
                                        str(data_dirs)))
            else:
                self.data_dir = data_dirs[0]
            
        return self.data_dir
    
    def set_dependencies(self):                
        build_section = self.get_build_dir()
        
        if build_section is not None:
            build_section = [(build_section, 'build'),
                             (build_section, 'doc'),
                             (build_section, 'test')]
        else:
            build_section = []
        self.depend_on_sections = {
            'pack': build_section,
            'install_pack': [(self, 'pack')],
            'test_pack': [(self, 'install_pack')],
            'testref_pack': [(self, 'install_pack')],
        }

    def process_configuration_lines(self):
        if not self._configuration_lines_processed:
            build_dir = self.get_build_dir()

            if self.init_components_from_build_dir.upper() == 'ON':
                build_dir.process_configuration_lines()
                # make sure to do an actual copy of build dir projects/components
                self.projects = list(build_dir.projects)
                self.components = dict(build_dir.components)
            super(PackageDirectory, self).process_configuration_lines()

    def info(self):
        self.process_configuration_lines()
        print('Base package directory: "' + self._directory + '"')
        print('  Real base package directory:', self.directory)
        print('  Real final package repository:', os.path.join(self.directory, self.package_repository_subdir))
        print('  Real temporary package repository:', 
              os.path.join(self.directory, self.package_repository_subdir) + '_tmp')
        print('  Build directory:', self.build_directory)
        for component, directory_version_model \
                in six.iteritems(self.components):
            directory, selected_version, version, build_model \
                = directory_version_model
            print('  %s (%s) <- %s' % (component, version, directory))

    def get_pack_version(self):
        if self.pack_version:
            version = self.pack_version
        else:
            version = '1.0.0'

            if not self._property_recursivity.get('build_directory'):
                build_dir = self.get_build_dir()
                v = build_dir.get_version()
                if v:
                    version = v
        return version
        
    def __init_python_vars(self):
        online = 'online'
        offline = 'offline'
        
        if not self._property_recursivity.get('build_directory'):
            build_dir = self.get_build_dir()
            self.update_python_vars(build_dir.get_python_vars())
        
        if not self._property_recursivity.get('packaging_options'):
            # Add i2bm and public vars
            i2bm_str = 'public'
            public = ''

            if '--i2bm' in self.packaging_options:
                i2bm_str = 'i2bm'
                public = '-i2bm'
            self.update_python_vars({'i2bm': i2bm_str, 
                                     'public': public})

        if not self._property_recursivity.get('pack_version'):
            # Add version var
            self.update_python_vars({'version': self.get_pack_version()})
            
        # Add online var and local variables
        self.update_python_vars({'online': online, 
                                 'offline': offline})
    
    def installer_variables(self):
        return self.get_python_vars()
    
    def installer_cmdline(self):
        components = list(self.components.keys())
        projects = list(self.projects)
        pack_options = self.packaging_options
        installer_filename = self.installer_filename
        #if not installer_filename:
            #installer_filename = os.path.join(
                #os.path.dirname(self.directory),
                #'brainvisa-installer/brainvisa_installer-'
                #'%(version)s-%(os)s-%(online)s%(public)s')
      
        offline_installer_filename = self.offline_installer_filename
        #directory = self.replace_vars(self.directory)
        directory = os.path.join(self.directory, self.package_repository_subdir)

        exe_suffix = ''
        if sys.platform == 'win32':
            exe_suffix = '.exe'

        # if bv_build_installer is in the build tree, use it
        bvi = os.path.join(self.build_directory, 'bin',
                           'bv_build_installer.py')
        if not os.path.exists(bvi):
            # otherwise use the path
            bvi = distutils.spawn.find_executable('bv_build_installer.py')
        cmd = [os.path.join(self.build_directory, 'bin',
                            'bv_env_host%s' % exe_suffix),
               sys.executable, bvi, '-r', directory]
        if installer_filename:
            cmd += ['-i', installer_filename]
            if not offline_installer_filename:
                cmd.append('--online-only')
        if offline_installer_filename:
            from brainvisa.installer import version as bvi_ver
            if [int(x) for x in bvi_ver.version.split('.')] >= [1, 2]:
                cmd += ['-j', offline_installer_filename]
                
                data_dir = self.get_data_dir()
                if data_dir and data_dir.directory:
                    # Add data directory as an additional repository to allow
                    # binarycreator to find data packages to embed in the 
                    # offline installer
                    cmd += ['-f', os.path.join(
                        data_dir.directory, 
                        data_dir.package_repository_subdir)]
            else:
                print('warning: bv installer version too old to handle '
                      'offline + online installers at the same time.')
            if not installer_filename:
                cmd.append('--offline-only')
        if not installer_filename and not offline_installer_filename:
            cmd.append('--repository-only')
        cmd += pack_options + ['-p'] + projects + ['-n'] + components
        return cmd

    def make_install_script(self, install_dir, repos_dir, data_repos_dir,
                            temp_dir=None):

        fd, script_fname = tempfile.mkstemp(prefix='install_script',
                                            dir=temp_dir)
        os.close(fd)
        
        install_dir = self.build_dir.to_target_path(install_dir)
        
        if not repos_dir.startswith('file://'):
            repos_dir = self.build_dir.to_target_path(repos_dir) \
                        .to_system('uri')
 
        if data_repos_dir:
            if not data_repos_dir.startswith('file://'):
                data_repos_dir = self.build_dir.to_target_path(data_repos_dir) \
                                 .to_system('uri')
           
            data_repos_dir_url = ', "%s"' % data_repos_dir
        else:
            data_repos_dir_url = ""
            
        

        with open(script_fname, 'w') as f:
            f.write('''var install_dir = "%s";
var repositories = ["%s"%s];

function Controller()
{
    print("controller instanciated");

    installer.currentPageChanged.connect(OnCurrentPageChangedCallback);
    installer.installationStarted.connect(OnInstallationStartedCallback);
    installer.installationFinished.connect(OnInstallationFinishedCallback);
    installer.installationInterrupted.connect(OnInstallationInterruptedCallback);

    installer.autoRejectMessageBoxes;
    
    installer.setMessageBoxAutomaticAnswer("OverwriteTargetDirectory", 
                                           QMessageBox.Yes);
    
    installer.setMessageBoxAutomaticAnswer("installationError", 
                                           QMessageBox.OK);

    installer.setMessageBoxAutomaticAnswer("installationErrorWithRetry", 
                                           QMessageBox.Cancel);

    installer.setMessageBoxAutomaticAnswer("AuthorizationError", 
                                           QMessageBox.Abort);

    installer.setMessageBoxAutomaticAnswer("OperationDoesNotExistError", 
                                           QMessageBox.Abort);
                                           
    installer.setMessageBoxAutomaticAnswer("isAutoDependOnError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("isDefaultError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("isDefaultError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("DownloadError", 
                                           QMessageBox.Cancel);
    
    installer.setMessageBoxAutomaticAnswer("archiveDownloadError", 
                                           QMessageBox.Cancel);
    
    installer.setMessageBoxAutomaticAnswer("WriteError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("ElevationError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("unknown", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("Error", 
                                           QMessageBox.OK);
                                                                              
    installer.setMessageBoxAutomaticAnswer("stopProcessesForUpdates", 
                                           QMessageBox.Ignore);
                                           
    installer.setMessageBoxAutomaticAnswer("Installer_Needs_To_Be_Local_Error", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("TargetDirectoryInUse", 
                                           QMessageBox.No);
                                           
    installer.setMessageBoxAutomaticAnswer("WrongTargetDirectory", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("AlreadyRunning", 
                                           QMessageBox.OK);
                                           
    //installer.setMessageBoxAutomaticAnswer("cancelInstallation", 
    //                                       QMessageBox.Yes);                                   
}

OnInstallationStartedCallback = function()
{
    print("installation started");
}

OnInstallationFinishedCallback = function()
{
    print("installation ended");
    // This is necessary for windows
    gui.clickButton(buttons.NextButton);
}

OnInstallationInterruptedCallback = function()
{
    print("installation interrupted");
}

OnCurrentPageChangedCallback = function(page)
{
    print("page changed");
}

Controller.prototype.IntroductionPageCallback = function()
{
    print("introduction page");
    installer.setTemporaryRepositories(repositories, true);
    gui.clickButton(buttons.NextButton)
}

Controller.prototype.TargetDirectoryPageCallback = function()
{
    print("target directory page");
    var widget = gui.currentPageWidget(); // get the current wizard page
    widget.TargetDirectoryLineEdit.setText(install_dir);
    print("install directory: " + widget.TargetDirectoryLineEdit.text)
    print("message: " + widget.MessageLabel.text)
    if (widget.WarningLabel)
    {
        print("warning: " + widget.WarningLabel.text)
    }
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.ComponentSelectionPageCallback = function()
{
    print("component selection page");
    var widget = gui.currentPageWidget();
    widget.selectAll();
    gui.clickButton(buttons.NextButton);
    //installer.setAutomatedPageSwitchEnabled(true);
}

Controller.prototype.LicenseAgreementPageCallback = function()
{
    print("licence agreement page");
    var widget = gui.currentPageWidget();
    widget.AcceptLicenseRadioButton.setChecked(true);
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.StartMenuDirectoryPageCallback = function()
{
    print("start menu directory page");
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.ReadyForInstallationPageCallback = function()
{
    print("ready for installation page");
    gui.clickButton(buttons.CommitButton);
}

Controller.prototype.PerformInstallationPageCallback = function()
{
    print("perform installation page");
    gui.clickButton(buttons.CommitButton);
}

Controller.prototype.FinishedPageCallback = function()
{
    print("finished page");
    gui.clickButton(buttons.FinishButton);
}

''' % (install_dir, repos_dir, data_repos_dir_url))
        return script_fname

    def package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        #directory = self.replace_vars(self.directory)
        directory = os.path.join(self.directory, self.package_repository_subdir)
        print('Building package:', directory)
        print('    from build dir:', self.build_dir.directory)
        self.cleanup_package_dir()
        cmd = self.installer_cmdline()
        print('running:', "'" + "' '".join(cmd) + "'")
        
            
        if subprocess32:
            subprocess32.check_call(cmd, cwd=self.build_dir.directory,
                                    env=self.get_environ(),
                                    timeout=timeout)
        else:
            subprocess.check_call(cmd, cwd=self.build_dir.directory,
                                  env=self.get_environ())

    @staticmethod
    def rm_with_empty_dirs(path):
        if os.path.isdir(path):
            shutil.rmtree(path)
        else:
            os.unlink(path)
        d = os.path.dirname(path)
        while d and len(os.listdir(d)) == 0:
            try:
                os.rmdir(d)
            except OSError:
                break
            d = os.path.dirname(d)

    @staticmethod
    def rm_with_empty_dirs_nofail(path):
        try:
            PackageDirectory.rm_with_empty_dirs(path)
        except OSError:
            pass # oh well...

    def cleanup_package_dir(self):
        #directory = self.replace_vars(self.directory)
        directory = os.path.join(self.directory, self.package_repository_subdir)
        dirs = [directory, directory + '_tmp']
        pack_options = self.packaging_options
        if '--skip-repos' not in pack_options \
                and '--skip-existing' not in pack_options:
            for d in dirs:
                if os.path.isdir(d):
                    shutil.rmtree(d)
        if os.path.isdir(directory):
            report_file = os.path.join(directory, 'tests_report.txt')
            if os.path.exists(report_file):
                os.unlink(report_file)
        # erase older repositories
        if '%(date)s' in os.path.join(self._directory,
                                      self._package_repository_subdir):
            real_vars = dict(self.installer_variables())
            real_vars.update(global_installer_datetime())
            vars = dict(real_vars) # copy vars
            vars['date'] = '*'
            my_dir = environmentPathVariablesSubstitution(
                os.path.join(self._directory,
                             self._package_repository_subdir), 
                env=self.get_environ()) % real_vars
            dir_pattern = environmentPathVariablesSubstitution(
                self._directory, env=self.get_environ()) % vars
            older_dirs = [d for d in glob.glob(dir_pattern) if d != my_dir]
            older_tmp_dirs = [d for d in glob.glob(dir_pattern + '_tmp')
                              if d != my_dir + '_tmp']
            # check in older repos if they were OK
            repos_to_remove = set()
            for d in older_dirs:
                report_file = os.path.join(d, 'tests_report.txt')
                if os.path.exists(report_file):
                    with open(report_file) as f:
                        report = f.readlines()
                    if report[-1].strip() != 'Tests_result: OK':
                        repos_to_remove.add(d)
                        print('removing older failed repos:', d)
            older_dirs = [d for d in older_dirs if d not in repos_to_remove]
            to_remove = set()
            for d in older_tmp_dirs:
                if not d[:-4] in older_dirs:
                    print('temp repos', d, 'has no real repos')
                    self.rm_with_empty_dirs_nofail(d)
                    to_remove.add(d)
            older_tmp_dirs = sorted([d for d in older_tmp_dirs
                                     if d not in to_remove])
            older_dirs = sorted(older_dirs)
            keep_n_older_repos = int(self.keep_n_older_repos)
            if len(older_dirs) > keep_n_older_repos:
                repos_to_remove.update(
                    older_dirs[:len(older_dirs) - keep_n_older_repos])
            # remove older repos and installs
            vars['date'] = '%(date)s' # keep date pattern as is
            pattern = environmentPathVariablesSubstitution(
                self._directory, env=self.get_environ()) % vars
            pattern = re.escape(pattern)
            # this replace restores the pattern '%(date)s' modified
            # by re.escape()
            pattern = pattern.replace(re.escape('%(date)s'), '%(date)s')
            pattern = re.compile(pattern % {'date': '(.+)'})
            for d in repos_to_remove:
                print('removing:', d)
                self.rm_with_empty_dirs_nofail(d)
                if d + '_tmp' in older_tmp_dirs:
                    print('removing:', d + '_tmp')
                    self.rm_with_empty_dirs_nofail(d + '_tmp')
                infos_file = os.path.join(os.path.dirname(d),
                                          'packages_infos.html')
                if os.path.exists(infos_file):
                    self.rm_with_empty_dirs_nofail(infos_file)
                m = pattern.match(d)
                r_date = m.group(1)
                vars['date'] = r_date
                # find associated installer
                if self.installer_filename:
                    installer = environmentPathVariablesSubstitution(
                        self._installer_filename,
                        env=self.get_environ()) % vars
                    if os.path.exists(installer):
                        print('removing:', installer)
                        self.rm_with_empty_dirs_nofail(installer)
                    if os.path.exists(installer + '.md5'):
                        self.rm_with_empty_dirs_nofail(installer + '.md5')
                    # check for lock file leaved after installer crash
                    lockfile = glob.glob(os.path.join(
                        os.path.dirname(installer), 'lock*.lock'))
                    for lock in lockfile:
                        self.rm_with_empty_dirs_nofail(lock)
                    # on Mac, remove .dmg files and .app directory
                    if sys.platform == 'darwin':
                        if os.path.exists(installer + '.dmg'):
                            self.rm_with_empty_dirs_nofail(installer + '.dmg')
                        if os.path.exists(installer + '.dmg.md5'):
                            self.rm_with_empty_dirs_nofail(
                                installer + '.dmg.md5')
                        if os.path.exists(installer + '.app'):
                            self.rm_with_empty_dirs_nofail(installer + '.app')
                # find associated install
                if self.test_install_dir:
                    install_dir = environmentPathVariablesSubstitution(
                        self._test_install_dir,
                        env=self.get_environ()) % vars
                    if os.path.exists(install_dir):
                        print('removing', install_dir)
                        self.rm_with_empty_dirs_nofail(install_dir)
                    # and tmp dir
                    tmp_dir = os.path.join(os.path.dirname(install_dir), 'tmp')
                    # remove it if empty
                    if os.path.isdir(tmp_dir) \
                            and len(os.listdir(tmp_dir)) == 0:
                        print('removing:', tmp_dir)
                        self.rm_with_empty_dirs_nofail(tmp_dir)


    def install_package(self, options, args):       
        #self.test_config(options, args)
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        #directory = self.replace_vars(self.directory)
        directory = os.path.join(self.directory, self.package_repository_subdir)
        
        if not self.test_install_dir:
            return IGNORED_STEP
        
        remote_test_install = True if self.remote_test_host_cmd \
                                      and not options.local \
                                      else False

        # Test install directory
        if options.prefix:
            test_install_dir = options.prefix
            remote_test_install_dir = options.prefix
        else:
            test_install_dir = self.test_install_dir
            if remote_test_install and self.remote_test_install_dir:
                remote_test_install_dir = self.remote_test_install_dir
            else:    
                remote_test_install_dir = test_install_dir

        # Temporary directory
        tmp_dir = os.path.join(os.path.dirname(test_install_dir), 'tmp')
        
        # Repository directory
        repos_dir = directory
        if remote_test_install and self.remote_repos_dir:
            remote_repos_dir = self.remote_repos_dir
        else:
            remote_repos_dir = repos_dir
        
        # Data repository directory
        data_dir = self.get_data_dir()
        if data_dir and data_dir.directory:
            data_repos_dir = os.path.join(
                data_dir.directory, 
                data_dir.package_repository_subdir)
            data_repos_dir = self.replace_vars(data_repos_dir)
            
        else:
            data_repos_dir = ''
            
        if remote_test_install and self.remote_data_repos_dir:
            remote_data_repos_dir = self.remote_data_repos_dir
            if data_dir is not None:
                remote_data_repos_dir = \
                    os.path.join(remote_data_repos_dir,
                                 data_dir.package_repository_subdir)
        elif data_repos_dir:
            remote_data_repos_dir = data_repos_dir
        else:
            remote_data_repos_dir = None

        use_online_installer = not options.offline \
            and self.installer_filename is not None
        
        if not use_online_installer \
           and self.offline_installer_filename is not None:
            installer_filename = self.offline_installer_filename
        else:        
            installer_filename = self.installer_filename
            
        if remote_test_install:
            if not use_online_installer \
               and self.remote_offline_installer_filename is not None:
                remote_installer_filename = self.remote_offline_installer_filename
            elif self.remote_installer_filename is not None:
                remote_installer_filename = self.remote_installer_filename
            else:
                remote_installer_filename = installer_filename

        else:
            remote_installer_filename = installer_filename

        print('Installing package:', directory)
        print('    with installer:', remote_installer_filename)
        if(data_repos_dir):
            print('    using data package:', data_repos_dir)
        print('    from build dir:', self.build_dir.directory)
        print('    to:', test_install_dir)
        if remote_test_install:
            print('    remote:', self.remote_test_host_cmd)

        if os.path.isdir(test_install_dir):
            print('removing previous test installation...')
            shutil.rmtree(test_install_dir)

        #if os.path.isdir(tmp_dir):
            #print('removing previous temporary directory...')
            #shutil.rmtree(tmp_dir)

        if not os.path.exists(test_install_dir):
            print('creating test directory...')
            os.makedirs(test_install_dir)

        if not os.path.exists(tmp_dir):
            print('creating temporary directory...')
            os.makedirs(tmp_dir)

        if use_online_installer \
            and (not os.path.isdir(repos_dir) \
                 or (data_repos_dir is not None \
                 and not os.path.isdir(data_repos_dir))):
            # For offline package installation these directories are not 
            # necessary
            raise RuntimeError('Some repositories are missing (%s, %s). ' \
                'Installation may fail.' % (repos_dir, data_repos_dir))

        install_script = self.make_install_script( 
            remote_test_install_dir, 
            remote_repos_dir, 
            remote_data_repos_dir, 
            temp_dir=tmp_dir)

        cmd = []
        if remote_test_install:
            cmd = shlex.split(self.remote_test_host_cmd)

        if sys.platform == 'darwin':
            # on Mac, the installer is a .app
            remote_installer_filename += '.app/Contents/MacOS/%s' \
                % os.path.basename(remote_installer_filename)
        cmd += [remote_installer_filename] \
               + shlex.split(self.installer_options) \
               + ['--script', self.build_dir.to_target_path(install_script)]
        try:
            print('installing...')
            # the ssh command needs to be converted to a string, some options
            # do not pass when check_call() is used with a list.
            cmd = '"' + '" "'.join([x.replace('"', '\"') for x in cmd]) + '"'
            print(cmd)
            # setup QT_QPA_PLATFORM=minimal envar to avoid need for
            # GUI/X server. Note that if remote_test_host_cmd is used (ssh or
            # other), it will need to re-export this variable in the remote
            # context to be taken into account.
            env = dict(self.get_environ())
            env['QT_QPA_PLATFORM'] = 'minimal'
            
            if subprocess32:
                subprocess32.check_call(cmd, shell=True, env=env, timeout=timeout)
            else:
                subprocess.check_call(cmd, shell=True, env=env)
                
            print('done.')
        finally:
            if not options.debug:
                os.unlink(install_script)

    def init_vars(self):        
        super(PackageDirectory, self).init_vars()
        
        self.__init_python_vars()
        self.__init_environ()
        
    def __init_environ(self):
        env = {}
        # binaries are in bin/real-bin/ (used by some python tests commands)
        env['BRAINVISA_REAL_BIN'] = '/real-bin'
        
        if not self._property_recursivity.get('remote_test_host_cmd'):
            if self.remote_test_host_cmd \
                and (not self._property_recursivity.get(
                    'remote_test_install_dir')) \
                and self.remote_test_install_dir:
                install_dir = self.remote_test_install_dir
                env['BRAINVISA_PACKAGE_INSTALL_PREFIX'] = install_dir            
            elif (not self._property_recursivity.get('test_install_dir')) \
                and self.test_install_dir:
                install_dir = self.test_install_dir
                env['BRAINVISA_PACKAGE_INSTALL_PREFIX'] = install_dir
    
            if (not self._property_recursivity.get('build_directory')):
                build_dir = self.configuration.buildDirectories.get(
                    self.build_directory)

                if build_dir:
                    if self.remote_test_host_cmd \
                        and (not self._property_recursivity.get(
                            'remote_test_run_data_dir')) \
                        and self.remote_test_run_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_RUN_DATA_DIR"] = \
                            build_dir.to_target_path(self.remote_test_run_data_dir)
                    elif (not self._property_recursivity.get(
                            'test_run_data_dir')) \
                         and self.test_run_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_RUN_DATA_DIR"] = \
                            build_dir.to_target_path(self.test_run_data_dir)
                    
                    if self.remote_test_host_cmd \
                        and (not self._property_recursivity.get(
                            'remote_test_ref_data_dir')) \
                        and self.remote_test_ref_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_REF_DATA_DIR"] = \
                            build_dir.to_target_path(self.remote_test_ref_data_dir)
                    elif (not self._property_recursivity.get(
                            'test_ref_data_dir')) \
                        and self.test_ref_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_REF_DATA_DIR"] = \
                            build_dir.to_target_path(self.test_ref_data_dir)
            
            if self.remote_test_host_cmd:
                # temporarily change os.environ since expand_shell uses
                # os.path.expandvars(), which use os.environ variables
                cur_env = os.environ
                os.environ = dict(os.environ)
                os.environ.update(env)
                env['BRAINVISA_TEST_REMOTE_COMMAND'] \
                    = self.expand_shell(self.remote_test_host_cmd)
                os.environ = cur_env
                
        self.update_environ(env)
        
        return env
    
    def reset_environ(self):
        super(PackageDirectory, self).reset_environ()
        self.__init_environ()
        
    def test_package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()
        
        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        if not self.test_install_dir:
            return IGNORED_STEP
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir is not defined; tests may fail.")
        # Create test_run_data_dir and test_ref_data_dir
        if self.test_run_data_dir \
                and not os.path.exists(self.test_run_data_dir):
            os.makedirs(self.test_run_data_dir)
        if self.test_ref_data_dir \
                and not os.path.exists(self.test_ref_data_dir):
            os.makedirs(self.test_ref_data_dir)
        print('Testing package:', self.directory)
        print('    from build dir:', self.build_dir.directory)
        install_dir = self.test_install_dir
        # Add directories to env
        new_env = self.get_environ(dict(os.environ))
        repos_dir = self.replace_vars(
            os.path.join(self.directory,
                         self.package_repository_subdir))
        report_file = os.path.join(repos_dir, 'tests_report.txt')
        if options.ctest_options is not None:
            ctoptions = shlex.split(options.ctest_options)
        else:
            ctoptions = self.ctest_options
        test_res = run_and_log_tests(cwd=self.build_dir.directory,
                                     env=new_env, options=ctoptions,
                                     projects=self.projects,
                                     timeout=timeout)
        if test_res:
            status = 'OK'
            for item in six.itervalues(test_res):
                if item['exception'] is not None:
                    status = 'FAILED'
            if os.path.isdir(repos_dir):
                with open(report_file, 'w') as f:
                    f.write('Tests_result: %s\n' % status)
        elif os.path.isdir(repos_dir):
            with open(report_file, 'w') as f:
                f.write('Tests_result: OK\n')
        return test_res

    def testref_package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()

        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        if not self.test_install_dir:
            return IGNORED_STEP
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir should be defined to create "
                  "reference files.")
        # Create test_ref_data_dir
        if self.test_ref_data_dir \
                and not os.path.exists(self.test_ref_data_dir):
            os.makedirs(self.test_ref_data_dir)
        if options.make_options is not None:
            ctoptions = shlex.split(options.make_options)
        else:
            ctoptions = self.make_options
        print('Creating test reference files for package:', self.directory)
        print('    from build dir:', self.build_dir.directory)
        install_dir = self.test_install_dir
        # Add directories to env
        new_env = self.get_environ(dict(os.environ))
        test_res = run_and_log_testref(cwd=self.build_dir.directory,
                                       env=new_env, options=ctoptions,
                                       timeout=timeout)
        return test_res

    def expand_shell(self, line):
        ''' Allow shell commands expressions $(command arg) in string
        '''
        patt = re.compile(r'\$\(([^\)]+)\)')
        expressions = patt.split(os.path.expandvars(line))
        new_line = expressions.pop(0)
        while expressions:
            expr = expressions.pop(0)
            text = subprocess.check_output(expr, shell=True).strip()
            new_line += text
            new_line += expressions.pop(0)
        return ' '.join(shlex.split(new_line))


class PublicationDirectory(DirectorySection, ConfigVariableParser):

    _path_variables = set(('package_directory', 
                           'stdout_file', 'stderr_file'))
    _variables_with_replacements = set(('directory', 'directory_id', 
                                        'publication_commands'))
    _variables_with_env_only_replacements = set(('env',))
    _validAdditiveOptions = set(('publication_commands', ))
    _validOptions = set(('build_condition', ))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)

    def __init__(self, directory, configuration):
        super(PublicationDirectory, self).__init__()
        
        self.configuration = configuration       
        self.directory = directory
        self.package_directory = ''
        self.pathvars = None
        self.default_steps = []
        self.publication_commands = []
        self.directory_id = ''
        self.env = {}

    def init_vars(self):
        super(PublicationDirectory, self).init_vars()
        
        self.__init_python_vars()
        
    def __init_python_vars(self):
        package_dir = self.get_package_dir()
        
        # Add same python variables than pack section
        self.update_python_vars(package_dir.get_python_vars())
        
    def get_package_dir(self):
        if not hasattr(self, 'package_dir'):
            package_dirs = get_matching_dirs(
                self.configuration.packageDirectories.values(),
                self.package_directory)
            if len(package_dirs) == 0:
                raise RuntimeError(
                    'Package directory: referenced package directory "%s" does '
                    'not exist' % self.package_directory)
            elif len(package_dirs) > 1:
                raise RuntimeError(
                    'Package directory: referenced package directory "%s" '
                    'must match a unique package directory. Matches %d '
                    'directories %s' % (self.package_directory, 
                                        len(package_dirs),
                                        str(package_dirs)))
            else:
                self.package_dir = package_dirs[0]
            
        return self.package_dir
    
    def get_build_dir(self):
        return self.get_package_dir().get_build_dir()
    
    def set_dependencies(self):                
        pack_section = self.get_package_dir()
        
        if pack_section is not None:
            pack_section = [(pack_section, 'pack')]
        else:
            pack_section = []
            
        self.depend_on_sections = {
            'publish': pack_section,
        }

    #def test_config(self, options, args):
        #package_dir = self.get_package_dir()
        #build_dir = package_dir.get_build_dir()

    def info(self):
        print('Publication package directory: "' + self._directory + '"')
        print('  Real publication package directory:', self.directory)
        print('  Package directory:', self.package_directory)
        print('  Build directory:', self.get_package_dir().build_directory)

    def publish_package(self, options, args):       
        #self.test_config(options, args)
        self.process_configuration_lines()

        timeout = configuration.general_section.subprocess_timeout
        timeout = getattr(options, 'subprocess_timeout', timeout)
        
        package_dir = self.get_package_dir()
        if not package_dir:
            return IGNORED_STEP
            
        print('Running commands for package publication', 
              self.package_directory, '=>', self.directory)

        # These values can only be added to python variables when they are
        # completely solved from the command
        self.update_python_vars({'package_directory': self.package_directory,
                                 'publication_directory': self.directory})
        
        if not self.publication_commands:
            # Default publication command
            self.publication_commands = [
                'cmake -E copy_directory '
                '"%(package_directory)s/brainvisa-installer" '
                '"%(package_directory)s/packages" '
                '"%(package_directory)s/packages_tmp" '
                '"%(publication_directory)s"']

        env = self.get_environ()
        for c in self.publication_commands:
            command = shlex.split(c)
            system_output_on_error(command, env = env, timeout=timeout)
            

def display_failure_summary(configuration):
    sections = [('sourcesDirectories', ['sources']),
                ('buildDirectories', ['configure', 'build', 'doc', 'testref',
                                      'test']),
                ('packageDirectories', ['pack', 'install_pack', 'testref_pack',
                                        'test_pack']),
                ('publicationDirectories', ['publish_pack']),
                ]
    global_failed = False
    status_map = {'not run': '',
                  'succeeded': 'OK         ',
                  'failed': 'FAILED     ',
                  'unmet dependency': 'UNMET DEP  ',
                  'interrupted': 'INTERRUPTED'}
    sys.stdout.flush()
    sys.stderr.flush()
    messages = ['\nbv_maker summary:']
    print(messages[0])
    #log_file = None
    #if configuration.general_section \
            #and configuration.general_section.global_status_file:
        #log_file = configuration.general_section.global_status_file
        #machine = gethostname()
        #osname = global_installer_variables()['os']
    first_start = None
    last_stop = None
    for section_name, steps in sections:
        for section in getattr(configuration, section_name).values():
            for step in steps:
                status = status_map[section.get_status(step)]
                if status != '':
                    message = '%s step %s: %s' % (status, step, 
                                                  section.directory)
                    start = section.start_time.get(step)
                    if start:
                        if first_start is None:
                            first_start = start
                        message += ', started: %04d/%02d/%02d %02d:%02d' \
                            % start[:5]
                    stop = section.stop_time.get(step)
                    if stop:
                        last_stop = stop
                        message += ', stopped: %04d/%02d/%02d %02d:%02d' \
                            % stop[:5]
                    messages.append(message)
                    print(message)
                    if section.has_failed(step):
                        global_failed = True
    if global_failed:
        status = 'There were errors.'
        print(status)
    else:
        status = 'All went good.'
        print(status)
    if not configuration.options.disable_jenkins and configuration.general_section.jenkins_server_url:
        global casa_environment
        global jenkins_server
        
        jenkins_server.create_build(environment=casa_environment,
            task='bv_maker finished',
            result=(1 if global_failed else 0),
            log='\n'.join(messages) + '\n')

    return global_failed

# ---

# export cpu_count() as NCPU env variable so that it can be used in conf file
# for env replacements
try:
    os.environ['NCPU'] = str(multiprocessing.cpu_count())
except NotImplementedError:
    # multiprocessing.cpu_count can raise NotImplementedError
    os.environ['NCPU'] = '1'

check_ld_library_path_error(fatal=False)

commands = {
    'info': InfoCommand,
    'sources': SourcesCommand,
    'status': SourceStatusCommand,
    'configure': ConfigureCommand,
    'build': BuildCommand,
    'doc': DocCommand,
    'test': TestCommand,
    'testref': TestrefCommand,
    'pack': PackCommand,
    'install_pack': InstallPackCommand,
    'test_pack': TestPackCommand,
    'testref_pack': TestrefPackCommand,
    'publish_pack': PublishPackCommand,
}

default_commands = ['info', 'sources', 'configure', 'build', 'doc', 'test',
                    'pack', 'install_pack', 'test_pack']
options_by_command = {None: []}
command = None
for i in sys.argv[1:]:
    if i in commands:
        command = i
        if command in options_by_command:
            raise ValueError('Command %s used twice' % command)
        options_by_command[command] = []
    else:
        options_by_command[command].append(i)

# Initialize global configuration
configuration = GlobalConfiguration(options_by_command[None])

# Parse commands options and prepare them for processing in the correct order
todo = []
if len(options_by_command) == 1:
    # No command selected => do all default commands
    for i in default_commands:
        options_by_command[i] = ['--only-if-default']

log_something = False
# Ordered command list
for command in ['info', 'status', 'sources', 'configure', 'build',
                'doc', 'test', 'testref', 'pack', 'install_pack', 'test_pack',
                'testref_pack', 'publish_pack']:
    if command in options_by_command:
        todo.append(
            commands[command](options_by_command[command], configuration))
        if command not in ('info', 'status') \
                and '-h' not in options_by_command[command] \
                and '--help' not in options_by_command[command]:
            log_something = True

if not log_something:
    # if no "real" job is required (help options used or only get info/status), 
    # then disable Jenkins logging
    configuration.options.disable_jenkins = True
    
if (not configuration.options.disable_jenkins and
    configuration.general_section.jenkins_server_url):
    
    import requests
    
    if configuration.general_section.casa_environment:
        casa_environment = configuration.general_section.casa_environment
    else:
        casa_environment = os.environ.get('CASA_ENVIRONMENT')
        if not casa_environment:
            raise ValueError('No name for Jenkins environment. '
                'Either set CASA_ENVIRONMENT env var or set casa_environment '
                'in bv_maker.cfg [general] section')
    jenkins_server = BrainVISAJenkins(
        configuration.general_section.jenkins_server_url,
        configuration.general_section.jenkins_username,
        configuration.general_section.jenkins_token)
    if not jenkins_server.job_exists(casa_environment):
        jenkins_server.create_job(casa_environment,
            distro=os.environ.get('CASA_DISTRO', 'unknown'),
            branch=os.environ.get('CASA_BRANCH', 'unknown'),
            system=os.environ.get('CASA_SYSTEM', 'unknown'))
    jenkins_server.create_build(environment=casa_environment,
        task='start bv_maker',
        result=0,
        log=' '.join("'%s'" %i for i in sys.argv) + '\n')

                                  

failed = False
# Execute selected commands
try:
    for f in todo:
        f()
except KeyboardInterrupt:
    traceback.print_exc()
    failed = True

failed |= display_failure_summary(configuration)

if failed:
    sys.exit(1)
