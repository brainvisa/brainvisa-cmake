#! /usr/bin/env python2
# -*- coding: utf-8 -*-

#  This software and supporting documentation are distributed by
#      Institut Federatif de Recherche 49
#      CEA/NeuroSpin, Batiment 145,
#      91191 Gif-sur-Yvette cedex
#      France
#
# This software is governed by the CeCILL-B license under
# French law and abiding by the rules of distribution of free software.
# You can  use, modify and/or redistribute the software under the
# terms of the CeCILL-B license as circulated by CEA, CNRS
# and INRIA at the following URL "http://www.cecill.info".
#
# As a counterpart to the access to the source code and  rights to copy,
# modify and redistribute granted by the license, users are provided only
# with a limited warranty  and the software's author,  the holder of the
# economic rights,  and the successive licensors  have only  limited
# liability.
#
# In this respect, the user's attention is drawn to the risks associated
# with loading,  using,  modifying and/or developing or reproducing the
# software by the user in light of its specific status of free software,
# that may mean  that it is complicated to manipulate,  and  that  also
# therefore means  that it is reserved for developers  and  experienced
# professionals having in-depth computer knowledge. Users are therefore
# encouraged to load and test the software's suitability as regards their
# requirements in conditions enabling the security of their systems and/or
# data to be ensured and,  more generally, to use and operate it in the
# same conditions as regards security.
#
# The fact that you are presently reading this means that you have had
# knowledge of the CeCILL-B license and that you accept its terms.

from __future__ import print_function
import sys
import os
import re
import pprint
import subprocess
import glob
import shutil
import json
from optparse import OptionParser
from fnmatch import fnmatchcase
import tempfile
import datetime
import distutils.spawn
import platform
import shlex
import time
import traceback
from smtplib import SMTP
import gzip

try:
    # backport of subprocess of python 3
    import subprocess32
except ImportError:
    subprocess32 = None
try:
    import jenkins
    if '_get_job_folder' not in jenkins.Jenkins.__dict__:
        def get_job_folder(self, name):
            '''Return the name and folder (see cloudbees plugin).

            This is a method to support cloudbees folder plugin.
            Url request should take into account folder path when the job name specify it
            (ex.: 'folder/job')

            :param name: Job name, ``str``
            :returns: Tuple [ 'folder path for Request', 'Name of job without folder path' ]
            '''

            a_path = name.split('/')
            short_name = a_path[-1]
            folder_url = (('job/' + '/job/'.join(a_path[:-1]) + '/')
                          if len(a_path) > 1 else '')

            return folder_url, short_name

        jenkins.Jenkins._get_job_folder = get_job_folder
        del get_job_folder

    if '_build_url' not in jenkins.Jenkins.__dict__:
        from six.moves.urllib.parse import urljoin

        def build_url(self, format_spec, variables=None):

            if variables:
                url_path = format_spec % self._get_encoded_params(variables)
            else:
                url_path = format_spec

            return urljoin(self.server, url_path)

        jenkins.Jenkins._build_url = build_url
        del build_url

    if '_get_encoded_params' not in jenkins.Jenkins.__dict__:
        from six.moves.urllib.parse import quote

        def get_encoded_params(self, params):
            for k, v in params.items():
                if k in ["name", "msg", "short_name", "from_short_name",
                        "to_short_name", "folder_url", "from_folder_url",
                        "to_folder_url"]:
                    params[k] = quote(v)
            return params

        jenkins.Jenkins._get_encoded_params = get_encoded_params
        del get_encoded_params

    if 'Request' not in jenkins.__dict__:
        from urllib2 import Request
        jenkins.Request = Request

except ImportError:
    # jenkins module is not here
    jenkins = None
try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen
try:
    # compatibility for python3
    import six
except ImportError:
    # six module not here, assume python2
    class six(object):
       @staticmethod
       def iteritems(obj, *args, **kwargs):
          return obj.iteritems(*args, **kwargs)
try:
    from cStringIO import StringIO
except ImportError:
    # python3
    from io import StringIO

# the following imports are just to make functions available in tests
# using eval() in filters/conditions
from socket import gethostname

# Ugly hack to backport subprocess.check_ouput method on python < 2.7
# TODO: remove this once BrainVISA is only compatible with python >= 2.7
if "check_output" not in dir(subprocess):  # duck punch it in!
    def f(*popenargs, **kwargs):
        if 'stdout' in kwargs:
            raise ValueError(
                'stdout argument not allowed, it will be overridden.')
        process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs,
                                   **kwargs)
        output, unused_err = process.communicate()
        retcode = process.poll()
        if retcode:
            cmd = kwargs.get("args")
            if cmd is None:
                cmd = popenargs[0]
            raise subprocess.CalledProcessError(retcode, cmd)
        return output
    subprocess.check_output = f

if os.path.exists(sys.argv[0]):
    this_script = sys.argv[0]
else:
    this_script = None
    for p in os.environ.get('PATH', '').split(os.pathsep) + [os.curdir]:
        s = os.path.join(p, sys.argv[0])
        if os.path.exists(s):
            this_script = s
            break
if this_script:
    this_script = os.path.normpath(os.path.abspath(this_script))
    python_modules = os.path.join(
        os.path.dirname(os.path.dirname(this_script)), 'python')
    if os.path.isdir(python_modules):
        sys.path.insert(0, python_modules)

import brainvisa.maker.components_definition
import brainvisa.maker.brainvisa_projects as brainvisa_projects

from brainvisa.maker.path import DefaultPathConverterRegistry, \
                                 Path, SystemPathConverter, \
                                 get_host_path_system
from brainvisa.maker.version import version as brainvisa_cmake_version

from brainvisa.maker.version_number import VersionNumber
from brainvisa.maker.version_number import version_format_short

IGNORED_STEP = 'ignored'
jenkins_cli = None
jenkins_wrapper = None

if this_script:
    cmake_root = os.path.join(os.path.dirname(this_script),
                              '..', 'share', 'brainvisa-cmake-%s' %
                              str(VersionNumber(
                                    brainvisa_cmake_version,
                                    version_format_short)),
                              'cmake')
    #print('cmake_root:', cmake_root)


def get_target_path_system(platform):
    if platform.startswith('win'):
        # We prefer alternative windows path i.e. pathes separated 
        # with slaches instead of back slaches
        return 'windows'
    
    else:
        return 'linux'

def system(*args, **kwargs):
    print(' '.join(args))
    if subprocess32 is not None:
        popen = subprocess32.Popen(args, **kwargs)
    else:
        if 'timeout' in kwargs:
            # timeout not supported in python2.subprocess
            kwargs = dict(kwargs)
            del kwargs['timeout']
        popen = subprocess.Popen(args, **kwargs)
    popen.communicate()
    if popen.returncode != 0:
        txt = 'Command failed: %s' % ' '.join((repr(i) for i in args))
        if 'cwd' in kwargs:
            txt = '%s\nFrom directory: %s' % (txt, kwargs['cwd'])
        raise OSError(txt)

def system_output_on_error(*args, **kwargs):
    # system_output_on_error is a bit strange currently:
    # on error an exception is raised and the output value is not passed
    # to the caller. Only stdout is used in this case, when the output
    # strings is actally useful in this situation.
    # However it should be in the exception e.output
    print(' '.join([str(x) for x in args]))
    try:
        if subprocess32 is not None:
            # !!! Redirecting STDERR to STDOUT is a burden on Windows OS and 
            # lead to enormous processing times using "wine" (x80) ... I do not
            # know why.
            # The issue can be reproduced using commands:
            # time python -c 'import subprocess;print subprocess.check_output(["winepath", "-u", "c:\\"]).strip()'
            # time python -c 'import subprocess;print subprocess.check_output(["winepath", "-u", "c:\\"], stderr=subprocess.STDOUT).strip()'
            output = subprocess32.check_output(*args, stderr=subprocess.STDOUT,
                                               **kwargs)
        else:
            if 'timeout' in kwargs:
                # timeout not supported in python2.subprocess
                kwargs = dict(kwargs)
                del kwargs['timeout']
            output = subprocess.check_output(*args, stderr=subprocess.STDOUT,
                                             **kwargs)
    except subprocess.CalledProcessError as e:
        print('-- failed command: --')
        print('-- command:', args)
        print('-- popen kwargs:', kwargs)
        print('-- return code: %d, output: --' % e.returncode)
        print(e.output)
        print('-- end of command outpput --')
        raise

    if sys.version_info[0] >= 3:
        output = output.decode()

    return output

def cmake_path(path):
    if sys.platform == 'win32':
        return Path(path, 'windows').to_system('windows_alt')
    else:
        return path

def copy_brainvisa_cmake(installDir):
    global this_script
    sourceDir = os.path.dirname(os.path.dirname(this_script))
    samefile = getattr(os.path, 'samefile', None)
    if samefile:
        samefile = samefile(sourceDir, installDir)
    else:
        samefile = sourceDir == installDir
    if samefile:
        return
    import brainvisa.maker
    for f in open(os.path.join(os.path.dirname(brainvisa.maker.__file__),
                               'installed_files.txt')):
        p, f = os.path.split(f.strip())
        d = os.path.join(installDir, p)
        if not os.path.exists(d):
            os.makedirs(d)
        shutil.copy(os.path.join(sourceDir, p, f), d)


def normalize_path(path):
    file_scheme = 'file://'
    has_file_scheme = path.startswith(file_scheme)
    if has_file_scheme:
        # Remove file scheme
        path = path[len(file_scheme):]
        
    # Try to detect windows pathes starting with drive letters
    # for cross compilation.
    # TODO: check only for cross compiling mode
    if not (len(path) > 1 and path[1] == ':'):
        path = os.path.normpath(os.path.realpath(os.path.abspath(path)))
    
    if has_file_scheme:
        # Add file scheme
        path = file_scheme + path
    
    return path
    
env_vars_regex = re.compile(r'\$([A-Za-z0-9_]*)')
python_vars_regex = re.compile(r'\%\(([A-Za-z0-9_]*)\)s')

def variablesSubstitution(parser, value, vars={}):
    result = value
    offset = 0
    for m in parser.finditer(value):
        content = vars.get(m.group(1))
        if content is not None:
            start, end = m.span()
            start += offset
            end += offset
            offset += len(content) - end + start
            result = result[:start] + content + result[end:]
    return result


def pythonVariablesSubstitution(value, python_vars={}):
    return variablesSubstitution(python_vars_regex, value, vars=python_vars)

def environmentVariablesSubstitution(value, env=None):
    if env is None:
        env = os.environ

    return variablesSubstitution(env_vars_regex, value, vars=env)

def environmentPathVariablesSubstitution(path, env=None):
    return normalize_path(environmentVariablesSubstitution(path, env))

def run_and_log_tests(cwd=None, env=None, options=None, projects=None):
    # get test labels to assign them to projects
    test_labels = system_output_on_error(
        ['ctest', '--print-labels'] + options, cwd=cwd)
    lines = test_labels.strip().split('\n')
    if 'All Labels:' in lines:
        labels_index = lines.index('All Labels:')
        labels = [line.strip() for line in lines[labels_index+1:]]
    elif 'No Labels Exist' in lines:
        labels = [] # no tests
    else:
        raise RuntimeError(
            'ctest --print-labels produced an unexpected output:\n'
            + '\n'.join(lines))
    logs = {}
    for label in labels:
        if projects is not None and label not in projects:
            # skip this test, it's not part of the packaging/build config
            continue
        logfile = tempfile.mkstemp(prefix='bv_test_%s' % label, suffix='.log')
        os.close(logfile[0])
        start_time = time.localtime()
        try:
            system(cwd=cwd, env=env,
                  *(['ctest', '-L', '^%s$' % label, '--output-on-failure',
                     '-O', logfile[1]] + options))
        except Exception as e:
            logitem = {}
            logitem['log_file'] = logfile[1]
            logitem['exception'] = e
            logitem['start_time'] = start_time
            logitem['stop_time'] = time.localtime()
            logs[label] = logitem
        else:
            logitem = {}
            logitem['log_file'] = logfile[1]
            logitem['exception'] = None
            logitem['start_time'] = start_time
            logitem['stop_time'] = time.localtime()
            logs[label] = logitem
            #os.unlink(logfile[1])
        # FIXME DEBUG
        print('-------------------------------------',
              file=open(logfile[1], 'a'))
        print('projects to test: %s' % repr(projects),
              file=open(logfile[1], 'a'))
        print('labels to test: %s' % repr(labels),
              file=open(logfile[1], 'a'))
        print('current label: %s' % label,
              file=open(logfile[1], 'a'))
    return logs


def run_and_log_testref(cwd=None, env=None, options=None):
    logs = {}
    logfile = tempfile.mkstemp(prefix='bv_testref', suffix='.log')
    os.close(logfile[0])
    start_time = time.localtime()
    try:
        output = system_output_on_error(['make'] + options + ['testref'],
                                        cwd=cwd, env=env)
    except Exception as e:
        if hasattr(e, 'output'):
            open(logfile[1], 'w').write(e.output)
        logitem = {}
        logitem['log_file'] = logfile[1]
        logitem['exception'] = e
        logitem['start_time'] = start_time
        logitem['stop_time'] = time.localtime()
        logs['testref'] = logitem
    else:
        open(logfile[1], 'w').write(output)
        logitem = {}
        logitem['log_file'] = logfile[1]
        logitem['exception'] = None
        logitem['start_time'] = start_time
        logitem['stop_time'] = time.localtime()
        logs['testref'] = logitem
        #os.unlink(logfile[1])
    return logs


class GlobalConfiguration(object):

    def __init__(self, argv):
        usage = '''%prog [options] [ command [command options] ]...

This program is for the management of source retrieval, configuration and compilation of BrainVISA projects.

In order to work, the commands svn and svnadmin must be installed on your system. On some Linux systems they are in two separate packages (e.g. subversion and subversion-tools).

Commands:

* info: Just output info about configured components.
* sources: Create or updated selected sources directories from Subversion
  repository.
* configure: Create and configure selected build directories with CMake.
* build: compile all selected build directories.
* doc: Generate documentation (sphinx, doxygen, docbook, epydoc).
* testref: Execute tests in a special mode to generate machine-specific
  reference files (this is needed by some tests).
* test: Execute tests using ctest.
* pack: Generate binary packages.
* install_pack: Install binary packages.
* testref_pack: Create the machine-specific reference files for tests in
  installed binary package.
* test_pack: Run tests in installed binary packages.
* publish_pack: Publish binary packages.

To get help for a specific command, use -h option of the command. Example: "%prog build -h".

To get help on how to configure and write a bv_maker configuration file, see:

http://brainvisa.info/brainvisa-cmake/compile_existing.html

config file syntax:

http://brainvisa.info/brainvisa-cmake/configuration.html

and more generally:

http://brainvisa.info/brainvisa-cmake/
'''
        defaultConfigurationFile = os.environ.get('BRAINVISA_BVMAKER_CFG')
        if defaultConfigurationFile is None:
            defaultConfigurationFile = os.path.join(
                os.environ['USERPROFILE' if sys.platform.startswith('win') 
                           else 'HOME'], '.brainvisa', 'bv_maker.cfg')
        parser = OptionParser(usage=usage)
        
        parser.add_option('-d', '--directory', dest='directories',
                          help='Restrict actions to a selected directory. May be used several times to process several directories.',
                          metavar='DIR', action='append', default=[])
        parser.add_option('-c', '--config', dest='configuration_file',
                          help='specify configuration file. Default ="' +
                          defaultConfigurationFile + '"',
                          metavar='CONFIG', default=None)
        parser.add_option('-s', '--sources', dest='sources_directories',
                          help='directory containing sources',
                          metavar='DIR', action='append', default=[])
        parser.add_option('-b', '--build', dest='build_directory',
                          help='build directory',
                          metavar='DIR', default=None)
        parser.add_option('--username', dest='username',
                          help='specify user login to use with the svn server',
                          metavar='USERNAME', default='')
        parser.add_option('-e', '--email', action='store_true',
                          help='Use email notification (if configured in the '
                          'general section of the configuration file)')
        parser.add_option('--disable-jenkins', action='store_true',
                          dest='disable_jenkins', default=False,
                          help='disable Jenkins server logging')
        parser.add_option(
            '-v', '--verbose', dest='verbose', action='store_true',
            help='show as much information as possible')
        parser.add_option(
            '--version', dest='version', action='store_true',
            help='show bv_maker (brainvisa-cmake) version number')

        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])

        if options.version:
            print('bv_maker version:', brainvisa_cmake_version)
            sys.exit(0)

        packages = []
        lineCount = 0
        currentDirectoryObject = None
        
        source_dirs = []
        build_dirs = []
        package_dirs = []
        publication_dirs = []
        
        self.sourcesDirectories = {}
        self.buildDirectories = {}
        self.packageDirectories = {}
        self.publicationDirectories = {}
        self.general_section = GeneralSection(self)
        condition_stack = []

        self.directories = options.directories

        for i in ('configuration_file', 'username', 'verbose'):
            setattr(self, i, getattr(options, i))

        if options.build_directory:
            if not options.configuration_file:
                cf = os.path.join(options.build_directory, 'bv_maker.cfg')
                if os.path.exists(cf):
                    options.configuration_file = cf
                else:
                    options.configuration_file = defaultConfigurationFile
            os.environ['BV_MAKER_BUILD'] = options.build_directory
            reload(brainvisa.maker.components_definition)
            reload(brainvisa_projects)

            bd = BuildDirectory(options.build_directory, self)
                
            build_dirs.append(bd)

            for sd in options.sources_directories:
                if os.path.exists(os.path.join(sd, 'project_info.cmake')) \
                    or glob.glob(os.path.join(sd, 'python', '*', 'info.py')) \
                    or glob.glob(os.path.join(sd, '*', 'info.py')):
                    bd.addConfigurationLine('directory ' + sd)
                else:
                    bd.addConfigurationLine('brainvisa all * ' + sd)
        elif not options.configuration_file:
            options.configuration_file = defaultConfigurationFile

        if options.configuration_file:

            # Read configuration file
            for line in open(options.configuration_file):
                lineCount += 1
                line = line.strip()
                # skip comments
                if not line or line[0] == '#' or line.startswith('//'):
                    continue
                try:
                    if line[0] == '[':
                        if line[-1] != ']':
                            raise SyntaxError()
                        l = line[1:-1].split(None, 1)
                        if len(l) != 2 and l[0] not in ('if', 'endif', 'else', 
                                                        'general'):
                            raise SyntaxError()

                        if l[0] == 'if' \
                                and currentDirectoryObject is not None \
                                and len(l) >= 2:
                            if len(condition_stack) != 0 \
                                    and condition_stack[-1] is False:
                                # if an upstream condition is already false,
                                # all the subtree is false (but we still have
                                # to parse it to count if/endif/else
                                # occurrences in it)
                                condition_stack.append(False)
                            else:
                                condition_stack.append(
                                    check_filter_condition(l[1:]))
                        elif l[0] == 'endif' and len(l) == 1:
                            if len(condition_stack) > 0:
                                # ends the filtered section
                                condition_stack.pop()
                            else:
                                SyntaxError('[endif] clause is not preceded '
                                            'by [if] clause.')
                        elif l[0] == 'else' and len(l) == 1:
                            if len(condition_stack) > 0:
                                # inverts the filtered section
                                condition_stack[-1] = not condition_stack[-1]
                            else:
                                SyntaxError('[else] clause is not preceded by '
                                            '[if] clause.')
                        elif len(condition_stack) == 0 \
                            or False not in condition_stack:
                            if self.verbose:
                                print('  processing line %s:' % str(lineCount),
                                      repr(line))
                                sys.stdout.flush()
                                
                            if l[0] == 'source':
                                currentDirectoryObject = SourceDirectory(
                                    l[1].strip(),
                                    self)
                                source_dirs.append(currentDirectoryObject)

                            elif l[0] == 'build':
                                currentDirectoryObject = BuildDirectory(
                                    l[1].strip(),
                                    self)
                                build_dirs.append(currentDirectoryObject)

                            elif l[0] == 'virtualenv':
                                currentDirectoryObject = VirtualenvDirectory(
                                    l[1].strip(),
                                    self)
                                build_dirs.append(currentDirectoryObject)
                                
                            elif l[0] == 'package':
                                currentDirectoryObject = PackageDirectory(
                                    l[1].strip(),
                                    self)
                                package_dirs.append(currentDirectoryObject)
                                
                            elif l[0] == 'package_publication':
                                currentDirectoryObject = PublicationDirectory(
                                    l[1].strip(),
                                    self)
                                publication_dirs.append(currentDirectoryObject)
                                
                            elif l[0] == 'general' and len(l) == 1:
                                currentDirectoryObject = self.general_section
                            else:
                                raise SyntaxError()

                    elif len(condition_stack) == 0 \
                        or False not in condition_stack:
                        if currentDirectoryObject is None:
                            raise SyntaxError()
                        if self.verbose:
                            print('  processing line %s:' % str(lineCount), 
                                  repr(line))
                            sys.stdout.flush()
                            
                        currentDirectoryObject.addConfigurationLine(line)
                except SyntaxError as e:
                    msg = e.message
                    if msg == '':
                        msg = 'Syntax error'
                    raise SyntaxError('%s in ' % msg + repr(
                        options.configuration_file) + ' on line '
                        + str(lineCount))

        if len(condition_stack) > 0:
            RuntimeError('some [if] clause remain unclosed by [endif].')
        
        if options.verbose:
            print('configuration file %s parsed' 
                % repr(options.configuration_file))
        
        for r, sections in ((None, [self.general_section]), \
                            ('sourcesDirectories', source_dirs), \
                            ('buildDirectories', build_dirs), \
                            ('packageDirectories', package_dirs), \
                            ('publicationDirectories', publication_dirs)):
            for s in sections:
                # Variable initialization is done after parsing of sections
                # because it may depend on the complete parsing of other
                # sections
                if not hasattr(s, '_initialized') or not s._initialized:
                    s.init_vars()

                    registry = getattr(self, r, None) if r else None
                    if registry is not None:
                        # Register section
                        registry[s.directory] = s

                    if isinstance(s, SourceDirectory):
                        # Parses source configuration
                        s.parseSourceConfiguration()

                if options.verbose:
                    print(s.directory if hasattr(s, 'directory') else 'general', 
                        'options:')
                    for o in s._validOptions:
                        print(' ', o, '=', getattr(s, o, None))
                
        if options.verbose:
            print('variables initialized')
        
        # store options and args
        self.options = options
        self.args = args


def check_filter_condition(filters):
    # for now, use python eval()
    expression = ' '.join(filters)
    # replace %(var)s vars
    vars = global_installer_variables()
    expression = expression % vars
    try:
        res = bool(eval(expression))
    except:
        traceback.print_exc()
        raise
    return res


_installer_datetime = None
_installer_variables = None

def get_standard_arch(arch = platform.architecture()[0]):
    return 64 if arch in ['64', '64bit', 'x86_64'] else 32
    
def get_host_system_name():
    systems = {'darwin' : 'osx', 
               'windows': 'win'}
    system = platform.system()
    osname = system.lower()
    osname = systems.get(osname, osname)
    
    if osname in ('linux', 'win'):
        # Append architecture
        arch = platform.architecture()[0]
        osname += str(get_standard_arch(arch))

    return osname

def get_host_libc_version():
    # determine libc version - using ctypes and calling C
    # gnu_get_libc_version() function
    # Note: plaform.libc_ver() is completely bogus.
    import ctypes
    libc = ctypes.cdll.LoadLibrary("libc.so.6")
    gnu_get_libc_version = libc.gnu_get_libc_version
    gnu_get_libc_version.restype = ctypes.c_char_p
    
    ver = gnu_get_libc_version()
    if sys.version_info[0] >= 3:
        # in python3, ver is a bytes, not a str
        ver = ver.decode()
    return ver.split('.')

def get_pack_host_system_name():
    '''
        Get system name to use for packaging.
        Because linux compatibility for packs depends on libc version, the
        libc version is integrated to the system name.
    '''
    pack_system = get_host_system_name()
    if pack_system.startswith('linux'):
        libc_version = get_host_libc_version()
        pack_system += '-glibc-'+ '.'.join(libc_version[:2])  
        
    return pack_system


def installer_parse_date(value):
    return datetime.datetime.strptime(value, '%Y_%m_%d').timetuple()[:3]

def installer_parse_time(value):
    return datetime.datetime.strptime(value, '%H:%M:%S').timetuple()[3:6]

def installer_format_date(date):
    return '%04d_%02d_%02d' % date
    
def installer_format_time(time):
    return '%02d:%02d:%02d' % time

def global_installer_datetime():
    global _installer_datetime
    if _installer_datetime is not None:
        return _installer_datetime
      
    plt = time.localtime()
    p_date = installer_format_date(plt[:3])
    p_time = installer_format_time(plt[3:6])

    _installer_datetime = {'date': p_date, 'time': p_time}
                            
    return _installer_datetime
    
def global_installer_variables():
    global _installer_variables
    if _installer_variables is not None:
        return _installer_variables

    pack_host_system = get_pack_host_system_name()
 
    _installer_variables = {'os': pack_host_system,
                            'hostname': gethostname().split('.')[0]}
    return _installer_variables


class JenkinsWrapper(object):

    jenkins_cli = ''
    # for use with using a ssh key
    jenkins_cli_options = ['-remoting'] # needed for recent client
    jenkins_unavailable_warned = False

    def __init__(self):
        # the following does not work on our server, it really needs ssh key
        # + 'remoting' mode
        #
        ## (configuration is global)
        #if configuration.general_section.jenkins_username \
                #and configuration.general_section.jenkins_token:
            #self.jenkins_cli_options = [
                #'-http', '-auth',
                #'%s:%s' % (configuration.general_section.jenkins_username,
                          #configuration.general_section.jenkins_token)]
        pass


    def __del__(self):
        # cleanup jenkins CLI temp file
        if self.__class__.jenkins_cli:
            shutil.rmtree(os.path.dirname(self.jenkins_cli))
            self.__class__.jenkins_cli = ''


    def jenkins_job_name(self, o, step):
        vars = dict(global_installer_variables())
        if o.directory_id:
            vars['directory_id'] = o.directory_id
        elif configuration.general_section.directory_id_by_default:
            vars['directory_id'] = configuration.general_section \
                                                .directory_id_by_default        
        else:
            vars['directory_id'] = os.path.basename(o.directory)
        project = ''
        if ':' in step:
            project = '-' + '-'.join(step.split(':')[1:])
            step = step.split(':')[0]
        vars['step'] = step
        vars['project'] = project
        job_name = configuration.general_section.jenkins_build_name % vars
        return job_name


    def jenkins_global_job_name(self):
        vars = dict(global_installer_variables())
        if configuration.general_section.directory_id_by_default:
            vars['directory_id'] = configuration.general_section \
                                                .directory_id_by_default        
        else:
            vars['directory_id'] = 'all'
        
        if configuration.general_section. \
                         jenkins_global_job_name_step_by_default:
            vars['step'] = configuration.general_section \
                                        .jenkins_global_job_name_step_by_default
        else:
            vars['step'] = 'status'
            
        vars['project'] = ''
        job_name = configuration.general_section.jenkins_build_name % vars
        return job_name


    def jenkins_long_job_name(self, o, step):
        vars = dict(global_installer_variables())
        if o.directory_id:
            vars['directory_id'] = o.directory_id
        elif configuration.general_section.directory_id_by_default:
            vars['directory_id'] = configuration.general_section \
                                                .directory_id_by_default
        else:
            vars['directory_id'] = os.path.basename(o.directory)
        project = ''
        if ':' in step:
            project = '-' + '-'.join(step.split(':')[1:])
            step = step.split(':')[0]
        vars['step'] = step
        vars['project'] = project
        job_long_name = '%(directory_id)s step %(step)s%(project)s, on ' \
            '%(hostname)s (%(os)s)' % vars
        return job_long_name


    def jenkins_notification(self, message, d, o, step, status):
        ''' Notify job execution (build, test etc) to a Jenkins server
        '''
        if not configuration.general_section.jenkins_server_url \
                or configuration.options.disable_jenkins:
            return # don't notify

        if jenkins is None and not JenkinsWrapper.jenkins_unavailable_warned:
            # jenkins module is not here
            JenkinsWrapper.jenkins_unavailable_warned = True
            print('Warning: jenkins module is not available')

        #Status = status[0].upper() + status[1:]
        if o.status[step] not in ('interrupted', 'failed'):
            res = 0
        #elif isinstance(o.status[step]['exception'], KeyboardInterrupt):
            #res = 2
        else:
            res = 1

        job_name = self.jenkins_job_name(o, step)
        job_long_name = self.jenkins_long_job_name(o, step)
        duration_t = [y - x
                      for x, y in zip(o.start_time[step],
                                      o.stop_time[step])]
        # duration in seconds
        duration = int(time.mktime(duration_t) - time.mktime((0, ) * 9)) \
            * 1000

        self.create_jenkins_job(job_name)
        self.submit_job_result(job_name, job_long_name, res, duration,
                               message, o.status[step], step)


    def submit_job_result(self, job_name, job_long_name, res, duration,
                          message, status, step='all'):
        jenkins_cli_path = self.get_jenkins_cli()
        if jenkins_cli_path:
            # gzip content
            zlog_f = tempfile.mkstemp(prefix='log_%s' %step, suffix='.gz')
            os.close(zlog_f[0])
            zlog = zlog_f[1]
            gf = gzip.GzipFile(zlog, 'wb')
            gf.write(message)
            gf.close()
            try:
                jkn_cmd = ['java', '-jar', jenkins_cli_path] \
                    + self.jenkins_cli_options \
                    + ['-s',
                       configuration.general_section.jenkins_server_url,
                       'set-external-build-result', '--display',
                       job_long_name, '--job', job_name,
                       '--result', str(int(res)),
                       '--duration', str(duration), '--log', '-']
                #print('Run jenkins:')
                #print(jkn_cmd)
                system_output_on_error(jkn_cmd, stdin=open(zlog), timeout=15)


            finally:
                os.unlink(zlog)
        elif jenkins:
            # jenkins_cli unavailable, use python-jenkins
            jen = self.jenkins

            POST_BUILD_RESULT = \
                '%(folder_url)sjob/%(short_name)s/postBuildResult'

            config = '''<run>
              <log encoding="hexBinary">%s</log>
              <result>%d</result>
              <duration>%d</duration>
              <displayName>%s</displayName>
              <description>%s</description>
            </run>''' % (message.encode('hex'), int(res), duration,
                         job_long_name, status)

            folder_url, short_name = jen._get_job_folder(job_name)
            jen.jenkins_open(jenkins.Request(
                jen._build_url(POST_BUILD_RESULT,
                              {'folder_url': folder_url,
                               'short_name': short_name}),
                config.encode('utf-8'), jenkins.DEFAULT_HEADERS))


    def jenkins_global_notification(self, message, res, start_time,
                                    stop_time, status):
        if not configuration.general_section.jenkins_server_url \
                or configuration.options.disable_jenkins:
            return # don't notify

        job_name = self.jenkins_global_job_name()
        self.create_jenkins_job(job_name)

        # duration in seconds
        if start_time is None or stop_time is None:
            duration = 0
        else:
            duration_t = [y - x for x, y in zip(start_time, stop_time)]
            duration = int(time.mktime(duration_t) - time.mktime((0, ) * 9)) \
                * 1000

        job_long_name = job_name

        self.submit_job_result(job_name, job_long_name, res, duration,
                               message, status)
        # remove the temporary "running" build
        if hasattr(self, 'running_build'):
            self.delete_build(job_name, self.running_build)
            del self.running_build


    def jenkins_global_notify_running(self):
        if not configuration.general_section.jenkins_server_url \
                or configuration.options.disable_jenkins:
            return # don't notify
        job_name = self.jenkins_global_job_name()
        self.create_jenkins_job(job_name)
        self.submit_job_result(job_name, 'RUNNING...', 0, 0,
                               'Job in progress.', '')
        # keep this temporary "running" build to allow deleting it later
        try:
            running_build = self.get_last_build(job_name)
        except AttributeError: # jenkins module not available
            running_build = None
        if running_build is not None:
            self.running_build = running_build


    def get_last_build(self, job_name):
        jenkins_cli_path = self.get_jenkins_cli()
        if jenkins_cli_path:
            return self.get_last_build_cli(job_name)
        else:
            return self.get_last_build_py(job_name)


    def get_last_build_cli(self, job_name):
        # cli does not allow to get builds list in a job...
        if jenkins and not hasattr(self, 'jenkins'):
            self.jenkins = jenkins.Jenkins(
                configuration.general_section.jenkins_server_url, configuration.general_section.jenkins_username,
                configuration.general_section.jenkins_token)
        if hasattr(self, 'jenkins'):
            return self.get_last_build_py(job_name)


    def get_last_build_py(self, job_name):
        return str(self.jenkins.get_job_info(job_name)['lastBuild']['number'])


    def delete_build(self, job_name, build_name):
        if hasattr(self, 'jenkins'):
            self.delete_build_py(job_name, build_name)
        #jenkins_cli_path = self.get_jenkins_cli()
        #if jenkins_cli_path:
            #self.delete_build_cli(job_name, build_name)
        #else:
            #self.delete_build_py(job_name, build_name)


    def delete_build_cli(self, job_name, build_name):
        # doesn't work: always returns "ERROR: No such job"
        jenkins_cli_path = self.get_jenkins_cli()
        # check if the job exists
        jkn_cmd = ['java', '-jar', jenkins_cli_path] \
            + self.jenkins_cli_options \
            + ['-s',
               configuration.general_section.jenkins_server_url,
               'delete-builds', job_name, build_name]
        system_output_on_error(jkn_cmd, timeout=15).strip().split('\n')


    def delete_build_py(self, job_name, build_name):
        DELETE_BUILD \
            = '%(folder_url)sjob/%(short_name)s/%(build_name)s/doDelete'
        folder_url, short_name = self.jenkins._get_job_folder(job_name)
        self.jenkins.jenkins_open(jenkins.Request(
            self.jenkins._build_url(DELETE_BUILD, locals()), b''))


    @classmethod
    def get_jenkins_cli(cls):
        if cls.jenkins_cli is None or cls.jenkins_cli:
            return cls.jenkins_cli
        if jenkins is not None:
            #if the python module is here, use it.
            cls.jenkins_cli = None
            return None

        java = distutils.spawn.find_executable('java')
        # test java version
        try:
            java_ver = system_output_on_error(['java', '-version'], timeout=3)
            ver = java_ver.split('\n')[0].strip()
            jvre = re.match('^.* version "([^"]+)"$', ver)
            if jvre:
                jver_s = jvre.group(1)
                jver = [int(x) for x in jver_s.split('.')[:2]]
                if jver < [1, 7]:
                    print('Java version %s is too old for Jenkins-cli.'
                          % jver_s)
                    java = None
                else:
                    print('Java version %s OK for jenkins-cli' % jver_s)
            else:
                print('Java version %s cannot be parsed. '
                      'Not using Jenkins-cli' % jver_s)
                java = None
        except:
            print('Could not check java version. Not using Jenkins-cli')
            java = None
        if not java:
            cls.jenkins_cli = None
            return None
        # jenkins-cli.jar is retreived from the server
        cli_file_d = tempfile.mkdtemp(prefix='bv_maker_jenkins')
        cli_file = os.path.join(cli_file_d, 'jenkins-cli.jar')
        url = configuration.general_section.jenkins_server_url \
            + '/jnlpJars/jenkins-cli.jar'
        try:
            f = urlopen(url)
            open(cli_file, 'wb').write(f.read())
            cls.jenkins_cli = cli_file
        except:
            shutil.rmtree(cli_file_d)
            cls.jenkins_cli = None
        return cls.jenkins_cli


    def create_jenkins_job(self, job_name):
        jenkins_cli_path = self.get_jenkins_cli()
        if jenkins_cli_path:
            return self.create_jenkins_job_cli(job_name)
        elif jenkins:
            # use jenkins module
            return self.create_jenkins_job_py(job_name)


    def create_jenkins_job_cli(self, job_name):
        jenkins_cli_path = self.get_jenkins_cli()
        # check if the job exists
        jkn_cmd = ['java', '-jar', jenkins_cli_path] \
            + self.jenkins_cli_options \
            + ['-s',
               configuration.general_section.jenkins_server_url,
               'list-jobs']
        jobs = system_output_on_error(jkn_cmd, timeout=15).strip().split('\n')
        if job_name not in jobs:
            # create new job
            template  = '''<?xml version='1.0' encoding='UTF-8'?>
<hudson.model.ExternalJob plugin="external-monitor-job@1.7">
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
</hudson.model.ExternalJob>'''
            tfile = tempfile.mkstemp(prefix='bv_maker_jenkins_',
                                      suffix='.xml')
            os.close(tfile[0])
            open(tfile[1], 'w').write(template)
            jkn_cmd = ['java', '-jar', jenkins_cli_path] \
                + self.jenkins_cli_options \
                + ['-s',
                   configuration.general_section.jenkins_server_url,
                   'create-job', job_name]
            #print('jkn cmd:', jkn_cmd)
            try:
                system_output_on_error(jkn_cmd, timeout=15,
                                       stdin=open(tfile[1]))
            finally:
                os.unlink(tfile[1])


    def create_jenkins_job_py(self, job_name):
        if not hasattr(self, 'jenkins'):
            self.jenkins = jenkins.Jenkins(
                configuration.general_section.jenkins_server_url, configuration.general_section.jenkins_username,
                configuration.general_section.jenkins_token)
        jen = self.jenkins
        if not jen.get_job_name(job_name):
            config = '''<?xml version='1.0' encoding='UTF-8'?>
<hudson.model.ExternalJob plugin="external-monitor-job@1.7">
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
</hudson.model.ExternalJob>'''
            jen.create_job(job_name, config)


class StepCommand(object):
    
    def __init__(self, argv, configuration):
        # Initialize python variables that can override directories
        # python variables
        super(StepCommand, self).__init__()
        self.python_vars = {}

    def process(self, step, directories_dict, method, *meth_args,
                **meth_kwargs):
        for o in directories_dict.values():
            # Update directory python variables by those coming from the command
            # line (package date and version)
            o.update_python_vars(self.python_vars)
            # Python variables update need to reprocess environment variables
            o.reset_environ()
            
            # Get the new directory value
            d = o.directory
            normalize_path_needed = 'directory' in \
                getattr(o, '_path_variables', set())
            
            # Resolve directories pattern using configuration directory 
            # variables
            conf_dirs = [normalize_path(o.replace_vars(c)) \
                         if normalize_path_needed else o.replace_vars(c) \
                         for c in configuration.directories] \
                        if configuration.directories else []
                        
            if (not conf_dirs or d in conf_dirs) and o.conditional_build():
                if not self.options.in_config or step in o.default_steps:
                    if o.has_satisfied_dependencies(step):
                        self.redirect_stdout(d, o, step)
                        logs = None
                        try:
                            logs = getattr(o, method)(*meth_args,
                                                      **meth_kwargs)
                            if not logs:
                                o.status[step] = 'succeeded' # mark as done
                        except KeyboardInterrupt:
                            # record failure
                            o.status[step] = 'interrupted'
                            o.stop_time[step] = time.localtime()
                            # user interruptions should stop all.
                            raise
                        except:
                            traceback.print_exc()
                            # record failure
                            o.status[step] = 'failed'
                        if logs:
                            if logs == IGNORED_STEP:
                                # step did nothing and should be ignored
                                o.status[step] = 'not run'
                                self.release_stdout(o)
                                continue
                            o.stop_time[step] = time.localtime()
                            o.status[step] = 'succeeded'
                            for label, item in six.iteritems(logs):
                                log = item['log_file']
                                exc = item['exception']
                                full_step = '%s:%s' % (step, label)
                                o.start_time[full_step] = item['start_time']
                                o.stop_time[full_step] = item['stop_time']
                                if exc is None:
                                    o.status[full_step] = 'succeeded'
                                elif isinstance(exc, KeyboardInterrupt):
                                    o.status[full_step] = 'interrupted'
                                    if o.status[step] != 'failed':
                                        o.status[step] = 'interrupted'
                                else:
                                    o.status[full_step] = 'failed'
                                    o.status[step] = 'failed'
                                self.release_notify_log(d, o, step, label, log,
                                                        exc)
                        else:
                            self.release_notify_stdout(d, o, step)
                    else:
                        print('Skipping', step, 'of', d,
                              'because it depends on a step that failed.')
            elif configuration.verbose:
                print('Skipping', step, 'of', d,
                      'because it is not in the selected directories.')


    def redirect_stdout(self, d, o, step):
        o.start_time[step] = time.localtime()
        if configuration.general_section is None:
            return
        if ((configuration.general_section.email_notification_by_default. \
                upper() != 'ON' and not configuration.options.email) \
                or (configuration.general_section.failure_email == ''
                    and configuration.general_section.success_email == ''
                    and configuration.general_section.failure_email_by_project
                        == {})) \
                and (not configuration.general_section.jenkins_server_url
                     or configuration.options.disable_jenkins):
            return
        if o.stdout_file or o.stderr_file:
            if o.stdout_file:
                self.tmp_stdout = open(o.stdout_file, 'w')
                if o.stderr_file:
                    self.tmp_stderr = open(o.stderr_file, 'w')
                else:
                    self.tmp_stderr = self.tmp_stdout
            else:
                self.tmp_stdout = open(o.stderr_file, 'w')
                self.tmp_stderr = self.tmp_stdout
        else:
            tmp_stdout = tempfile.mkstemp(prefix='buildout_')
            os.close(tmp_stdout[0])
            print('redirecting outputs to temporary file:', tmp_stdout[1])
            sys.stdout.flush()
            sys.stderr.flush()
            self.tmp_stdout = open(tmp_stdout[1], 'w')
            self.tmp_stderr = self.tmp_stdout
        self.orig_stdout = os.dup(sys.stdout.fileno())
        self.orig_stderr = os.dup(sys.stderr.fileno())
        os.dup2(self.tmp_stdout.fileno(), 1)
        os.dup2(self.tmp_stderr.fileno(), 2)

    def release_notify_stdout(self, d, o, step):
        o.stop_time[step] = time.localtime()
        fix_stdout = False
        if hasattr(self, 'orig_stdout'):
            fix_stdout = True
            os.dup2(self.orig_stdout, 1)
            os.dup2(self.orig_stderr, 2)
            self.tmp_stdout.close()
            if self.tmp_stderr is not self.tmp_stdout:
                self.tmp_stderr.close()
        self.notify_log(d, o, step)
        if fix_stdout:
            del self.orig_stderr
            del self.orig_stdout
            if not o.stdout_file:
                os.unlink(self.tmp_stdout.name)
            # tmp_stderr is never removed: either it is specified as a
            # persistant file or it is tmp_stdout.
            del self.tmp_stdout
            del self.tmp_stderr

    def release_stdout(self, o):
        if not hasattr(self, 'orig_stdout'):
            return
        os.dup2(self.orig_stdout, 1)
        os.dup2(self.orig_stderr, 2)
        self.tmp_stdout.close()
        if self.tmp_stderr is not self.tmp_stdout:
            self.tmp_stderr.close()
        del self.orig_stderr
        del self.orig_stdout
        if not o.stdout_file:
            os.unlink(self.tmp_stdout.name)
        # tmp_stderr is never removed: either it is specified as a persistant
        # file or it is tmp_stdout.
        del self.tmp_stdout
        del self.tmp_stderr

    def release_notify_log(self, d, o, step, label, log, exc):
        self.release_stdout(o)
        self.tmp_stdout = open(log)
        self.tmp_stdout.close()
        self.tmp_stderr = self.tmp_stdout
        full_step = '%s:%s' % (step, label)
        if exc is None:
            o.status[full_step] = 'succeeded'
        elif isinstance(exc, KeyboardInterrupt):
            o.status[full_step] = 'interrupted'
        else:
            o.status[full_step] = 'failed'
        self.notify_log(d, o, full_step)
        del self.tmp_stdout
        os.unlink(log)

    def notify_log(self, d, o, step):
        status =  o.status.get(step, 'not run')
        # global log file notification
        self.log_in_global_log_file(d, o, step, status)
        # email notification
        email = ''
        if configuration.general_section.email_notification_by_default.upper() \
                == 'ON' or configuration.options.email:
            if status in ('failed', 'interrupted'):
                email = configuration.general_section.failure_email
                if configuration.general_section.failure_email_by_project:
                    project = step.split(':')[-1]
                    if project in  configuration.general_section. \
                            failure_email_by_project:
                        email = configuration.general_section. \
                            failure_email_by_project[project]
            elif status == 'succeeded':
                email = configuration.general_section.success_email
        if email:
            try:
                self.send_log_email(email, d, o, step, status)
            except Exception as e:
                print('WARNING: notification email could not be sent:',
                      e.message)
                traceback.print_exc()
        # Jenkins notification
        self.jenkins_notification(d, o, step, status)
        # console notification
        if email and status in ('failed', 'interrupted'):
            # original stdout has been changed, we need to print again
            print(self.message_header(d, o, step, status))
            print(self.log_message_content())

    def message_header(self, d, o, step, status):
        real_dir = o.replace_vars(d)
        dlen = max((len(step), len(status), len(real_dir)))
        if hasattr(o, 'get_environ'):
            env = o.get_environ()
        else:
            env = os.environ
        start_time = '%04d/%02d/%02d %02d:%02d' % o.start_time[step][:5]
        stop_time = '%04d/%02d/%02d %02d:%02d' % o.stop_time[step][:5]
        message = '''========================================='
== directory: %s%s ==
== step:      %s%s ==
== status:    %s%s ==
== started:   %s%s ==
== stopped:   %s%s ==
=========================================

--- environment: ---
''' % (real_dir, ' ' * (dlen - len(real_dir)),
            step, ' ' * (dlen - len(step)),
            status, ' ' * (dlen - len(status)),
            start_time, ' ' * (dlen - len(start_time)),
            stop_time, ' ' * (dlen - len(stop_time)))
        message += '\n'.join(['%s=%s' % (var, env[var])
                              for var in sorted(env.keys())])
        message += '\n------------------------------------------\n\n'

        return message

    def send_log_email(self, email, d, o, step, status):
        if configuration.general_section.from_email == '':
            from_address = '%s-%s@intra.cea.fr' \
                % (os.getenv('USER'), gethostname())
        else:
            from_address = configuration.general_section.from_email
        if configuration.general_section.reply_to_email == '':
            reply_to_address = 'appli@saxifrage.saclay.cea.fr'
        else:
            reply_to_address = configuration.general_section.reply_to_email
        to_address = email

        # header
        machine = gethostname()
        osname = global_installer_variables()['os']
        Status = status[0].upper() + status[1:]
        message = '''MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset="utf-8"
Reply-To: %s
Subject: %s - %s %s on %s (%s)

%s - build started %s, stopped %s on %s (%s)

''' % (reply_to_address, Status, step,
            '%04d/%02d/%02d' % o.start_time[step][:3],
            machine, osname, Status,
            '%04d/%02d/%02d %02d:%02d' % o.start_time[step][:5],
            '%04d/%02d/%02d %02d:%02d' % o.stop_time[step][:5], machine,
            osname)

        message += self.message_header(d, o, step, status)
        message += self.log_message_content()

        if configuration.general_section.smtp_server != '':
            smtp_server = configuration.general_section.smtp_server
        else:
            smtp_server = 'mx.intra.cea.fr'
        server = SMTP(smtp_server)
        server.sendmail(from_address, to_address, message)
        server.quit()

    def log_message_content(self):
        if self.tmp_stderr is not self.tmp_stdout:
            message = '====== standard output ======\n\n'
        else:
            message = '====== output ======\n\n'
        # Read message from file
        file = open(self.tmp_stdout.name)
        message += file.read()
        file.close()
        if self.tmp_stderr is not self.tmp_stdout:
            message += '====== standard error ======\n\n'
            file = open(self.tmp_stderr.name)
            message += file.read()
            file.close()
        return message

    def log_in_global_log_file(self, d, o, step, status):
        # print('log_in_global_log_file', step, status)
        if status == 'not run':
            return # don't log non-running steps
        log_file = None
        if configuration.general_section \
                and configuration.general_section.global_status_file:
            log_file = configuration.general_section.global_status_file
        if not log_file:
            return

        status = status.upper()
        if status == 'SUCCEEDED':
            status = 'OK' # we used OK, so let's go on
        machine = gethostname()
        osname = global_installer_variables()['os']

        message = '%s step %s: %s' % (status, step, d)
        start = o.start_time.get(step)
        if start:
            message += ', started: %04d/%02d/%02d %02d:%02d' \
                % start[:5]
        stop = o.stop_time.get(step)
        if stop:
            message += ', stopped: %04d/%02d/%02d %02d:%02d' \
                % stop[:5]
        open(log_file, 'a').write(
            '%s on %s (%s)\n' % (message, machine, osname))

    def jenkins_notification(self, d, o, step, status):
        ''' Notify job execution (build, test etc) to a Jenkins server
        '''
        if not configuration.general_section.jenkins_server_url \
                or configuration.options.disable_jenkins:
            return # don't notify
        message = self.message_header(d, o, step, status)
        message += self.log_message_content()
        global jenkins_wrapper
        if jenkins_wrapper is None:
            jenkins_wrapper = JenkinsWrapper()
        jenkins_wrapper.jenkins_notification(message, d, o, step, status)


class InfoCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] info [options]

    Display information about configuration, sources directories and build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(InfoCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        print('Configuration file:', configuration.configuration_file)
        dirs = dict(configuration.sourcesDirectories)
        dirs.update(configuration.buildDirectories)
        dirs.update(configuration.packageDirectories)
        dirs.update(configuration.publicationDirectories)
        self.process('info', dirs, 'info')


class SourcesCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] sources [options]

    Create or updated selected sources directories from Subversion repository.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--no-cleanup', dest='cleanup', action='store_false',
                          default=True,
                          help='don\'t cleanup svn sources')
        parser.add_option('--no-svn', dest='svn', action='store_false',
                          default=True,
                          help='don\'t update svn sources')
        parser.add_option('--no-git', dest='git', action='store_false',
                          default=True,
                          help='don\'t update git sources')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(SourcesCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('sources', configuration.sourcesDirectories,
                     'process', self.options, self.args)


class ConfigureCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] configure [options]

    Create or updated selected build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('-c', '--clean', dest='clean', action='store_true',
                          default=False,
                          help='clean build tree (using bv_clean_build_tree '
                          '-d) before configuring')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(ConfigureCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('configure', configuration.buildDirectories,
                     'configure', self.options, self.args)

class BuildCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] configure [options]

    Compile selected build directories.'''
        parser = OptionParser(usage=usage)
        parser.add_option('-c', '--clean', dest='clean', action='store_true',
                          default=False,
                          help='clean build tree (using '
                          'bv_clean_build_tree -b) before building')
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(BuildCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('build', configuration.buildDirectories,
                     'build', self.options, self.args)


class DocCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] doc [options]

    Generate documentation (docbook, epydoc, doxygen).'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(DocCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('doc', configuration.buildDirectories, 'doc')


class TestCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] test

    Executes ctest.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        parser.add_option('-t', '--ctest_options',
                          default=None,
                          help='options passed to ctest (ex: "-VV -R carto*"). '
                          'Same as the configuration option ctest_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('test', configuration.buildDirectories, 'test',
                     self.options, self.args)


class TestrefCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] testref

    Executes tests in the testref mode (used to generate reference files).'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, and '
                          '"configure build" for build sections')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestrefCommand, self).__init__(argv, configuration)
        self.options = options
        self.args = args

    def __call__(self):
        self.process('testref', configuration.buildDirectories, 'testref',
                     self.options, self.args)


class PackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] pack [options]

    Make installer package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(PackCommand, self).__init__(argv, configuration)
        self.python_vars = dict(global_installer_datetime())
        self.options = options
        self.args = args

    def __call__(self):
        self.process('pack', configuration.packageDirectories,
                     'package', self.options, self.args)


class InstallPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] install_pack [options]

    Install a binary package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--prefix', dest='prefix',
                          default=None,
                          help='sets the prefix directory to install the pack.')
        parser.add_option('--local', dest='local',
                          action='store_true',
                          default=False,
                          help='True if the installation must be done ' \
                               'locally. Default is False.')
        parser.add_option('--offline', dest='offline',
                          action='store_true',
                          default=False,
                          help='True if the installation must be done using ' \
                               'offline installer. Default is False.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(InstallPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('install_pack', configuration.packageDirectories,
                     'install_package', self.options, self.args)


class TestPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] test_pack [options]

    Test in installed package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-t', '--ctest_options',
                          default=None,
                          help='options passed to ctest (ex: "-VV -R carto*"). '
                          'Same as the configuration option ctest_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('test_pack', configuration.packageDirectories,
                     'test_package', self.options, self.args)


class TestrefPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] testref_pack [options]

    Create test reference files in installed package for the selected build directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(TestrefPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('testref_pack', configuration.packageDirectories,
                     'testref_package', self.options, self.args)


class PublishPackCommand(StepCommand):

    def __init__(self, argv, configuration):
        usage = '''%prog [global options] publish [options]

    Run command to publish package for the selected publication directory.'''
        parser = OptionParser(usage=usage)
        parser.add_option('--only-if-default', dest='in_config',
                          action='store_true',
                          default=False,
                          help='only perform this step if it is a default '
                          'step, or specified in the "default_steps" option '
                          'of bv_maker.cfg config file. Default steps are '
                          'normally "sources" for source sections, '
                          '"configure build" for build sections.')
        parser.add_option('-m', '--make_options',
                          default=None,
                          help='options passed to make (ex: "-j8") during test '
                          'reference generation. '
                          'Same as the configuration option make_options but '
                          'specified at runtime. The commandline option here '
                          'overrides the bv_maker.cfg options.')
        parser.add_option('--package-date', dest='package_date',
                          default=None,
                          help='sets the date of the pack to install. '
                          'This is only useful if a %(date)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-time', dest='package_time',
                          default=None,
                          help='sets the time of the pack to install. '
                          'This is only useful if a %(time)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        parser.add_option('--package-version', dest='package_version',
                          default=None,
                          help='sets the version of the pack to install. '
                          'This is only useful if a %(version)s pattern '
                          'has been used in the package directory sections '
                          'of bv_maker.cfg.')
        (options, args) = parser.parse_args(argv)
        if args:
            raise ValueError('Invalid option: %s' % args[0])
        
        super(PublishPackCommand, self).__init__(argv, configuration)
        
        date = installer_format_date(installer_parse_date(options.package_date)) \
               if options.package_date else global_installer_datetime()['date']
        time = installer_format_time(installer_parse_time(options.package_time)) \
               if options.package_time else global_installer_datetime()['time']
        self.python_vars = {'date': date,
                            'time': time}
        if options.package_version:
            self.python_vars.update({'version': options.package_version})
            
        self.options = options
        self.args = args

    def __call__(self):
        self.process('publish_pack', configuration.publicationDirectories,
                     'publish_package', self.options, self.args)

class VarReplacementType:
    NO = 0
    PYTHON = 1
    ENV = 2
    ALL = PYTHON | ENV
        
def replace_vars(value, 
                 replacement_type = VarReplacementType.ALL,
                 python_vars = None,
                 env_vars = None):   
    result = value
    
    if python_vars and (replacement_type & VarReplacementType.PYTHON):
        # Uses python variable substitutions to allow partial replacements
        #print('replace_vars, replace_python_vars call', value, replacement_type)
        #result = result % python_vars
        result = pythonVariablesSubstitution(result, python_vars = python_vars)
        
    if env_vars and (replacement_type & VarReplacementType.ENV):
        #print('replace_vars, replace_env_vars call', value, replacement_type)
        # Replaces only environment variables
        result = environmentVariablesSubstitution(result, env = env_vars)
        
    return result
    
class ConfigVariableParser(object):

    _validOptions = set()
    _validAdditiveOptions = set()
    _path_variables = set()
    _variables_with_replacements = set()
    _variables_with_env_only_replacements = set()
    _variables_with_python_only_replacements = set()

    def __new__(cls, *args):
        # Initialize the class properties
        for prop in cls._validOptions.union(cls._validAdditiveOptions):
            cls.property_init(prop)
            
        return super(ConfigVariableParser, cls).__new__(cls)
        
    def __init__(self, *args):
        super(ConfigVariableParser, self).__init__(*args)
        
        self._property_info = {}
        self._property_recursivity = {}
        for prop in self._validOptions.union(self._validAdditiveOptions):
            self._property_info[prop] = \
                (self.get_replacement_type(prop), 
                 self.is_path(prop))
                
    @classmethod
    def property_init(cls, name, doc = None):
        from functools import partial
        
        # Declare option as a property
        setattr(cls, name, 
                property(partial(getattr(cls, '_property_get'), name),
                         partial(getattr(cls, '_property_set'), name),
                         partial(getattr(cls, '_property_del'), name),
                         doc if doc else 'property ' + name))
    
    @staticmethod
    def _property_has(name, config_parser):
        return name in config_parser._property_info
        
    @staticmethod            
    def _property_set(name, config_parser, value):
        setattr(config_parser, '_' + name, value)
        #print('val_type is', type(v), 'for value:', value)

    @staticmethod
    def _property_get_origin(name, config_parser):
        getattr(config_parser, '_' + name)
        
    @staticmethod
    def _property_get(name, config_parser):
        info = config_parser._property_info.get(name, None)
        if info is None:
            raise RuntimeError('Property %s is not declared' % name)
        
        repl_type, is_path = info
        
        def from_config_object(value):
            # Recursively replaces configuration patterns 
            # using ConfigValue object
            if isinstance(value, (list, tuple, set)):
                value = type(value)([from_config_object(v) for v in value])
                
            elif isinstance(value, dict):
                value = dict([(k, from_config_object(v)) \
                              for k, v in six.iteritems(value)])
                
            elif isinstance(value, six.string_types):
                env_vars = config_parser.get_environ()
                python_vars = config_parser.get_python_vars()
                value = replace_vars(value, repl_type, python_vars, env_vars)
                if is_path and value:
                    value = normalize_path(value)
                   
            return value

        value = getattr(config_parser, '_' + name)
        config_parser._property_recursivity[name] = True
        value = from_config_object(value)
        del config_parser._property_recursivity[name]
        
        #print('_property_get', name, value, type(value), repl_type, is_path);sys.stdout.flush()
        return value
    
    @staticmethod
    def _property_del(name, config_parser):   
        delattr(config_parser, '_' + name)
    
    def property_append(self, name, value):
        old_value = getattr(self, '_' + name)
        prop_type = type(old_value)
        
        if prop_type in (dict, set):
            old_value.update(value)
        else:
            old_value += value
        
        setattr(self, name, old_value)
    
    def property_remove(self, name, value):
        old_value = getattr(self, '_' + name)
        prop_type = type(old_value)
        if prop_type is dict:
            for k in value:
                if k in old_value:
                    del old_value[k]
        elif prop_type is set:
            old_value.difference_update(value)
        elif prop_type is list:
            old_value = [x for x in old_value if x not in value]
            setattr(self, name, old_value)
        else:
            try:
                old_value -= value
            except:
                raise SyntaxError()
    
    def get_valid_options(self):
        return self._validOptions
    
    def addConfigurationLine(self, line):
        i = line.find('=')
        if i > 0:
            oper = '' # assign (=) operator by default
            if i > 1 and line[i-1] in ('-', '+'): # operators -=, +=
                oper = line[i-1]
                option = line[:i-1].strip()
                if option not in self._validAdditiveOptions:
                    raise SyntaxError('Option %s does not allow additive '
                                      'assignation (+=, -=)' % option)
            else:
                option = line[:i].strip()
            value = line[i + 1:].strip()
            if option not in self._validOptions:
                raise SyntaxError('Invalid option: %s' % option)
            
            var_type = str
            if hasattr(self, option):
                var_type = type(getattr(self, option))
                if var_type in (list, tuple):
                    value = shlex.split(value)
                elif var_type is dict:
                    if value.startswith('{') and value.endswith('}'):
                        try:
                            value = eval(value)
                        except:
                            raise SyntaxError()
                    else:
                        try:
                            value = eval('{' + value + '}')
                        except:
                            # try simpler syntax without quotes
                            try:
                                value = [x.strip() for x in value.split(',')]
                                value = dict([(x[:x.find(':')],
                                               x[x.find(':') + 1:].strip())
                                    for x in value])
                            except:
                                raise SyntaxError()
            
            if oper == '':
                setattr(self, option, value)
                        
            elif oper == '+':
                self.property_append(option, value)

            elif oper == '-':
                self.property_remove(option, value)
                
            self.validate_option(option)
            return True # parsed
        return False # not parsed

    def validate_option(self, option):
        # by default nothing more is done
        pass

    def is_path(self, var):
        return var in getattr(self, '_path_variables', set())

    def allows_env_replacements(self, var):
        return (self.is_path(var) \
                and var not in getattr(self, 
                                   '_variables_with_python_only_replacements', 
                                   set())) \
            or var in getattr(self, 
                              '_variables_with_env_only_replacements', 
                              set()) \
            or var in getattr(self, 
                              '_variables_with_replacements', 
                              set())

    def allows_python_replacements(self, var):
        return (self.is_path(var) \
                and var not in getattr(self, 
                                   '_variables_with_env_only_replacements', 
                                   set())) \
            or var in getattr(self, 
                              '_variables_with_python_only_replacements', 
                              set()) \
            or var in getattr(self, 
                              '_variables_with_replacements', 
                              set())

    def allows_replacements(self, var):
        return self.allows_python_replacements(var) \
           and self.allows_env_replacements(var)

    def get_replacement_type(self, var):
        if self.allows_replacements(var):
            return VarReplacementType.ALL
        
        elif self.allows_env_replacements(var):
            return VarReplacementType.ENV
        
        elif self.allows_python_replacements(var):
            return VarReplacementType.PYTHON
        
        else:
            return VarReplacementType.NO
        
    def init_vars(self):
        self.__init_python_vars()
        self.__init_environ()
            
    def __init_python_vars(self):
        self._python_vars = dict(global_installer_variables())

    def __init_environ(self):
        self._env_vars = dict(os.environ)

        if not self._property_recursivity.get('env'):
            # Automatically add the env property of the directory 
            # to the environment variables if it exists
            if hasattr(self, 'env'):
                # Add env property content
                self.update_environ(getattr(self, 'env', {}))
        
    def reset_environ(self):
        self.__init_environ()

    def update_python_vars(self, vars):
        '''Update python variable cache for the section'''               
        self._python_vars.update(vars)        

    def update_environ(self, vars):
        '''Update environment variable cache for the section'''
        self._env_vars.update(vars)
        
    def get_python_vars(self):
        return getattr(self, '_python_vars', {})

    def get_environ(self, env = None):
        env_vars = getattr(self, '_env_vars', None)
        if not env_vars:
            return os.environ
            #raise RuntimeError('Environment is not initialized')

        new_env = dict(self._env_vars)
        if env:
            new_env.update(env)
        return new_env

    def replace_vars(self, value, replacement_type=VarReplacementType.ALL):
        return replace_vars(value, replacement_type, 
                            self.get_python_vars(), 
                            self.get_environ())

    def replace_vars_if_allowed(self, var, value, env=None):
        if self.allows_replacements(var):
            return replace_vars(value, VarReplacementType.ALL, 
                                self.get_python_vars(), 
                                self.get_environ())
        
        elif self.allows_env_replacements(var):
            # Replaces only environment variables
           return replace_vars(value, VarReplacementType.ENV,
                               env_vars = self.get_environ())
        elif self.allows_python_replacements(var):
            # Replaces only environment variables
           return replace_vars(value, VarReplacementType.PYTHON,
                               python_vars = self.get_python_vars())
        else:
            return value


class GeneralSection(ConfigVariableParser):
    _variables_with_replacements = \
        set(('directory_id_by_default',
             'jenkins_global_job_name_step_by_default',
             'jenkins_server_url'))
    _variables_with_env_only_replacements = set(('jenkins_build_name', 'env'))
    _validAdditiveOptions = set(('env', ))
    _path_variables = set(('global_status_file', ))
    _validOptions = set(('failure_email', 'success_email', 'smtp_server',
                         'from_email', 'reply_to_email',
                         'email_notification_by_default',
                         'failure_email_by_project',
                         'jenkins_build_name',
                         'jenkins_username',
                         'jenkins_token'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_variables_with_env_only_replacements)

    def __init__(self, configuration):
        super(GeneralSection, self).__init__()
        
        self.configuration = configuration
        self.configurationLines = []
        self.failure_email = ''
        self.failure_email_by_project = {}
        self.success_email = ''
        self.smtp_server = ''
        self.from_email = ''
        self.reply_to_email = ''
        self.global_status_file = None
        self.email_notification_by_default = 'OFF'
        self.jenkins_server_url = ''
        self.jenkins_build_name = ''
        self.jenkins_global_job_name_step_by_default = ''
        self.jenkins_username = None
        self.jenkins_token = None
        self.directory_id_by_default = ''
        self.env = {}

    def addConfigurationLine(self, line):
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            raise SyntaxError()

    def validate_option(self, option):
        if option == 'env':
            # env variables are set immediately
            self.init_vars()

    def init_vars(self):
        super(GeneralSection, self).init_vars()
        # actually add env vars to os.environ
        for var, value in six.iteritems(self._env_vars):
            if var not in os.environ or os.environ[var] != value:
                os.environ[var] = value


class DirectorySection(object):

    def __init__(self):
        super(DirectorySection, self).__init__()
        self.status = {}
        self.start_time = {}
        self.stop_time = {}
        self.depend_on_sections = {}
        self.deps_set = False
        self.build_condition = None
        self.stdout_file = None
        self.stderr_file = None

    def has_failed(self, step):
        return self.status.get(step, 'not run') \
            in ('failed', 'interrupted', 'unmet dependency')

    def has_succeeded(self, step):
        return not self.status.get(step, 'not run') == 'succeeded'

    def get_status(self, step):
        return self.status.get(step, 'not run')

    def has_satisfied_dependencies(self, step):
        if not self.deps_set:
            self.set_dependencies()
            self.deps_set = True

        for dep, dep_step in self.depend_on_sections.get(step, []):
            if dep.has_failed(dep_step):
                self.status[step] = 'unmet dependency'
                return False
        return True

    def set_dependencies(self):
        pass

    def conditional_build(self):
        '''Tells if the current directory has actually to be built.
        If a condition option is False, it will not.
        '''
        if not self.build_condition:
            return True
        cond = True
        try:
            cond = eval(self.build_condition)
        except Exception as e:
            print('Directory', self.directory,
                  ': error in parsing build_condition option:',
                  file=sys.stderr)
            print(self.build_condition, file=sys.stderr)
            print('(Condition is evaluated as python expression). Error:',
                  sys.stderr)
            print(e, file=sys.stderr)
            raise
        return cond

    def process_configuration_lines(self):
        pass


class SourceDirectory(DirectorySection, ConfigVariableParser):

    _variables_with_replacements = set(('directory_id',  'cross_compiling_dirs'))
    _path_variables = set(('directory',))
    _validAdditiveOptions = set(('default_steps', 'cross_compiling_dirs'))
    _validOptions = set(('revision_control',
                         'build_condition',
                         'stdout_file', 'stderr_file'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)
        
    def __init__(self, directory, configuration):
        super(SourceDirectory, self).__init__()
        self.configuration = configuration
        self.directory = directory
        self.configurationLines = []
        self.sourceConfigurationLines = []
        self.svnComponents = []
        self.gitComponents = []
        self.default_steps = ['sources']
        self.revision_control = 'ON'
        self.directory_id = ''
        # cross_compiling_dirs contains toolchain substitutions for source
        # directories. This is used when execution needs different path to
        # access sources (i.e.: in windows cross compilation, for pure python
        # components, it is necessary to access source directory through
        # network share, instead of NFS mount point.
        self.cross_compiling_dirs = {}
        if self.configuration.verbose:
            print('Processing source directory %s' % self.directory)
        
    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ source ... ]:
        #    default_steps [info] [sources]
        #    git <url> <git_tag> [<dest_directory> [<bv_version>]]
        #    svn <url> [<dest_directory> [<bv_version>]]
        #    brainvisa <component_pattern> <version_pattern>
        #    brainvisa_exclude <component_pattern> [<version_pattern>]
        #    + soma/soma-base/trunk [<dest_directory>] [<bv_version>]]
        #    + https://svn.url [<dest_directory>] [<bv_version>]]
        #    + <component_pattern> <version_pattern>
        #    - <component_pattern> [<version_pattern>]
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            self.sourceConfigurationLines.append(line)
            
    def parseSourceConfiguration(self):
        for l in self.sourceConfigurationLines:
            self.parseSourceConfigurationLine(l)
        
    def parseSourceConfigurationLine(self, line, virtual=False, 
                                     component_version = None):
        line = os.path.expandvars(line)
        l = line.split()
        sign = l[0]
        if sign == 'git':
            if len(l) < 3 or len(l) > 5:
                raise SyntaxError()
            sign, url, git_tag, dest_directory, bv_version = (
                l + [None, None])[:5]
            git_tag_type, git_tag = (['branch'] \
                + git_tag.split(':',1))[-2:]
            if self.configuration.verbose:
                print('    adding repository: git', url, git_tag)
                print('                   in:', \
                    os.path.join(self.directory, dest_directory))
                if component_version:
                    print('                  for: %s version %s' \
                        % component_version)
            self.gitComponents.append(
                (component_version, url, git_tag, dest_directory,
                    bv_version))
        else:
            if len(l) < 2 or len(l) > 4:
                raise SyntaxError()
            sign, componentPattern, versionPattern, bv_version = (
                l + [None, None])[:4]
            if sign == 'svn' or (sign == '+' and '/' in componentPattern):
                if '*' in componentPattern:
                    raise SyntaxError()
                if componentPattern.startswith('http') \
                        or componentPattern.startswith('file'):
                    url = componentPattern
                    dest_directory = versionPattern
                else:
                    url = brainvisa_projects.SVN_URL + '/' \
                        + componentPattern
                    dest_directory = versionPattern
                    if dest_directory is None:
                        dest_directory = componentPattern
                if dest_directory is None:
                    raise SyntaxError()
                if self.configuration.verbose:
                    print('    adding repository: svn', url,
                            component_version)
                    print('                   in:', \
                        os.path.join(self.directory, dest_directory))
                    if component_version:
                        print('                  for: %s version %s' \
                            % component_version)

                self.svnComponents.append(
                    (component_version, url, dest_directory, bv_version))
            elif sign in ('brainvisa', '+'):
                if versionPattern is None:
                    raise SyntaxError()
                for component in brainvisa_projects.find_components(
                    componentPattern):
                    project = brainvisa_projects.project_per_component[
                        component]
                    for version, repo_dir in six.iteritems(
                        brainvisa_projects.url_per_component[component]):
                        repo, dir = repo_dir
                        if fnmatchcase(version, versionPattern):
                            self.parseSourceConfigurationLine(
                                '%s %s %s' % (repo, dir, version), 
                                virtual=True, 
                                component_version=(component, version))
            elif sign in ('-', 'brainvisa_exclude'):
                if '/' in componentPattern:
                    raise SyntaxError()
                else:
                    if versionPattern is None:
                        versionPattern = '*'
                    for component in brainvisa_projects.find_components(
                        componentPattern):
                        for version, repo_dir in six.iteritems(
                            brainvisa_projects.url_per_component[
                                component]):
                            if fnmatchcase(version, versionPattern):
                                # Remove unwanted svn components
                                count = 0
                                for component_version \
                                    in [i[0] for i in self.svnComponents]:
                                    if component_version:
                                        c, v = component_version
                                        if c == component and v == version:
                                            if self.configuration.verbose:
                                                component_version, url, \
                                                dest_directory, bv_version = \
                                                self.svnComponents[count]
                                                print('    removing repository:',
                                                      'svn', url)
                                                print('                     in:',
                                                      os.path.join(
                                                          self.directory, 
                                                          dest_directory))
                                                print('                    for: %s version %s' % component_version)
                                            del self.svnComponents[count]
                                            count -= 1
                                    count += 1
                                # Remove unwanted git components
                                count = 0
                                for component_version in [i[0] for i in self.gitComponents]:
                                    if component_version:
                                        c, v = component_version
                                        if c == component and v == version:
                                            if self.configuration.verbose:
                                                component_version, url, git_tag, dest_directory, bv_version = self.gitComponents[
                                                    count]
                                                print('    removing repository: git', url, git_tag)
                                                print('                     in:', os.path.join(self.directory, dest_directory))
                                                print('                    for: %s version %s' % component_version)
                                            del self.gitComponents[count]
                                            count -= 1
                                    count += 1
            else:
                raise SyntaxError('Line cannot begin with "%s"' % sign)
            
        if not virtual:
            self.configurationLines.append(line)

    def process(self, options, args):
        if not os.path.exists(self.directory):
            os.makedirs(self.directory)
        clientFile = open(os.path.join(self.directory, 'bv_maker.cfg'), 'w')
        print('\n'.join(self.configurationLines), file=clientFile)

        repositoryDirectory = os.path.join(self.directory, '.repository')
        checkout = False
        use_rcs = self.revision_control.upper() in ('', 'ON')
        if use_rcs and options.svn and not os.path.exists(repositoryDirectory):
            os.makedirs(repositoryDirectory)
            # Because of a bug in svnadmin on MacOS, I cannot use an absolute name for the directory to create.
            # When I try "svnadmin create /neurospin/brainvisa/cmake_mac/", I have the following error:
            # svnadmin: '/neurospin/brainvisa/cmake_mac' is a subdirectory of an existing repository rooted at '/neurospin'
            # But it works if I do "cd /neurospin/brainvisa && vnadmin create
            # cmake_mac"
            cwd, dir = os.path.split(repositoryDirectory)
            system('svnadmin', 'create', dir, cwd=cwd)

            if len(os.path.splitdrive(repositoryDirectory)[0]) > 0:
                # This is for windows absolute pathes
                repositoryDirectory = '/' + \
                    repositoryDirectory.replace(os.path.sep, "/")

            self.svncommand(
                'checkout',  'file://' + repositoryDirectory, self.directory)
            checkout = True

        source_directories = []

        # Update SVN repositories

        current_dir = os.getcwd()
        # Go to the sources directory
        os.chdir(self.directory)
        externalsFileName = os.path.join(self.directory, 'bv_maker.externals')
        externalsFile = open(externalsFileName, 'w')
        for component_version, url, dest_directory, bv_version in set(self.svnComponents):
            print(dest_directory, url, file=externalsFile)
            source_directories.append((dest_directory, bv_version))
        externalsFile.close()
        if use_rcs and options.svn:
            if options.cleanup:
                self.svncommand('cleanup', self.directory)
            self.svncommand('propset', 'svn:externals',
                            '--file', externalsFileName, self.directory)
            self.svncommand('commit', '-m', '', self.directory)
            self.svncommand('update', self.directory)
        os.chdir(current_dir)

        # update Git Repositories

        for component_version, url, git_tag, dest_directory, bv_version \
                in self.gitComponents:
            if dest_directory is None:
                dest_directory = url.rsplit('/', 1)[-1]
                if dest_directory.endswith('.git'):
                    dest_directory = dest_directory[:-4]
            dest_path = os.path.join(self.directory, dest_directory)
            if use_rcs and options.git:
                self.gitupdate(url, dest_path, git_tag)
            source_directories.append((dest_path, bv_version))

        components_sources = {}
        for dest_path, bv_version in source_directories:
            pinfo = brainvisa_projects.read_project_info(
                os.path.join(self.directory, dest_path),
                version_format=version_format_short
            )
            if pinfo:
                project, component, version, build_model = pinfo
                version = str(version)
                components_sources.setdefault(component, {})[
                    bv_version or version] = (dest_path, build_model)
            else:
                print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found' % os.path.join(self.directory, dest_path))
        json.dump(components_sources, open(
            os.path.join(self.directory, 'components_sources.json'), 'w'), indent=2)

    def svncommand(self, *svnargs):
        cmd = ['svn', svnargs[0]]
        if self.configuration.username:
            cmd += ['--username', self.configuration.username]
            if self.configuration.username == 'brainvisa':
                cmd += ['--password', 'Soma2009']
        cmd.extend(svnargs[1:])
        system(*cmd)

    def get_git_remotes(self, dest):
        cmd_output = str(system_output_on_error(['git', 'remote', '-v'],
                                                cwd=dest))
        remotes = {}
        for line in cmd_output.split('\n'):
            remotere = re.compile('^([^ ]+)[\s|\t]+([^ ]+)\s+([^ ]+)\s*$')
            m = remotere.match(line)
            if not m:
                continue
            remote, url, io = m.group(1), m.group(2), m.group(3)
            if remote not in remotes:
                if url.startswith('git@'):
                    protocol = 'git'
                    prefix, address = url.split(':')
                    prefix += ':'
                elif url.startswith('https://'):
                    protocol = 'https'
                    address = url[8:].split('/')
                    prefix = url[:8] + address[0] + '/'
                    address = '/'.join(address[1:])
                else:
                    # assume local repository
                    protocol = ''
                    prefix = ''
                    address = url
                remotes[remote] = protocol, prefix, address
        return remotes

    def gitupdate(self, src, dest, remote_ref="HEAD"):
        # Set a username in src if necessary
        if '@' not in src and self.configuration.username:
            url_head, url_tail = src.split('//', 1)
            src = '%s//%s@%s' % (
                url_head, self.configuration.username, url_tail)

        print("Updating git repository {0}".format(dest))

        # Clone repository if it does not exist yet locally
        if not os.path.exists(os.path.join(dest, '.git')):
            if os.path.isdir(dest) and os.listdir(dest):
                print('''
ERROR: directory "%s" is not empty, Git will not be able to clone into it.
This error may be due to a repository change for a component (typically
going from Subversion to Git). You must check yourself that you have nothing
to keep in this directory and delete it to make "bv_maker sources" work.'''
                       % dest)
            if self.configuration.verbose:
                print('directory %s is not a git repository => clone from git %s'
                      % (dest, src))
            os.makedirs(dest)
            retcode = subprocess.call(['git', 'init', '--quiet'], cwd=dest)
            if retcode != 0:
                print(
                    'ERROR: could not initialize git repository in {0}'.format(dest))
                return

        remotes = self.get_git_remotes(dest)
        if 'origin' in remotes:
            remote = remotes['origin']
            if src.endswith(remote[2]):
                    # user has configured manually a different protocol:
                    # respect it.
                src = remote[1] + remote[2]
        # Configure a remote for the developer's convenience
        retcode = subprocess.call(['git', 'remote', 'set-url', 'origin', src],
                                  cwd=dest, stderr=open(os.devnull, 'w'))
        if retcode != 0:
            subprocess.call(['git', 'remote', 'add', 'origin', src],
                            cwd=dest)
            # Failure is ignored deliberately (the remote is just for
            # convenience)

        # Get the SHA-1 identifiers of HEAD and refs/bv_head commits
        try:
            old_head = str(subprocess.check_output(
                ['git', 'rev-parse', '--quiet', '--verify', 'HEAD^{commit}'],
                cwd=dest))
        except subprocess.CalledProcessError:
            old_head = None
        try:
            old_bv_head = str(subprocess.check_output(
                ['git', 'rev-parse', '--quiet',
                 '--verify', 'refs/bv_head^{commit}'],
                cwd=dest))
        except subprocess.CalledProcessError:
            old_bv_head = None

        # Fetch the remotes specified in bv_maker.cfg into refs/bv_head
        remotes = self.get_git_remotes(dest)
        for remote in remotes:
            # get stderr in a separate stream since git finds it funny to print
            # normal operation messages in stderr.
            stderr_str = tempfile.NamedTemporaryFile(delete=False)
            retcode = subprocess.call(['git', 'fetch', '--quiet', '--tags',
                                       remote],
                                      cwd=dest, stderr=stderr_str)
            stderr_str.close()
            stderr_content = open(stderr_str.name).read()
            os.unlink(stderr_str.name)

            if retcode != 0:
                sys.stderr.write(stderr_content)
                print(
                    '{0}: could not fetch from git repository {1}'.format(dest, src))
            else:
                # if no error, the output is sent to stdout, not stderr.
                sys.stdout.write(stderr_content)

        retcode = subprocess.call(['git', 'fetch', '--quiet', src,
                                   "+" + remote_ref + ":refs/bv_head"],
                                  cwd=dest)
        if retcode != 0:
            print(
                '{0}: could not fetch from git repository {1}'.format(dest, src))
            return  # Abort for this repository, continue with other repositories

        # Check if we are in detached HEAD state
        retcode = subprocess.call(['git', 'symbolic-ref', '--quiet', 'HEAD'],
                                  cwd=dest, stdout=open(os.devnull, 'w'))
        detached_head = False if retcode == 0 else True

        if (not old_head) or (detached_head and old_head == old_bv_head):
            # HEAD is detached, and is the same as left by the previous
            # bv_maker run: this is "follower mode", the remote ref can be
            # checked out. This is safe to do even if there are local
            # uncommitted changes, in which case "git checkout" will error out
            # appropriately.
            retcode = subprocess.call(['git', 'checkout', '--quiet',
                                       '--detach', 'refs/bv_head', '--'],
                                      cwd=dest)
            if retcode != 0:
                print("""\
The git repository at {0} could not be updated,
please refer to the above error message.

If you have made local changes, you should keep track of them in a branch:
  git checkout -b <my_branch>
  git add ...
  git commit

Or, discard your changes and go back to following the upstream version:
  git checkout bv_head""".format(dest))
        elif not detached_head:
            # We are following a branch. Advance the branch if it has not
            # diverged from upstream. If local commits exist, that would
            # require creating a merge commit, and we do not want to do that
            # behind the back of the developer. The (fetch + merge) command
            # sequence is equivalent to "git pull --ff-only src remote_ref".
            # The merge aborts safely if there are local uncommitted changes,
            # and prints an appropriate message.
            retcode = subprocess.call(
                ['git', 'merge', '--ff-only', 'refs/bv_head'],
                cwd=dest)
            if retcode != 0:
                print("""\
Upstream changes could not be merged in {0},
please refer to the above message of "git merge".

If you do not want to develop in this repository anymore, you should
leave the branch and go back to tracking the upstream version:
  git checkout bv_head""".format(dest))
        else:
            # HEAD is detached but has been moved since last bv_maker run. The
            # user has likely checked out a tag manually, do not mess with
            # their repository.
            print("""\
The git repository at {0} will not be updated by bv_maker,
because it is detached at a commit that does not correspond to bv_head.
If you did not do this on purpose, you should go back to following upstream:
  git -C '{0}' checkout bv_head""".format(dest))

    def info(self):
        print('Source directory: "' + self.directory + '"')
        for component_version, url, dest_directory, bv_version in self.svnComponents:
            print('  %s <- svn %s' % (dest_directory, url))
            if component_version:
                component, version = component_version
                print('    component %s (%s)' % (component, version))
        for component_version, url, git_tag, dest_directory, bv_version in self.gitComponents:
            print('  %s <- git %s' % (dest_directory, url))
            if component_version:
                component, version = component_version
                print('    component %s (%s)' % (component, version))


class ComponentsConfigParser(DirectorySection):

    def __init__(self, directory, configuration):
        super(ComponentsConfigParser, self).__init__()
        self.configuration = configuration
        self.directory = directory
        self.configurationLines = []
        self.projects = set()
        self.components = {}
        self._configuration_lines_processed = False

    def process_configuration_lines(self):
        if not self._configuration_lines_processed:
            if self.configuration.verbose:
                print('Processing build directory %s' % self.directory)
            for line in self.configurationLines:
                if '=' in line:
                    continue
                first, rest = line.split(None, 1)
                if first in ('directory', '+'):
                    directory = environmentPathVariablesSubstitution(
                            rest.strip(), env=self.get_environ())
                    pinfo = brainvisa_projects.read_project_info(
                        directory,
                        version_format=version_format_short
                    )
                    if pinfo:
                        project, component, version, build_model = pinfo
                        version = str(version)
                        if self.configuration.verbose:
                            print('    adding component %s version %s from %s'
                                  % (component, version, directory))
                        self.components[component] = (
                            directory, version, version, build_model)
                    else:
                        print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found' % directory)
                elif first in ('brainvisa_exclude', '-'):
                    component_def = rest.split(None, 1)
                    componentPattern, versionPattern = (
                        component_def + ['*'])[:2]
                    components \
                        = brainvisa_projects.find_components(componentPattern)
                    if len(components) == 0 \
                            and component_def[0] in self.components:
                        components = [component_def[0]]
                    for component in components:
                        dir_version = self.components.get(component)
                        if dir_version:
                            dir, selected_version, component_version, \
                               build_model = dir_version
                            if fnmatchcase(selected_version, versionPattern):
                                if self.configuration.verbose:
                                    print('    removing component %s from %s'
                                          % (component, dir))
                                del self.components[component]
                elif first == 'brainvisa' \
                        or (first
                            in brainvisa_projects.project_per_component) \
                        or (first in brainvisa_projects.components_per_group) \
                        or (first
                            in brainvisa_projects.components_per_project) \
                        or '*' in first:
                    if first == 'brainvisa':
                        l = rest.split(None, 2)
                        componentPattern, versionPattern, sourceDirectory = l
                    else:
                        l = rest.split(None, 1)
                        componentPattern = first
                        versionPattern, sourceDirectory = l
                    sourceDirectory = environmentPathVariablesSubstitution(
                            sourceDirectory, env=self.get_environ())
                    components_sources = json.load(
                        open(os.path.join(sourceDirectory,
                                          'components_sources.json')))
                    projects_set = brainvisa_projects.ProjectsSet()
                    projects_set.add_sources_list(components_sources)
                    possible_components = set(
                        projects_set.find_components(componentPattern))
                    for component in possible_components:
                        for version, directory_model \
                                in six.iteritems(
                                    components_sources.get(component, {})):
                            if isinstance(directory_model, list):
                                directory, build_model = directory_model
                            else:
                                directory = directory_model
                                build_model = None
                            directory = os.path.join(
                                sourceDirectory, directory)
                            if fnmatchcase(version, versionPattern):
                                pinfo = brainvisa_projects.read_project_info(
                                    directory,
                                    version_format=version_format_short
                                )
                                if pinfo:
                                    project, component, component_version, \
                                        build_model = pinfo
                                    component_version = str(component_version)
                                    if self.configuration.verbose:
                                        print('    adding component %s version %s from %s' \
                                            % (component, version, directory))
                                    self.components[component] = (
                                        directory, version, component_version, build_model)
                                else:
                                    print('WARNING: directory %s will be ignored because project_info.cmake, python/*/info.py or */info.py cannot be found'
                                          % directory)
                elif first == 'pip':
                    if '=' in rest:
                        module, version = rest.split(None, 1)
                    else:
                        module = rest
                        version = None
                    installed_json = os.path.join(
                        self.directory, 'bv_maker_install.json')
                    if os.path.exists(installed_json):
                        installed = json.load(open(installed_json))
                    else:
                        installed = {}
                    pip_installed = installed.setdefault('pip', {})
                    if module not in pip_installed:
                        command = [os.path.join(
                            self.directory, 'bin', 'pip'), 'install',
                            ('%s==%s' % (module, version) if version
                             else module)]
                        print('Running:', ' '.join(command))
                        subprocess.check_call(command)
                        pip_installed[module] = version
                        json.dump(installed, open(installed_json, 'w'))
                else:
                    SyntaxError()
            projects = set(brainvisa_projects.project_per_component.get(i, i)
                           for i in self.components)
            self.projects = [i for i in brainvisa_projects.ordered_projects
                             if i in projects]
            self.projects.extend(projects - set(self.projects))
            self._configuration_lines_processed = True
            if self.configuration.verbose:
                print('Build directory %s parsing done.' % self.directory)


class BuildDirectory(ComponentsConfigParser, ConfigVariableParser):

    _path_variables = set(('directory',
                           'stdout_file', 'stderr_file',
                           'test_ref_data_dir', 'test_run_data_dir'))
    _variables_with_replacements = set(('make_options', 'cmake_options',
                                        'ctest_options', 'directory_id', ))
    _variables_with_env_only_replacements = set(('cross_compiling_prefix',
                                          'cross_compiling_target_system',
                                          'cross_compiling_to_target_path_cmd',
                                          'env', 
                                          'test_ref_data_dir', 
                                          'test_run_data_dir'))
    _validAdditiveOptions = set(('make_options', 'cmake_options', 'env',
                                 'default_steps', 'ctest_options'))
    _validOptions = set(('build_type',
                         'packaging_thirdparty',
                         'build_condition', 'clean_config',
                         'clean_build'))
    _validOptions.update(_validAdditiveOptions)
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)

    sitecustomize_content = '''import os, sys

for i in os.listdir(os.path.dirname(__file__)):
    if i.endswith('.py') and i != '__init__.py':
        module = i[:-3]
        __import__('sitecustomize.%s' % module)

# seek for other sitecustomize modules in path
try:
    i = sys.path.index(os.path.dirname(os.path.dirname(__file__)))
except ValueError:
    i = -1
if 'old_file' not in globals():
  old_file = []
old_file.append(__file__)
for p in sys.path[i+1:]:
    if os.path.isdir(p):
        filename = os.path.join(p, 'sitecustomize.py')
        if not os.path.exists(filename):
            filename = os.path.join(p, 'sitecustomize', '__init__.py')
        if os.path.exists(filename):
            __file__ = filename
            exec(compile(open(filename).read(), filename, 'exec'))
__file__ = old_file.pop()
for v in ('filename', 'p', 'i'):
    if v in globals():
        del globals()[v]
del v
if len(old_file) == 0:
    del old_file
'''

    def __init__(self, directory, configuration):
        super(BuildDirectory, self).__init__(directory, configuration)
        # self.configurationDirectories = []
        self.build_type = ''
        self.make_options = []
        self.cmake_options = []
        self.packaging_thirdparty = ''
        self.cross_compiling_prefix = ''
        self.cross_compiling_target_system = ''
        self.cross_compiling_to_target_path_cmd = ''
        self.clean_commands = True
        self.default_steps = ['configure', 'build']
        self.clean_config = 'OFF'
        self.clean_build = 'OFF'
        self.ctest_options = []
        self.directory_id = ''
        self.env = {}
        self.test_ref_data_dir = ''
        self.test_run_data_dir = tempfile.gettempdir()

    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ build ... ]:
        #    default_steps [info] [configure] [build] [doc] [test]
        #    directory <directory>
        #    brainvisa <component_pattern> <version_pattern> <source_directory>
        #    brainvisa_exclude <component_pattern> [<version_pattern>]
        #    + <directory>
        #    - <component_pattern> [<version_pattern>]
        #    <component_pattern> <version_pattern> <source_directory>
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            line = os.path.expandvars(line)
            if line[0] == '+':
                if '*' in line:
                    raise SyntaxError()
        self.configurationLines.append(line)

    def set_dependencies(self):
        self.depend_on_sections = {
            'configure': [(d, 'sources')
                          for d in
                          self.configuration.sourcesDirectories.values()],
            'build': [(self, 'configure')],
            'doc': [(self, 'build')],
            'test': [(self, 'build')],
            'testref': [(self, 'build')],
        }
    
    def target_system(self):
        if self.cross_compiling_target_system:
            return self.cross_compiling_target_system
        elif self.cross_compiling_prefix:
            if 'mingw' in self.cross_compiling_prefix:
                # Try to split target prefix
                cross_compiling_info = self.cross_compiling_prefix.split('-')
                
                if len(cross_compiling_info) == 3 \
                   and cross_compiling_info[0] == 'x86_64':
                       return 'win64'
                
                return 'win32'
            else:
                raise RuntimeError('Unable to determine target cross '
                                   'compilation system. Please set '
                                   'cross_compiling_target_system option in '
                                   ' build section of your configuration file.')
        else:
            # Target system is the host system
            return sys.platform
        
    def to_target_path(self, path):
        '''
            Get target system path from path
        '''
        host_path_system = get_host_path_system()
        if not isinstance(path, Path):
            path = Path(path, host_path_system)
            
        target_path_system = get_target_path_system(self.target_system())
        if host_path_system != target_path_system:
            if not DefaultPathConverterRegistry().get((host_path_system, 
                                                       target_path_system)):
                if self.cross_compiling_to_target_path_cmd:
                    # Register host to target conversion command
                    cmd = shlex.split(self.cross_compiling_to_target_path_cmd)
                elif host_path_system == 'linux' \
                    and target_path_system == 'windows':
                    # Default cross compilation try to use winepath command
                    # to convert pathes
                    cmd = ['winepath', '-w']
                else:
                    raise RuntimeError('No known conversion between %s and %s '
                                       'path systems. Please set ' 
                                       '\'cross_compiling_to_target_path_cmd\' '
                                       'using an available command to do the '
                                       'conversion'
                                       % (host_path_system, target_path_system))
                
                SystemPathConverter(host_path_system, 
                                    target_path_system, 
                                    cmd)
            
            if target_path_system == 'windows':
                # If target path system is windows, 
                # we prefer to use the windows alternative with slashes
                target_path_system = 'windows_alt'
                
            return path.to_system(target_path_system)
        
        else:
            return path

    def configure(self, options, args):
        self.process_configuration_lines()
        # Order of projects and components is important for dependencies
        sortedProjects = [p for p in brainvisa_projects.ordered_projects
                          if p in self.projects]
        sortedComponents = []
        components = set(self.components)
        for project in sortedProjects:
            for component \
                    in brainvisa_projects.components_per_project[project]:
                if component in components:
                    sortedComponents.append(component)
                    components.remove(component)
        sortedComponents.extend(components)

        if not os.path.exists(self.directory):
            os.makedirs(self.directory)

        if options.clean or self.clean_config.upper == 'ON':
            my_path = os.path.dirname(__file__)
            bv_clean = os.path.join(my_path, 'bv_clean_build_tree')
            print('cleaning build tree', self.directory)
            # clean and remove empty dirs. Don't use -b option here
            # because configuration has to be done first.
            subprocess.call([sys.executable, bv_clean, '-d', self.directory],
                            env=self.get_environ())

        # Create a sitecustomize Python package that imports all modules it
        # contains during Python startup. This is mainly used to modify
        # sys.path to include pure Python components source (see module
        # brainvisa.maker.build_models.pure_python). This package is used only
        # in build directory, it is not installed in packages (to date there is
        # one exception to this in axon component, see Axon's CMakeLists.txt).
        sitecustomize_dir = os.path.join(
            self.directory, 'python', 'sitecustomize')
        if not os.path.exists(sitecustomize_dir):
            os.makedirs(sitecustomize_dir)
        open(os.path.join(sitecustomize_dir, '__init__.py'), 'w').write(
            self.sitecustomize_content)
        # Remove existing sitecustomize.py (was generated by older Axon)
        for i in glob.glob(sitecustomize_dir + '.py*'):
            os.remove(i)

        if not os.path.exists(self.directory):
            os.makedirs(self.directory)

        cross_compiling_directories = {}
        for k, s in six.iteritems(self.configuration.sourcesDirectories):
            if s.cross_compiling_dirs is not None:
                if len(self.cross_compiling_prefix) > 0:
                    cross_compiling_dir = \
                        s.cross_compiling_dirs.get(
                            self.cross_compiling_prefix)

                    if cross_compiling_dir is not None:
                        cross_compiling_directories[s.directory] = cross_compiling_dir

        #print('==== Toolchain:', self.cross_compiling_prefix,
        #      'directories:', cross_compiling_directories)
        self.buildModelPerComponent = {}
        for component in sortedComponents:
            # find build model
            build_model = self.components[component][3]
            if build_model is None:
                build_model = brainvisa_projects.info_per_component.get(
                    component, {}).get('build_model')
            if build_model is not None:
                build_model_class = getattr(__import__(
                    'brainvisa.maker.build_models',
                    fromlist=['pure_python'], level=0),
                    build_model)
                build_model = build_model_class(
                    component, self.components[component][0], self,
                    cross_compiling_directories, options=options, args=args)
                self.buildModelPerComponent[component] = build_model

        cmakeFile = os.path.join(self.directory, 'bv_maker.cmake')
        out = open(cmakeFile, 'w')
        print('set( BRAINVISA_PROJECTS', ' '.join(
            sortedProjects), 'CACHE STRING "BrainVISA Projects list" FORCE )',
            file=out)
        print('set( _BRAINVISA_PROJECTS', ' '.join(
            sortedProjects), 'CACHE STRING "BrainVISA Projects list" FORCE )',
            file=out)
        print('set( BRAINVISA_COMPONENTS',
              ' '.join(sortedComponents),
              'CACHE STRING "BrainVISA components list" FORCE )',
              file=out)
        print('set( _BRAINVISA_COMPONENTS',
              ' '.join(sortedComponents),
              'CACHE STRING "BrainVISA components list" FORCE )',
              file=out)
        print(file=out)
        for component, directory_version_model in six.iteritems(self.components):
            directory, selected_version, version, build_model = directory_version_model
            if component in self.buildModelPerComponent:
                print('set( BRAINVISA_SOURCES_' + component + ' "' \
                    + cmake_path(self.directory ) + '/build_files/' \
                    + component + '_src' \
                    + '" CACHE STRING "Sources directory for component ' \
                    + component + '" FORCE )',
                    file=out)
            else:
                print('set( BRAINVISA_SOURCES_' + component + ' "' \
                    + cmake_path(directory) \
                    + '" CACHE STRING "Sources directory for component ' \
                    + component + '" FORCE )',
                    file=out)
            print('set( ' + component + '_DIR "' \
                + cmake_path(self.directory ) + '/share/' + component + \
                '-' + version + \
                '/cmake" CACHE STRING "Directory used for find_package( ' + \
                component + \
                ' )" FORCE )',
                file=out)
            print('set( ' + component + '_VERSION "' + version + '" )',
                  file=out)

        cmakeLists = os.path.join(self.directory, 'CMakeLists.txt')
        out.close()
        out = open(cmakeLists, 'w')
        print('''
cmake_minimum_required( VERSION 2.6 )
set( CMAKE_PREFIX_PATH "${CMAKE_BINARY_DIR}" ${CMAKE_PREFIX_PATH} )
find_package( brainvisa-cmake NO_POLICY_SCOPE )
include( "${brainvisa-cmake_DIR}/brainvisa-compilation.cmake" )
''', file=out)
        out.close()
        exe_suffix = ''
        if sys.platform == 'win32':
            command_base = ['cmake', '-G', 'MSYS Makefiles']
            exe_suffix = '.exe'
        else:
            command_base = ['cmake']

        command_options = list(self.cmake_options)
        command_options += ['-DCMAKE_BUILD_TYPE:STRING=' + self.build_type]
        if self.packaging_thirdparty.upper() == 'ON':
            command_options += ['-DBRAINVISA_PACKAGING_THIRDPARTY:BOOL=ON']
        elif self.packaging_thirdparty.upper() == 'OFF':
            command_options += ['-DBRAINVISA_PACKAGING_THIRDPARTY:BOOL=OFF']

        config_dir = cmake_path(self.directory)

        for component, build_model \
                in six.iteritems(self.buildModelPerComponent):
            build_model.configure()

        # set bv_maker path, so that cmake finds its modules
        os.environ['PATH'] = os.path.dirname(this_script) + os.pathsep \
            + os.getenv('PATH')

        # cross compilation options
        cross_compiling_prefix = self.cross_compiling_prefix.strip()
        if len(cross_compiling_prefix) > 0:
            cross_compiling_prefix_path = os.path.join( cmake_root,
                                                        'toolchains',
                                                        cross_compiling_prefix )
            cross_compiling_options = ['-DBRAINVISA_CMAKE_OPTIONS:STRING=' \
                                       'CMAKE_CROSSCOMPILING;COMPILER_PREFIX;' \
                                       'CMAKE_TOOLCHAIN_FILE', \
                                       '-DCOMPILER_PREFIX:STRING=%s' % \
                                       self.cross_compiling_prefix.strip(), \
                                       '-DCMAKE_CROSSCOMPILING:BOOL=ON']
            cross_compiling_toolchain_path = os.path.join(
                                                cross_compiling_prefix_path,
                                                'toolchain.cmake' )

            cross_compiling_init_cache_path = os.path.join(
                                                cross_compiling_prefix_path,
                                                'init-cache.cmake' )
            #print("=== cross_compiling_prefix:", cross_compiling_prefix, "===")
            #print("=== cross_compiling_prefix_path:", cross_compiling_prefix_path, "===")
            #print("=== cross_compiling_toolchain_path:", cross_compiling_toolchain_path, "===")
            #print("=== cross_compiling_init_cache_path:", cross_compiling_init_cache_path, "===")
            if os.path.exists( cross_compiling_toolchain_path ):
                cross_compiling_options += ['-DCMAKE_TOOLCHAIN_FILE:PATH=%s' % \
                                            cmake_path(
                                              cross_compiling_toolchain_path),]

            if os.path.exists( cross_compiling_init_cache_path ):
                cross_compiling_options += ['-C',
                                            cmake_path(
                                              cross_compiling_init_cache_path),]
            #print('cross compiling using toolchain:', cross_compiling_prefix)
            #print('  with options:', *cross_compiling_options)
        else:
            cross_compiling_options = []

        # special case: if bv-cmake is part of the build directory, run cmake
        # in 2 passes: once to reinstall bv-cmake from sources, and a second
        # time to actually configure all projects using the newly installed
        # bv-cmake.
        if 'brainvisa-cmake' in self.components:
            print('=== bootstraping brainvisa-cmake project ===')
            bvcmake_dir = os.path.join(self.directory, 'brainvisa-cmake')
            if not os.path.exists(bvcmake_dir):
                os.makedirs(bvcmake_dir)
            # pass it Qt version if we have any info
            bvcmake_options = []
            qt_opt = [x for x in self.cmake_options
                      if x.startswith('DESIRED_QT_VERSION')]
            if qt_opt:
                qt_opt = qt_opt[0].split('=')[1].strip()
                bvcmake_options.append('-DDESIRED_QT_VERSION=%s' %qt_opt)
            elif os.path.exists(os.path.join(self.directory, 'CMakeCache.txt')):
                with open(os.path.join(self.directory, 'CMakeCache.txt')) as f:
                    for l in f.readlines():
                        if l.startswith('DESIRED_QT_VERSION:'):
                            qt_opt = l.split('=')[1].strip()
                            bvcmake_options.append(
                                '-DDESIRED_QT_VERSION=%s' %qt_opt)
            system(cwd=bvcmake_dir,
                   *(command_base
                     + [self.components['brainvisa-cmake'][0],
                        '-DBRAINVISA_CMAKE_BUILD_TYPE=brainvisa-cmake-only',
                        '-DCMAKE_INSTALL_PREFIX=%s' % self.directory]
                     + bvcmake_options),
                     env=self.get_environ())
            system(cwd=bvcmake_dir, *['make', 'install'],
                   env=self.get_environ())
            print('=== now configuring all other projects ===')
            # run with this local bv-cmake environment
            system(cwd=self.directory,
                   *( [os.path.join(self.directory, 'bin',
                                    'bv_env_host%s' % exe_suffix)]
                     + command_base
                     + command_options
                     + cross_compiling_options
                     + ["-DBRAINVISA_CMAKE_BUILD_TYPE=no-brainvisa-cmake"]
                     + [config_dir]),
                   env=self.get_environ())
        else:
            # run cmake in a regular way
            system(cwd=self.directory, *( command_base
                                        + command_options
                                        + cross_compiling_options
                                        + [config_dir]),
                   env=self.get_environ())
            
        
        # After a first configuration, the global version file of the build 
        # directory has been generated, and package directories variables, 
        # must be updated
        for p in self.configuration.packageDirectories.values() \
               + self.configuration.publicationDirectories.values():
            if p.get_build_dir() is self:
                version = self.get_version()
                if version:
                    p.update_python_vars({'version': version})

    def build(self, options, args):
        self.process_configuration_lines()
        if options.clean or self.clean_build.upper() == 'ON':
            if self.clean_commands:
                clean_opts = ['-b']
            else:
                clean_opts = []
            my_path = os.path.dirname(__file__)
            bv_clean = os.path.join(my_path, 'bv_clean_build_tree')
            print('cleaning build tree', self.directory)
            # don't remove empty dirs here since configure may have created
            # directories which will be used during build
            subprocess.call(
                [sys.executable, bv_clean] + clean_opts + [self.directory],
                env=self.get_environ())

        print('Building directory:', self.directory)
        system(cwd=self.directory, *(['make'] + self.make_options),
               env=self.get_environ())

    def doc(self):
        self.process_configuration_lines()
        print('Building docs in directory:', self.directory)
        system(cwd=self.directory, *
               (['make'] + self.make_options + ['doc']),
               env=self.get_environ())

    def init_vars(self):
        super(BuildDirectory, self).init_vars()
        
        self.__init_python_vars()
        self.__init_environ()
     
    def __init_python_vars(self):
        if not self._property_recursivity.get('directory'):             
            if self.target_system() == sys.platform:
                build_system = get_pack_host_system_name()
            else:
                build_system = self.target_system() 

            self.update_python_vars({'os': build_system})
            
    def __init_environ(self):
        env = {}
        
        # During environment initialization, we need skip property
        # mechanims
        if (not self._property_recursivity.get('test_run_data_dir')) \
           and self.test_run_data_dir:
            # Add directories to env
            env["BRAINVISA_TEST_RUN_DATA_DIR"] = self.to_target_path(
                self.test_run_data_dir)
        if (not self._property_recursivity.get('test_ref_data_dir')) \
           and self.test_ref_data_dir:
            # Add directories to env
            env["BRAINVISA_TEST_REF_DATA_DIR"] = self.to_target_path(
                self.test_ref_data_dir)
            
        self.update_environ(env)
    
    def reset_environ(self):
        super(BuildDirectory, self).reset_environ()
        self.__init_environ()

    def test(self, options, args):
        self.process_configuration_lines()
        if options.ctest_options is not None:
            ctoptions = shlex.split(options.ctest_options)
        else:
            ctoptions = self.ctest_options
        print('Testing directory:', self.directory)
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir is not defined; tests may fail.")
        env = self.get_environ()
        # Create test_run_data_dir and test_ref_data_dir
        if self.test_run_data_dir:
            if not os.path.exists(self.test_run_data_dir):
                os.makedirs(self.test_run_data_dir)
        if self.test_ref_data_dir:
            if not os.path.exists(self.test_ref_data_dir):
                os.makedirs(self.test_ref_data_dir)
        return run_and_log_tests(cwd=self.directory, options=ctoptions,
                                 env=env)

    def testref(self, options, args):
        self.process_configuration_lines()
        if options.make_options is not None:
            ctoptions = shlex.split(options.make_options)
        else:
            ctoptions = self.make_options
        print('Creating test reference data for directory:', self.directory)
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir should be defined to create "
                  "reference files.")
        env = self.get_environ()
        # Create test_ref_data_dir
        if self.test_ref_data_dir:
            if not os.path.exists(self.test_ref_data_dir):
                os.makedirs(self.test_ref_data_dir)
        return run_and_log_testref(cwd=self.directory, options=ctoptions,
                                   env=env)

    def info(self):
        self.process_configuration_lines()
        print('Build directory: "' + self.directory + '"')
        for component, directory_version_model \
                in six.iteritems(self.components):
            directory, selected_version, version, build_model \
                = directory_version_model
            print('  %s (%s) <- %s' % (component, version, directory))
            
    def get_version(self):
        bvconf = os.path.join(self.directory, 
                              'python', 'brainvisa', 'config.py')
        fullVersion = None
        
        if os.path.exists(bvconf):
            ver = {}
            try:
                with open(bvconf) as f:
                    code = compile(f.read(), bvconf, 'exec')
                    exec(code, ver, ver)
                fullVersion = ver.get('fullVersion', fullVersion)
            except ImportError:
                pass
            
        return fullVersion

class VirtualenvDirectory(BuildDirectory):

    '''
    It does the samething with the BuildDirectory
    with additional virtualenv init.
    '''

    def __init__(self, directory, configuration):
        super(VirtualenvDirectory, self).__init__(directory, configuration)
        self.clean_commands = False

    def configure(self, options, args):
        self.virtualenv_command(self.directory)
        super(VirtualenvDirectory, self).configure(options, args)

    def which(self, program):
        def is_exe(fpath):
            return os.path.exists(fpath) and os.access(fpath, os.X_OK)

        def ext_candidates(fpath):
            yield fpath
            for ext in os.environ.get("PATHEXT", "").split(os.pathsep):
                yield fpath + ext
        fpath, fname = os.path.split(program)
        if fpath:
            if is_exe(program):
                return program
        else:
            for path in os.environ["PATH"].split(os.pathsep):
                exe_file = os.path.join(path, program)
                for candidate in ext_candidates(exe_file):
                    if is_exe(candidate):
                        return candidate
        return None

    def virtualenv_command(self, env_path):
        if not self.which("virtualenv"):
            raise ValueError("Cannot find virtual. Please install virtualenv.")
        active_path = os.path.join(env_path, "bin", "activate")
        if not os.path.isfile(active_path):
            cmd = ["virtualenv",  "--system-site-packages"]
            cmd.append(env_path)
            system(*cmd, env=self.get_environ())
        else:
            print("No need to virtualenv init '%s' since it is already initialized." \
                % env_path)
        pass


class PackageDirectory(ComponentsConfigParser, ConfigVariableParser):

    _path_variables = set(('directory', 'build_directory',
                           'installer_filename',
                           'offline_installer_filename',
                           'data_repos_dir', 'test_install_dir',
                           'stdout_file', 'stderr_file', 'test_ref_data_dir',
                           'test_run_data_dir', 'remote_installer_filename',
                           'remote_offline_installer_filename',
                           'remote_repos_dir', 'remote_data_repos_dir',
                           'remote_test_install_dir',
                           'remote_test_ref_data_dir',
                           'remote_test_run_data_dir'))
    _variables_with_replacements = set(('pack_version', 'directory_id',
                                        'packaging_options',
                                        'make_options', 'ctest_options',
                                        'installer_options'))
    _variables_with_env_only_replacements = set(('env',
                                                 'test_ref_data_dir',
                                                 'test_run_data_dir',
                                                 'remote_test_ref_data_dir',
                                                 'remote_test_run_data_dir'))
    _validAdditiveOptions = set(('packaging_options', 'default_steps',
                                 'make_options', 'ctest_options', 'env',
                                 'installer_options'))
    _validOptions = set(('build_condition',
                         'remote_test_host_cmd',
                         'init_components_from_build_dir',
                         'keep_n_older_repos'))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)

    def __init__(self, directory, configuration):
        super(PackageDirectory, self).__init__(directory, configuration)
        self.build_directory = ''
        self.packaging_options = []
        #self.packaging_thirdparty = ''
        self.installer_filename = None
        self.installer_options = ''
        self.offline_installer_filename = None
        self.data_repos_dir = ''
        self.test_install_dir = ''
        self.init_components_from_build_dir = 'ON'
        self.pack_version = None
        self.pathvars = None
        self.default_steps = []
        self.keep_n_older_repos = 1
        self.ctest_options = []
        self.make_options = []
        self.directory_id = ''
        self.env = {}
        self.test_ref_data_dir = ''
        self.test_run_data_dir = tempfile.gettempdir()
        self.remote_installer_filename = None
        self.remote_offline_installer_filename = None
        self.remote_repos_dir = None
        self.remote_data_repos_dir = None
        self.remote_test_install_dir = None
        self.remote_test_host_cmd = None
        self.remote_test_ref_data_dir = None
        self.remote_test_run_data_dir = None

    def addConfigurationLine(self, line):
        # Supported lines in bv_maker.cfg for [ pack ... ]:
        if ConfigVariableParser.addConfigurationLine(self, line):
            pass
        else:
            line = os.path.expandvars(line)
            if line[0] == '+':
                if '*' in line:
                    raise SyntaxError()
        self.configurationLines.append(line)

    #def validate_option(self, option):
        #if option in ('init_components_from_build_dir', 'build_directory'):
            #if self.build_directory not in ('', None):
                #if self.init_components_from_build_dir.upper() == 'ON':
                    #build_dir = self.get_build_dir()
                    #build_dir.process_configuration_lines()
                    #self.components = dict(build_dir.components)
                #else:
                    #self.components = {}

    def get_matching_build_dirs(self):
        build_dirs = []
        for o in self.configuration.buildDirectories.values():
            if normalize_path(
                o.replace_vars(self._build_directory)) == o.directory:
                build_dirs.append(o)
                
        return build_dirs
        
    def get_build_dir(self):
        if not hasattr(self, 'build_dir'):
            build_dirs = self.get_matching_build_dirs()
            if len(build_dirs) == 0:
                raise RuntimeError(
                    'Package directory: referenced build directory "%s" does '
                    'not exist' % self.build_directory)
            elif len(build_dirs) > 1:
                raise RuntimeError(
                    'Package directory: referenced build directory "%s" '
                    'must match a unique build directory. Matches %d '
                    'directories %s' % (self.build_directory, len(build_dirs),
                                        str(build_dirs)))
            else:
                self.build_dir = build_dirs[0]
            
        return self.build_dir
    
    def set_dependencies(self):                
        build_section = self.get_build_dir()
        
        if build_section is not None:
            build_section = [(build_section, 'build'),
                             (build_section, 'doc'),
                             (build_section, 'test')]
        else:
            build_section = []
        self.depend_on_sections = {
            'pack': build_section,
            'install_pack': [(self, 'pack')],
            'test_pack': [(self, 'install_pack')],
        }

    def process_configuration_lines(self):
        if not self._configuration_lines_processed:
            build_dir = self.get_build_dir()

            if self.init_components_from_build_dir.upper() == 'ON':
                build_dir.process_configuration_lines()
                # make sure to do an actual copy of build dir projects/components
                self.projects = list(build_dir.projects)
                self.components = dict(build_dir.components)
            super(PackageDirectory, self).process_configuration_lines()

    def info(self):
        self.process_configuration_lines()
        print('Package directory: "' + self._directory + '"')
        print('  Real package directory:', self.directory)
        print('  Build directory:', self.build_directory)
        for component, directory_version_model \
                in six.iteritems(self.components):
            directory, selected_version, version, build_model \
                = directory_version_model
            print('  %s (%s) <- %s' % (component, version, directory))

    def get_pack_version(self):
        if self.pack_version:
            version = self.pack_version
        else:
            version = '1.0.0'

            if not self._property_recursivity.get('build_directory'):
                build_dir = self.get_build_dir()
                v = build_dir.get_version()
                if v:
                    version = v
        return version
        
    def __init_python_vars(self):
        online = 'online'
        offline = 'offline'
        
        if not self._property_recursivity.get('build_directory'):
            build_dir = self.get_build_dir()
            self.update_python_vars(build_dir.get_python_vars())
        
        if not self._property_recursivity.get('packaging_options'):
            # Add i2bm and public vars
            i2bm_str = 'public'
            public = ''

            if '--i2bm' in self.packaging_options:
                i2bm_str = 'i2bm'
                public = '-i2bm'
            self.update_python_vars({'i2bm': i2bm_str, 
                                     'public': public})

        if not self._property_recursivity.get('pack_version'):
            # Add version var
            self.update_python_vars({'version': self.get_pack_version()})
            
        # Add online var and local variables
        self.update_python_vars({'online': online, 
                                 'offline': offline})
    
    def installer_variables(self):
        return self.get_python_vars()
    
    def installer_cmdline(self):
        components = self.components.keys()
        projects = list(self.projects)
        pack_options = self.packaging_options
        installer_filename = self.installer_filename
        #if not installer_filename:
            #installer_filename = os.path.join(
                #os.path.dirname(self.directory),
                #'brainvisa-installer/brainvisa_installer-'
                #'%(version)s-%(os)s-%(online)s%(public)s')
      
        offline_installer_filename = self.offline_installer_filename
        #directory = self.replace_vars(self.directory)
        directory = self.directory

        exe_suffix = ''
        if sys.platform == 'win32':
            exe_suffix = '.exe'

        # if bv_build_installer is in the build tree, use it
        bvi = os.path.join(self.build_directory, 'bin',
                           'bv_build_installer.py')
        if not os.path.exists(bvi):
            # otherwise use the path
            bvi = distutils.spawn.find_executable('bv_build_installer.py')
        cmd = [os.path.join(self.build_directory, 'bin',
                            'bv_env_host%s' % exe_suffix),
               sys.executable, bvi, '-r', directory]
        if installer_filename:
            cmd += ['-i', installer_filename]
        if offline_installer_filename:
            from brainvisa.installer import version as bvi_ver
            if [int(x) for x in bvi_ver.version.split('.')] >= [1, 2]:
                cmd += ['-j', offline_installer_filename]
                
                if self.data_repos_dir:
                    # Add data directory as an additional repository to allow
                    # binarycreator to find data packages to embed in the 
                    # offline installer
                    cmd += ['-f', self.data_repos_dir]
            else:
                print('warning: bv installer version too old to handle '
                      'offline + online installers at the same time.')
        if not installer_filename and not offline_installer_filename:
            cmd.append( '--repository-only' )
        cmd += pack_options + ['-p'] + projects + ['-n'] + components
        return cmd

    def make_install_script(self, install_dir, repos_dir, data_repos_dir,
                            temp_dir=None):

        fd, script_fname = tempfile.mkstemp(prefix='install_script',
                                            dir=temp_dir)
        os.close(fd)
        
        install_dir = self.build_dir.to_target_path(install_dir)
        
        if not repos_dir.startswith('file://'):
            repos_dir = self.build_dir.to_target_path(repos_dir) \
                        .to_system('uri')
 
        if data_repos_dir:
            if not data_repos_dir.startswith('file://'):
                data_repos_dir = self.build_dir.to_target_path(data_repos_dir) \
                                 .to_system('uri')
           
            data_repos_dir_url = ', "%s"' % data_repos_dir
        else:
            data_repos_dir_url = ""
            
        

        f = open(script_fname, 'w')
        f.write('''var install_dir = "%s";
var repositories = ["%s"%s];

function Controller()
{
    print("controller instanciated");

    installer.currentPageChanged.connect(OnCurrentPageChangedCallback);
    installer.installationStarted.connect(OnInstallationStartedCallback);
    installer.installationFinished.connect(OnInstallationFinishedCallback);
    installer.installationInterrupted.connect(OnInstallationInterruptedCallback);

    installer.autoRejectMessageBoxes;
    
    installer.setMessageBoxAutomaticAnswer("OverwriteTargetDirectory", 
                                           QMessageBox.Yes);
    
    installer.setMessageBoxAutomaticAnswer("installationError", 
                                           QMessageBox.OK);

    installer.setMessageBoxAutomaticAnswer("installationErrorWithRetry", 
                                           QMessageBox.Cancel);

    installer.setMessageBoxAutomaticAnswer("AuthorizationError", 
                                           QMessageBox.Abort);

    installer.setMessageBoxAutomaticAnswer("OperationDoesNotExistError", 
                                           QMessageBox.Abort);
                                           
    installer.setMessageBoxAutomaticAnswer("isAutoDependOnError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("isDefaultError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("isDefaultError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("DownloadError", 
                                           QMessageBox.Cancel);
    
    installer.setMessageBoxAutomaticAnswer("archiveDownloadError", 
                                           QMessageBox.Cancel);
    
    installer.setMessageBoxAutomaticAnswer("WriteError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("ElevationError", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("unknown", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("Error", 
                                           QMessageBox.OK);
                                                                              
    installer.setMessageBoxAutomaticAnswer("stopProcessesForUpdates", 
                                           QMessageBox.Ignore);
                                           
    installer.setMessageBoxAutomaticAnswer("Installer_Needs_To_Be_Local_Error", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("TargetDirectoryInUse", 
                                           QMessageBox.No);
                                           
    installer.setMessageBoxAutomaticAnswer("WrongTargetDirectory", 
                                           QMessageBox.OK);
                                           
    installer.setMessageBoxAutomaticAnswer("AlreadyRunning", 
                                           QMessageBox.OK);
                                           
    //installer.setMessageBoxAutomaticAnswer("cancelInstallation", 
    //                                       QMessageBox.Yes);                                   
}

OnInstallationStartedCallback = function()
{
    print("installation started");
}

OnInstallationFinishedCallback = function()
{
    print("installation ended");
    // This is necessary for windows
    gui.clickButton(buttons.NextButton);
}

OnInstallationInterruptedCallback = function()
{
    print("installation interrupted");
}

OnCurrentPageChangedCallback = function(page)
{
    print("page changed");
}

Controller.prototype.IntroductionPageCallback = function()
{
    print("introduction page");
    installer.setTemporaryRepositories(repositories, true);
    gui.clickButton(buttons.NextButton)
}

Controller.prototype.TargetDirectoryPageCallback = function()
{
    print("target directory page");
    var widget = gui.currentPageWidget(); // get the current wizard page
    widget.TargetDirectoryLineEdit.setText(install_dir);
    print("install directory: " + widget.TargetDirectoryLineEdit.text)
    print("message: " + widget.MessageLabel.text)
    if (widget.WarningLabel)
    {
        print("warning: " + widget.WarningLabel.text)
    }
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.ComponentSelectionPageCallback = function()
{
    print("component selection page");
    var widget = gui.currentPageWidget();
    widget.selectAll();
    gui.clickButton(buttons.NextButton);
    //installer.setAutomatedPageSwitchEnabled(true);
}

Controller.prototype.LicenseAgreementPageCallback = function()
{
    print("licence agreement page");
    var widget = gui.currentPageWidget();
    widget.AcceptLicenseRadioButton.setChecked(true);
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.StartMenuDirectoryPageCallback = function()
{
    print("start menu directory page");
    gui.clickButton(buttons.NextButton);
}

Controller.prototype.ReadyForInstallationPageCallback = function()
{
    print("ready for installation page");
    gui.clickButton(buttons.CommitButton);
}

Controller.prototype.PerformInstallationPageCallback = function()
{
    print("perform installation page");
    gui.clickButton(buttons.CommitButton);
}

Controller.prototype.FinishedPageCallback = function()
{
    print("finished page");
    gui.clickButton(buttons.FinishButton);
}

''' % (install_dir, repos_dir, data_repos_dir_url))
        f.close()
        return script_fname

    def package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()
        #directory = self.replace_vars(self.directory)
        directory = self.directory
        print('Building package:', directory)
        print('    from build dir:', self.build_dir.directory)
        self.cleanup_package_dir()
        cmd = self.installer_cmdline()
        print('running:', "'" + "' '".join(cmd) + "'")
        subprocess.check_call(cmd, cwd=self.build_dir.directory,
                              env=self.get_environ())

    @staticmethod
    def rm_with_empty_dirs(path):
        if os.path.isdir(path):
            shutil.rmtree(path)
        else:
            os.unlink(path)
        d = os.path.dirname(path)
        while d and len(os.listdir(d)) == 0:
            try:
                os.rmdir(d)
            except:
                break
            d = os.path.dirname(d)

    def cleanup_package_dir(self):
        #directory = self.replace_vars(self.directory)
        directory = self.directory
        dirs = [directory, directory + '_tmp']
        pack_options = self.packaging_options
        if '--skip-repos' not in pack_options \
                and '--skip-existing' not in pack_options:
            for d in dirs:
                if os.path.isdir(d):
                    shutil.rmtree(d)
        if os.path.isdir(directory):
            report_file = os.path.join(directory, 'tests_report.txt')
            if os.path.exists(report_file):
                os.unlink(report_file)
        # erase older repositories
        if '%(date)s' in self._directory:
            real_vars = dict(self.installer_variables())
            real_vars.update(global_installer_datetime())
            vars = dict(real_vars) # copy vars
            vars['date'] = '*'
            my_dir = environmentPathVariablesSubstitution(
                self._directory, env=self.get_environ()) % real_vars
            dir_pattern = environmentPathVariablesSubstitution(
                self._directory, env=self.get_environ()) % vars
            older_dirs = [d for d in glob.glob(dir_pattern) if d != my_dir]
            older_tmp_dirs = [d for d in glob.glob(dir_pattern + '_tmp')
                              if d != my_dir + '_tmp']
            # check in older repos if they were OK
            repos_to_remove = set()
            for d in older_dirs:
                report_file = os.path.join(d, 'tests_report.txt')
                if os.path.exists(report_file):
                    report = open(report_file).readlines()
                    if report[-1].strip() != 'Tests_result: OK':
                        repos_to_remove.add(d)
                        print('removing older failed repos:', d)
            older_dirs = [d for d in older_dirs if d not in repos_to_remove]
            to_remove = set()
            for d in older_tmp_dirs:
                if not d[:-4] in older_dirs:
                    print('temp repos', d, 'has no real repos')
                    self.rm_with_empty_dirs(d)
                    to_remove.add(d)
            older_tmp_dirs = sorted([d for d in older_tmp_dirs
                                     if d not in to_remove])
            older_dirs = sorted(older_dirs)
            keep_n_older_repos = int(self.keep_n_older_repos)
            if len(older_dirs) > keep_n_older_repos:
                repos_to_remove.update(
                    older_dirs[:len(older_dirs) - keep_n_older_repos])
            # remove older repos and installs
            vars['date'] = '%(date)s' # keep date pattern as is
            pattern = environmentPathVariablesSubstitution(
                self._directory, env=self.get_environ()) % vars
            pattern = pattern.replace('\\', '\\\\').replace('.', '\.')
            pattern = re.compile(pattern % {'date': '(.+)'})
            for d in repos_to_remove:
                print('removing:', d)
                self.rm_with_empty_dirs(d)
                if d + '_tmp' in older_tmp_dirs:
                    print('removing:', d + '_tmp')
                    self.rm_with_empty_dirs(d + '_tmp')
                infos_file = os.path.join(os.path.dirname(d),
                                          'packages_infos.html')
                if os.path.exists(infos_file):
                    self.rm_with_empty_dirs(infos_file)
                m = pattern.match(d)
                r_date = m.group(1)
                vars['date'] = r_date
                # find associated installer
                if self.installer_filename:
                    installer = environmentPathVariablesSubstitution(
                        self._installer_filename,
                        env=self.get_environ()) % vars
                    if os.path.exists(installer):
                        print('removing:', installer)
                        self.rm_with_empty_dirs(installer)
                    if os.path.exists(installer + '.md5'):
                        self.rm_with_empty_dirs(installer + '.md5')
                    # check for lock file leaved after installer crash
                    lockfile = glob.glob(os.path.join(
                        os.path.dirname(installer), 'lock*.lock'))
                    for lock in lockfile:
                        self.rm_with_empty_dirs(lock)
                    # on Mac, remove .dmg files and .app directory
                    if sys.platform == 'darwin':
                        if os.path.exists(installer + '.dmg'):
                            self.rm_with_empty_dirs(installer + '.dmg')
                        if os.path.exists(installer + '.dmg.md5'):
                            self.rm_with_empty_dirs(installer + '.dmg.md5')
                        if os.path.exists(installer + '.app'):
                            self.rm_with_empty_dirs(installer + '.app')
                # find associated install
                if self.test_install_dir:
                    install_dir = environmentPathVariablesSubstitution(
                        self._test_install_dir,
                        env=self.get_environ()) % vars
                    if os.path.exists(install_dir):
                        print('removing', install_dir)
                        self.rm_with_empty_dirs(install_dir)
                    # and tmp dir
                    tmp_dir = os.path.join(os.path.dirname(install_dir), 'tmp')
                    # remove it if empty
                    if os.path.isdir(tmp_dir) \
                            and len(os.listdir(tmp_dir)) == 0:
                        print('removing:', tmp_dir)
                        self.rm_with_empty_dirs(tmp_dir)


    def install_package(self, options, args):       
        #self.test_config(options, args)
        self.process_configuration_lines()
        #directory = self.replace_vars(self.directory)
        directory = self.directory
        
        if not self.test_install_dir:
            return IGNORED_STEP
        
        remote_test_install = True if self.remote_test_host_cmd \
                                      and not options.local \
                                      else False

        # Test install directory            
        if options.prefix:
            test_install_dir = options.prefix
            remote_test_install_dir = options.prefix
        else:
            test_install_dir = self.test_install_dir
            if remote_test_install and self.remote_test_install_dir:
                remote_test_install_dir = self.remote_test_install_dir
            else:    
                remote_test_install_dir = test_install_dir

        # Temporary directory
        tmp_dir = os.path.join(os.path.dirname(test_install_dir), 'tmp')
        
        # Repository directory
        repos_dir = directory
        if remote_test_install and self.remote_repos_dir:
            remote_repos_dir = self.remote_repos_dir
        else:
            remote_repos_dir = repos_dir
        
        # Data repository directory
        data_repos_dir = self.data_repos_dir
        if remote_test_install and self.remote_data_repos_dir:
            remote_data_repos_dir = self.remote_data_repos_dir
        elif self.data_repos_dir:
            remote_data_repos_dir = data_repos_dir
        else:
            remote_data_repos_dir = None

        use_online_installer = not options.offline \
            and self.installer_filename is not None
        
        if not use_online_installer \
           and self.offline_installer_filename is not None:
            installer_filename = self.offline_installer_filename
        else:        
            installer_filename = self.installer_filename
            
        if remote_test_install:
            if not use_online_installer \
               and self.remote_offline_installer_filename is not None:
                remote_installer_filename = self.remote_offline_installer_filename
            elif self.remote_installer_filename is not None:
                remote_installer_filename = self.remote_installer_filename
            else:
                remote_installer_filename = installer_filename

        else:
            remote_installer_filename = installer_filename

        print('Installing package:', directory)
        print('    with installer:', remote_installer_filename)
        if(data_repos_dir):
            print('    using data package:', data_repos_dir)
        print('    from build dir:', self.build_dir.directory)
        print('    to:', test_install_dir)
        if remote_test_install:
            print('    remote:', self.remote_test_host_cmd)

        if os.path.isdir(test_install_dir):
            print('removing previous test installation...')
            shutil.rmtree(test_install_dir)

        #if os.path.isdir(tmp_dir):
            #print('removing previous temporary directory...')
            #shutil.rmtree(tmp_dir)

        if not os.path.exists(test_install_dir):
            print('creating test directory...')
            os.makedirs(test_install_dir)

        if not os.path.exists(tmp_dir):
            print('creating temporary directory...')
            os.makedirs(tmp_dir)

        if use_online_installer \
            and (not os.path.isdir(repos_dir) \
                 or (data_repos_dir is not None \
                 and not os.path.isdir(data_repos_dir))):
            # For offline package installation these directories are not 
            # necessary
            raise RuntimeError('Some repositories are missing (%s, %s). ' \
                'Installation may fail.' % (repos_dir, data_repos_dir))

        install_script = self.make_install_script( 
            remote_test_install_dir, 
            remote_repos_dir, 
            remote_data_repos_dir, 
            temp_dir=tmp_dir)

        cmd = []
        if remote_test_install:
            cmd = shlex.split(self.remote_test_host_cmd)

        if sys.platform == 'darwin':
            # on Mac, the installer is a .app
            remote_installer_filename += '.app/Contents/MacOS/%s' \
                % os.path.basename(remote_installer_filename)
        cmd += [remote_installer_filename] \
               + shlex.split(self.installer_options) \
               + ['--script', self.build_dir.to_target_path(install_script)]
        try:
            print('installing...')
            cmd = '"' + '" "'.join(cmd) + '"'
            print(cmd)
            subprocess.check_call(cmd, shell=True, env=self.get_environ())
            print('done.')
        finally:
            os.unlink(install_script)

    def init_vars(self):        
        super(PackageDirectory, self).init_vars()
        
        self.__init_python_vars()
        self.__init_environ()
        
    def __init_environ(self):
        env = {}
        # binaries are in bin/real-bin/ (used by some python tests commands)
        env['BRAINVISA_REAL_BIN'] = '/real-bin'
        
        if not self._property_recursivity.get('remote_test_host_cmd'):
            if self.remote_test_host_cmd \
                and (not self._property_recursivity.get(
                    'remote_test_install_dir')) \
                and self.remote_test_install_dir:
                install_dir = self.remote_test_install_dir
                env['BRAINVISA_PACKAGE_INSTALL_PREFIX'] = install_dir            
            elif (not self._property_recursivity.get('test_install_dir')) \
                and self.test_install_dir:
                install_dir = self.test_install_dir
                env['BRAINVISA_PACKAGE_INSTALL_PREFIX'] = install_dir
    
            if (not self._property_recursivity.get('build_directory')):
                build_dir = self.configuration.buildDirectories.get(
                    self.build_directory)

                if build_dir:
                    if self.remote_test_host_cmd \
                        and (not self._property_recursivity.get(
                            'remote_test_run_data_dir')) \
                        and self.remote_test_run_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_RUN_DATA_DIR"] = \
                            build_dir.to_target_path(self.remote_test_run_data_dir)
                    elif (not self._property_recursivity.get(
                            'test_run_data_dir')) \
                         and self.test_run_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_RUN_DATA_DIR"] = \
                            build_dir.to_target_path(self.test_run_data_dir)
                    
                    if self.remote_test_host_cmd \
                        and (not self._property_recursivity.get(
                            'remote_test_ref_data_dir')) \
                        and self.remote_test_ref_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_REF_DATA_DIR"] = \
                            build_dir.to_target_path(self.remote_test_ref_data_dir)
                    elif (not self._property_recursivity.get(
                            'test_ref_data_dir')) \
                        and self.test_ref_data_dir:
                        # Add directories to env
                        env["BRAINVISA_TEST_REF_DATA_DIR"] = \
                            build_dir.to_target_path(self.test_ref_data_dir)
            
            if self.remote_test_host_cmd:
                # temporarily change os.environ since expand_shell uses
                # os.path.expandvars(), which use os.environ variables
                cur_env = os.environ
                os.environ = dict(os.environ)
                os.environ.update(env)
                env['BRAINVISA_TEST_REMOTE_COMMAND'] \
                    = self.expand_shell(self.remote_test_host_cmd)
                os.environ = cur_env
                
        self.update_environ(env)
        
        return env
    
    def reset_environ(self):
        super(PackageDirectory, self).reset_environ()
        self.__init_environ()
        
    def test_package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()
        if not self.test_install_dir:
            return IGNORED_STEP
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir is not defined; tests may fail.")
        # Create test_run_data_dir and test_ref_data_dir
        if self.test_run_data_dir \
                and not os.path.exists(self.test_run_data_dir):
            os.makedirs(self.test_run_data_dir)
        if self.test_ref_data_dir \
                and not os.path.exists(self.test_ref_data_dir):
            os.makedirs(self.test_ref_data_dir)
        print('Testing package:', self.directory)
        print('    from build dir:', self.build_dir.directory)
        install_dir = self.test_install_dir
        # Add directories to env
        new_env = self.get_environ(dict(os.environ))
        repos_dir = self.replace_vars(self.directory)
        report_file = os.path.join(repos_dir, 'tests_report.txt')
        if options.ctest_options is not None:
            ctoptions = shlex.split(options.ctest_options)
        else:
            ctoptions = self.ctest_options
        test_res = run_and_log_tests(cwd=self.build_dir.directory,
                                     env=new_env, options=ctoptions,
                                     projects=self.projects)
        if test_res:
            status = 'OK'
            for item in six.itervalues(test_res):
                if item['exception'] is not None:
                    status = 'FAILED'
            if os.path.isdir(repos_dir):
                open(report_file, 'w').write('Tests_result: %s\n' % status)
        elif os.path.isdir(repos_dir):
            open(report_file, 'w').write('Tests_result: OK\n')
        return test_res

    def testref_package(self, options, args):
        #self.test_config(options, args)
        self.process_configuration_lines()

        if not self.test_install_dir:
            return IGNORED_STEP
        if not self.test_ref_data_dir:
            print("Warning: test_ref_data_dir should be defined to create "
                  "reference files.")
        # Create test_ref_data_dir
        if self.test_ref_data_dir \
                and not os.path.exists(self.test_ref_data_dir):
            os.makedirs(self.test_ref_data_dir)
        if options.make_options is not None:
            ctoptions = shlex.split(options.make_options)
        else:
            ctoptions = self.make_options
        print('Creating test reference files for package:', self.directory)
        print('    from build dir:', self.build_dir.directory)
        install_dir = self.test_install_dir
        # Add directories to env
        new_env = self.get_environ(dict(os.environ))
        return run_and_log_testref(cwd=self.build_dir.directory,
                                   env=new_env, options=ctoptions)

    def expand_shell(self, line):
        ''' Allow shell commands expressions $(command arg) in string
        '''
        patt = re.compile('\$\(([^\)]+)\)')
        expressions = patt.split(os.path.expandvars(line))
        new_line = expressions.pop(0)
        while expressions:
            expr = expressions.pop(0)
            text = subprocess.check_output(expr, shell=True).strip()
            new_line += text
            new_line += expressions.pop(0)
        return ' '.join(shlex.split(new_line))


class PublicationDirectory(DirectorySection, ConfigVariableParser):

    _path_variables = set(('package_directory', 
                           'stdout_file', 'stderr_file'))
    _variables_with_replacements = set(('directory', 'directory_id', 
                                        'publication_commands'))
    _variables_with_env_only_replacements = set(('env',))
    _validAdditiveOptions = set(('publication_commands', ))
    _validOptions = set(('build_condition', ))
    _validOptions.update(_variables_with_replacements)
    _validOptions.update(_variables_with_env_only_replacements)
    _validOptions.update(_path_variables)
    _validOptions.update(_validAdditiveOptions)

    def __init__(self, directory, configuration):
        super(PublicationDirectory, self).__init__()
        
        self.configuration = configuration       
        self.directory = directory
        self.package_directory = ''
        self.pathvars = None
        self.default_steps = []
        self.publication_commands = []
        self.directory_id = ''
        self.env = {}

    def init_vars(self):
        super(PublicationDirectory, self).init_vars()
        
        self.__init_python_vars()
        
    def __init_python_vars(self):
        package_dir = self.get_package_dir()
        
        # Add same python variables than pack section
        self.update_python_vars(package_dir.get_python_vars())

    def get_matching_package_dirs(self):
        package_dirs = []
        for o in self.configuration.packageDirectories.values():
            if normalize_path(
                o.replace_vars(self.package_directory)) == o.directory:
                package_dirs.append(o)
                
        return package_dirs
        
    def get_package_dir(self):
        if not hasattr(self, 'package_dir'):
            package_dirs = self.get_matching_package_dirs()
            if len(package_dirs) == 0:
                raise RuntimeError(
                    'Package directory: referenced package directory "%s" does '
                    'not exist' % self.package_directory)
            elif len(package_dirs) > 1:
                raise RuntimeError(
                    'Package directory: referenced package directory "%s" '
                    'must match a unique package directory. Matches %d '
                    'directories %s' % (self.package_directory, 
                                        len(package_dirs),
                                        str(package_dirs)))
            else:
                self.package_dir = package_dirs[0]
            
        return self.package_dir
    
    def get_build_dir(self):
        return self.get_package_dir().get_build_dir()
    
    def set_dependencies(self):                
        pack_section = self.get_package_dir()
        
        if pack_section is not None:
            pack_section = [(pack_section, 'build'),
                            (pack_section, 'doc'),
                            (pack_section, 'test'),
                            (pack_section, 'pack')]
        else:
            pack_section = []
            
        self.depend_on_sections = {
            'publish': pack_section,
        }

    #def test_config(self, options, args):
        #package_dir = self.get_package_dir()
        #build_dir = package_dir.get_build_dir()

    def info(self):
        print('Publication package directory: "' + self._directory + '"')
        print('  Real publication package directory:', self.directory)
        print('  Package directory:', self.package_directory)
        print('  Build directory:', self.get_package_dir().build_directory)

    def publish_package(self, options, args):       
        #self.test_config(options, args)
        self.process_configuration_lines()

        package_dir = self.get_package_dir()
        if not package_dir:
            return IGNORED_STEP
            
        print('Running commands for package publication', 
              self.package_directory, '=>', self.directory)

        # These values can only be added to python variables when they are
        # completely solved from the command
        self.update_python_vars({'package_directory': self.package_directory,
                                 'publication_directory': self.directory})
        
        if not self.publication_commands:
            # Default publication command
            self.publication_commands = [
                'cmake -E copy_directory '
                '"%(package_directory)s/brainvisa-installer" '
                '"%(package_directory)s/packages" '
                '"%(package_directory)s/packages_tmp" '
                '"%(publication_directory)s"']

        env = self.get_environ()
        for c in self.publication_commands:
            command = shlex.split(c)
            system_output_on_error(command, env = env)
            

def display_failure_summary(configuration):
    sections = [('sourcesDirectories', ['sources']),
                ('buildDirectories', ['configure', 'build', 'doc', 'test']),
                ('packageDirectories', ['pack', 'install_pack', 'test_pack']),
                ('publicationDirectories', ['publish_pack']),
                ]
    global_failed = False
    status_map = {'not run': '',
                  'succeeded': 'OK         ',
                  'failed': 'FAILED     ',
                  'unmet dependency': 'UNMET DEP  ',
                  'interrupted': 'INTERRUPTED'}
    sys.stdout.flush()
    sys.stderr.flush()
    messages = ['\nbv_maker summary:']
    print(messages[0])
    #log_file = None
    #if configuration.general_section \
            #and configuration.general_section.global_status_file:
        #log_file = configuration.general_section.global_status_file
        #machine = gethostname()
        #osname = global_installer_variables()['os']
    first_start = None
    last_stop = None
    for section_name, steps in sections:
        for section in getattr(configuration, section_name).values():
            for step in steps:
                status = status_map[section.get_status(step)]
                if status != '':
                    message = '%s step %s: %s' % (status, step, 
                                                  section.directory)
                    start = section.start_time.get(step)
                    if start:
                        if first_start is None:
                            first_start = start
                        message += ', started: %04d/%02d/%02d %02d:%02d' \
                            % start[:5]
                    stop = section.stop_time.get(step)
                    if stop:
                        last_stop = stop
                        message += ', stopped: %04d/%02d/%02d %02d:%02d' \
                            % stop[:5]
                    messages.append(message)
                    print(message)
                    if section.has_failed(step):
                        global_failed = True
    if global_failed:
        status = 'There were errors.'
        print(status)
    else:
        status = 'All went good.'
        print(status)
    global jenkins_wrapper
    jenkins_wrapper.jenkins_global_notification(
        '\n'.join(messages) + '\n', global_failed, first_start, last_stop,
        status)
    return global_failed

# ---

commands = {
    'info': InfoCommand,
    'sources': SourcesCommand,
    'configure': ConfigureCommand,
    'build': BuildCommand,
    'doc': DocCommand,
    'test': TestCommand,
    'testref': TestrefCommand,
    'pack': PackCommand,
    'install_pack': InstallPackCommand,
    'test_pack': TestPackCommand,
    'testref_pack': TestrefPackCommand,
    'publish_pack': PublishPackCommand,
}

default_commands = ['info', 'sources', 'configure', 'build', 'doc', 'test',
                    'pack', 'install_pack', 'test_pack']
options_by_command = {None: []}
command = None
for i in sys.argv[1:]:
    if i in commands:
        command = i
        if command in options_by_command:
            raise ValueError('Command %s used twice' % command)
        options_by_command[command] = []
    else:
        options_by_command[command].append(i)

# Initialize global configuration
configuration = GlobalConfiguration(options_by_command[None])

# Parse commands options and prepare them for processing in the correct order
todo = []
if len(options_by_command) == 1:
    # No command selected => do all default commands
    for i in default_commands:
        options_by_command[i] = ['--only-if-default']

if not jenkins_wrapper:
    jenkins_wrapper = JenkinsWrapper()
jenkins_wrapper.jenkins_global_notify_running()

# Ordered command list
for command in ['info', 'sources', 'configure', 'build', 'doc', 'test',
                'testref', 'pack', 'install_pack', 'test_pack',
                'testref_pack', 'publish_pack']:
    if command in options_by_command:
        todo.append(
            commands[command](options_by_command[command], configuration))

failed = False
# Execute selected commands
try:
    for f in todo:
        f()
except KeyboardInterrupt:
    traceback.print_exc()
    failed = True

failed |= display_failure_summary(configuration)

# cleanup
del f, todo, commands, options_by_command, configuration

if failed:
    sys.exit(1)
